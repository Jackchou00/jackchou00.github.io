[{"content":"从生豆开始 精品咖啡早就形成了完整的产业链：从上游原产地的采摘和处理，到生豆运回国内，再由烘焙商烘焙成熟豆进行销售。\n买的咖啡豆多了，会发现好像各家烘焙的都在卖同一款豆，在网上搜索一下就会发现，其实是因为它们也都是买同一个生豆商的，既然如此，我能不能也自己烘焙呢。\n这个黄绿色的就是咖啡生豆，是来自弘顺咖啡的花魁 XS，有一股草药和谷物的味道。市面上的一些“生咖”产品（如星巴克的某些饮品和瑞幸的轻咖）就利用了生豆萃取液，喝起来有一股独特的青草味，并富含绿原酸。这样的生豆不适合直接研磨冲煮。\n咖啡豆的烘焙是一个复杂而迷人的化学与物理转化过程，本质上是在热量的作用下，咖啡生豆经过脱水，梅纳德反应和焦糖化之后，将内部的各种物质转变为风味的过程。\n因此，烘焙咖啡豆需要一台能够将热量传递给生豆的机器，比如以热风的形式，就像本文的主角：火柴盒 H7S Lite。\n火柴盒 H7S Lite 买它的原因单纯是因为它足够便宜，在配套的软件里也提供了很多辅助功能。\n一个很简易的泡沫包装，配套的电源线有 1.5 平方毫米，1800W 功率提供足够的热能。\n铝合金制作的小巧机身也是选择的一大理由。\n产品名“火柴盒”阴刻在侧面，这个品牌也比较接近小作坊。\n移去顶部接银皮的收集仓，这个玻璃管子便是生豆仓，底下是热风的出口，螺旋出风将咖啡豆旋转吹动，使其均匀受热。\n伸出的一根东西是温度传感器，用于检测豆温，掌握烘焙进程。\n过程中，咖啡豆被热风吹动，逐渐升高温度，颜色从生豆的黄绿色脱水变为黄色，然后发生一系列化学反应转变为棕褐色。并在 190 摄氏度附近，由于豆内部的水蒸气和二氧化碳压力升高，使得内部结构被撑破，发出清脆的爆裂声，称为“一爆”。在一爆之后不久便可结束加热，得到浅度烘焙附近的咖啡熟豆。\n烘焙过程中，咖啡豆的一层薄膜会随着豆体膨胀脱落下来，称为“银皮”，这层碎屑一样的东西会被热风吹进收集器中。\n熟豆和自烘的利弊 最后，便得到了我们熟悉的咖啡熟豆。经过了脱水等环节，熟豆的重量相比生豆会减轻 10% 左右。\n生豆角度下咖啡的成本 从成本的角度来看，这个花魁 XS 的生豆价格是 139 元一公斤，生豆的瑕疵率比较低，几乎可以不计。熟豆的重量是 90% 左右，即 155 元每公斤。售卖熟豆的店铺里，这款花魁一般会卖到 27-36 元不等每一百克，而 15g 花魁熟豆，在实体店里制作成一份手冲咖啡大概会卖到 20-35 元。当然，除去开店、运营的成本，尤其是线下实体店，咖啡的整体利润仍然是较低水平。\n说回自烘咖啡豆，成本的优势其实并不大，这样一台最基础的烘豆机，也得喝上千杯咖啡才能回本。主要当然还是好玩，可以自己掌握从生豆到熟豆的过程，尝试不同的烘焙方法带来的风味影响。\n自烘的缺点 关于烘焙本身，一方面，烘焙咖啡的过程说不上简单，要在几分钟的时间里精确的控制温度和风力，根据实际情况做出调整，并最终反馈到风味表现上。但同时，烘焙的容错率实际上比想象的更大，上面这锅熟豆是完全手动控制风力和火力，错误的设置导致接近十分钟才慢慢进入一爆，但也能得到“能喝”的东西。\n另外一个较大的问题是生豆，个人购买生豆主要依靠经销商，一般都是一公斤一公斤的卖，有更小规格的，单价也会高一些。这就导致烘一款豆子，可能接下来的一个月都是喝这个。然后一些比较小批次的咖啡豆，或者是精品一些，由“猎头”们直接去产地带回来的，就还是得购买别人烘好的熟豆来品鉴。\n点到为止 对于绝大部分咖啡爱好者来说，买烘豆机的钱足够你接下来一年内，把各种烘焙商的豆买个遍，然后喝到各种国家，产区和品种的咖啡豆。而不是一个月都在喝自己烘成各种各样的花魁。\n不过，人生在于折腾嘛。说不定哪天，我可能还会去种颗自己的咖啡树呢？\n","permalink":"https://jackchou.top/photos/matchbox-h7s-lite-roaster/","summary":"自烘咖啡的利与弊：火柴盒 H7S Lite 烘豆机体验","title":"一颗生豆的艺术之旅，自己动手烘咖啡"},{"content":"前情提要 需求 使用 Python 处理和生成的图片，通常以 NumPy 数组的形式存在，把这个数组输出到文件是处理链路的最后一环。以往，使用最多的是 PIL 编码成 JPEG 格式。而随着 HDR，高位深，高压缩率的需求增加，我开始寻找能将数字直接编码成 AVIF 图像的方法。\nlibavif 和 libheif 几乎所有相关的库都是 libavif 或 libheif 的 Python 绑定，实际上你完全可以先导出一个 JPEG 或者高位深的 TIFF，然后直接调用编译好的 libavif 进行编码，所有参数（质量、速度、颜色配置）都可以传进去。如果你的需求只是压缩图片，那没有必要进入 Python 再绕一圈。\n所以核心需求其实就是找一个好用的 libavif 的 Python 绑定，需要能够支持各种参数传入，如果 API 设计的优雅就更好了\n为数不多的选择 Python 中的 AVIF 编码已经有了一些发展，PIL 在 11.3.0 版本中加入了对 AVIF 的官方支持，但读和写都仅支持 8 bit，也没有传参数的接口，下面的两个插件则可以读写高位深图片和传参数。\n在 PIL 的 11.3.0 版本之前，要使用 PIL 编码 AVIF 的选择是 pillow-avif-plugin 插件，高级参数可以用变长关键字塞进去。\nPIL 的另一个选择是 pillow-heif，它是 libheif 的绑定，在 1.0.0 版本之后，去除了对 AVIF 的支持，开发者给出的理由是 PIL 已经原生支持了 AVIF，最后一个可用 AVIF 的版本是 0.22.0，高级参数同样需要使用变长关键字。\nImageIO 和 OpenImageIO，这两个库都提供了各种图像格式的读写功能，但似乎也不支持高位深和高级参数，（其实是这俩 API 的用法比较复杂，我还没研究明白，但应该是没有或者比较麻烦）。\n新选择：ImageCodecs ImageCodecs 也是一个提供了各种图像格式读写功能的库，AVIF 用的后端是 libavif。\n它的优点是 API 设计的非常简洁，曾经不支持色彩空间参数的传入，在 2025.11.11 版本中加入了支持。（有需求时，请大胆又合理地在 Issue 里“伸手”）\nfrom imagecodecs import avif_version, avif_encode, AVIF import numpy as np print(AVIF.available) print(avif_version()) array = np.ones((100, 100), dtype=np.uint16) * 65535 # 10-bit, BT.2020 with BT.2100 PQ transfer function # The numeric values for primaries/transfer are defined in H.273 encoded: bytes = avif_encode( array, bitspersample=10, primaries=9, transfer=16 ) with open(\u0026#34;output.avif\u0026#34;, \u0026#34;wb\u0026#34;) as f: f.write(encoded) 它的所有图像格式都采用类似的函数命名，你只需要检查是否可用，版本号，然后 encode 或 decode 即可。\n小心闪光弹（不过可能晚了）\nBT.2020 基色，BT.2100 PQ 传递函数的最大 RGB 及白色，10 bit，由 ImageCodecs 编码。\n","permalink":"https://jackchou.top/posts/imagecodecs-avif/","summary":"（速报）ImageCodecs 现已支持传入色彩空间和传递函数参数。","title":"Python AVIF 编码新选择：ImageCodecs"},{"content":"Here is a temporary page for CIC presentation usage, after the conference, will be re-organized as a paper reivew.\nAll images below are encoded as ISO 22028-5 format using PQ EOTF-inverse curve, should be HDR if you are using MacBook Pro with MiniLED display and Chrome or Safari (macOS Tahoe).\nInput Image, only basic colour conversion has been applied, absolute luminance of the image has been scaled down for less clipping.\nInput Adopted White, which is a blur version of the image above, blur amount here is 3 (a relative number, larger means less blur).\nOutput Adopted White, which is a blur version of the input image, blur amount here is 2 (means more blur, already close to flat). This represents how size will affect, if the display size is larger, more local adaptation should be considered.\nOutput Image, after forward transformation and adjustment in CAM16-UCS and reverse transformation using adopted white above. This should be close to observer\u0026rsquo;s result.\nHere is the ground-truth from observers and a comparison.\nMy pleasure to have you here! Please contact me using e-mail if you have any questions.\n","permalink":"https://jackchou.top/posts/cic33-paper/","summary":"Visual Matching Experiment and Tone Mapping based on CAM16-UCS","title":"(Temp) CIC 33 Paper Demonstration"},{"content":"\nThis one has up to 16x headroom\nThis one has up to 16x headroom\n","permalink":"https://jackchou.top/photos/hongkong-2025/","summary":"(5 Images) 在 CIC33 期间持续更新中","title":"香港"},{"content":" 观前提示：本篇文章没什么营养，单纯的发发牢骚，品鉴一下这家公司的作品而已。\n来自杭州的神秘小作坊 Geekon 是一家来自杭州的公司，生产很多显示器，参数非常诱人的同时，有着比其它“杂牌”显示器更高的价格和看似非常精致的外观，就连网页、网店和社交帐号的风格也是相当的简洁和高端，看起来非常有设计感，并不像是一个普通的用公模的小作坊。\n它还生产一些非常高端的型号，比如使用 6K 面板的 HDR 显示器，宣称色域达到了 92% BT.2020，亮度则是 2000 nits，这毫无疑问是非常高的参数。Geekon 表示自己使用的是一种自研面板，使用了国产的自研量子点技术，各种 4K，5K 和 6K 型号都能达到 92% BT.2020 色域和 1000 或 2000 nits 的超高亮度。需要注意的是，这种高亮度和 HDR 不是由分区背光等技术实现的，对比度仍然是 IPS 或类似 Black-IPS 的 1000:1 或 2000:1。\n本着对该品牌和超广色域的好奇，准备在它的淘宝店拿下一台型号为“黑界” DarkVision Studio 2700 的 4K 显示器。而各种出乎意料的事情，从购买前的仙家对话开始。\n询问客服 92% BT.2020 具体是如何计算的，客服简短的回答四个字：“缩限92”。询问如何开发票，回答“要多少”，我们现在只有 5K 的有货，4K 的卖完了，正在加工，要等到 11 月（此时商品的页面上写着：24小时内发货）。另一个号直接下单之后，发货却是非常的迅速，然后立刻下架了该商品（而小红书等平台上还在销售）。\n十八手包装箱 最外面是一个纸板箱，有它简洁的 Logo，可能有快递运输的影响，但这个包装的磨损和脏污情况也是超出意料，至少它很好的承担了防护的责任。上面有各种透明胶带，有没有品牌的普通透明胶，有印着它自己 Logo 的，有京东的，还有顺丰的，可谓是齐聚一堂，大概这也是一只去过天南海北闯荡过的纸箱了，非常的环保和循环。\n划开各种交叠着的胶带，里面是一个黑色的彩包，也是相当的高级，相比之下，明基一万多的专业摄影显示器都没这待遇。只是这个彩盒的左右似乎有点不适配，明显的要鼓起一些，上面不知为何还有一道压痕和一些磕伤，甚至还有一些被撕裂的部分，想必我已经不是第一个打开这个箱子的人了。彩盒上印有一些产品的卖点和介绍，比如说这块很神秘的 27 寸自研量子点 IPS 面板和 HDR 1000。\n打开这个彩盒，原来是一个翻盖式的设计，打开之后，是设计精美的说明书，被一个破损的塑料袋装着，里面还有一个纸壳子盖着屏本体（只不过这个纸壳子同样充满了裂缝），这个纸壳子内部还有泡棉填充，泡棉上挖了两个洞塞着两盒配件，配件盒的工艺和印刷也是十分考究。\n配件是一个适配器和一盒线材。\n败絮其中 正式欣赏屏幕之前，先看看给的配件具体是什么，电源适配器没有贴自己的牌子，直接来自湖南井富源，有 65W 反向供电的情况下使用了 24V 5A 规格，实际上要支撑 1000 nits 的全屏亮度确实是需要比较高的功率的，这个适配器单独买大概也要一百多块钱。\n线材就比较抽象了，给了 HDMI，DP 和 Type-C 各一根，但比较少见的是三根线材的包装方式各不相同，尤其是 HDMI，直接绕了一下就放进盒子了。\n在泡棉底下，终于见到庐山真面目，屏本体是直接连同支架安装好的。不得不说这个盒子做的真的很不错。\n为了防止支架回弹，拿一根扎带捆着，这根扎带看着也像是身经百战了。\n来到背面，上方是“黑界”的字样，铝合金支架没有采用快拆的结构，用四颗螺丝直接固定，不过在包装盒里就是安装好的形态，甚至比快拆还少一步，真正做到开箱就用。\n不幸的是支架的塑料包裹已经开裂。支架的铝合金和塑料部件有很多毛刺，做工很粗糙。\n来到正面，这个黑边足够停下一整个福特号航母战斗群，粗糙颗粒的黑色塑料大边框，倒是有些艺卓的风味。\n来到侧面，原来还是略带一点弧度的微曲面屏，也许是为了装下支撑 1000 nits 亮度的背光和散热，这个侧面的厚度足够停剩下的尼米兹级航母战斗群。\n未完待续 看完了外观，我对它的显示性能更是充满了期待，请期待下集：《借问 BT.2020 何处有》。我将以该显示器为案例，结合一些仿真计算，看看 92% BT.2020 是一个如何苛刻的指标。\n","permalink":"https://jackchou.top/posts/geekon-darkvision-2700-unbox-preview/","summary":"大胆尝试神秘小作坊的超高参数产品，却疑是买到十八手显示器","title":"来自 Geekon 的显示器开箱：高端与作坊并存"},{"content":"为什么 WSL 类似 Codex 的各种 CLI 式的 AI 编程工具，不擅长在 Powershell 中运行命令来精确的编辑文件，一方面是因为其训练时可能更熟悉 Unix 类的语法，另一方面则是 Powershell 缺少精确编辑文件内容的工具。因此安装 WSL，然后把 Codex 安装进 WSL 是更好的选择，也是 OpenAI 的推荐做法。\n要理解其原因，我们需要对比两种环境在处理文件和命令时的差异。\nAI Agent 修改代码时，能生成 sed、awk、diff、patch 这类命令，它们像外科手术刀一样，能对文件进行精确到行、列、模式的流式编辑（Stream Editing）。而 PowerShell 的常规操作是“读取-修改-写回”：Get-Content 将文件读入内存，修改元素，再用 Set-Content 将文件写回。这个过程不仅更繁琐，在处理大文件时性能也较差。AI Agent 需要花费更多精力来稳定地生成复杂的 PowerShell 代码块去完成修改。\nWSL2 允许利用 Linux 内核原生的命名空间技术创建一个安全的沙箱。这意味着 AI Agent 可以在一个被隔离的环境中运行，其文件访问被严格限制在项目目录内，并且可以禁用网络，这极大地提升了自动化代码修改的安全性。\n提示不支持 WSL2 即使已经在 BIOS 里打开了虚拟化，按网上的教程在 Windows 功能中勾选了 Hyper-V（其实是不必要的），但安装过程中仍然会报错，提示系统不支持 WSL2，虚拟化错误，以及 Hyper-V 没有安装。\nWsl/InstallDistro/Service/RegisterDistro/CreateVm/HCS/HCS_E_HYPERV_NOT_INSTALLED\n网络上解决该问题的方法多为使用命令行手动检查与打开 Hyper-V，或者使用 systeminfo 查看是否支持了 Hyper-V，但不能解决我的问题。\n隐形的 Hyper-V 实际上，运行 wsl --install 命令时，自动就会开启 Hyper-V 等有关内容，如微软的网页中所说：\nwsl --install 的功能如下：\n启用可选的 WSL 和虚拟机平台组件 下载并安装最新 Linux 内核 将 WSL 2 设置为默认值 下载并安装 Ubuntu Linux 发行版 这可能是由于一些“隐藏的” Hyper-V 功能没有开启，在启用或关闭 Windows 功能的 GUI 里看到 Hyper-V 相关内容都勾选了，但这可能是假象。\n我们使用命令行查看全部功能，dism 不区分大小写：\ndism /online /get-features 这些一般显示为已启用，它们和 GUI 中的那些 Hyper-V 选项对应。\nMicrosoft-Hyper-V-All Microsoft-Hyper-V Microsoft-Hyper-V-Tools-All Microsoft-Hyper-V-Management-PowerShell Microsoft-Hyper-V-Hypervisor Microsoft-Hyper-V-Services Microsoft-Hyper-V-Management-Clients 另外，还有两个名字里带着 Hyper-V 的功能，却没有出现在 GUI（也可能是因为微软的翻译问题）或 wsl --install 附带的命令中，可能是导致失败的主要原因。\nHyperV-KernelInt-VirtualDevice HyperV-Guest-KernelInt 使用命令行将这两个设置为启用，然后重启系统。\ndism /online /enable-feature /featurename:HyperV-KernelInt-VirtualDevice /all /norestart dism /online /enable-feature /featurename:HyperV-Guest-KernelInt /all /norestart 重启后，再次尝试安装。为避免重复下载发行版（在大陆网络环境非常浪费时间），我们可以先用不带参数的 wsl 命令或 wsl --status 来检查核心组件是否正常工作。如果不再报错，再执行 wsl --install -d \u0026lt;DistroName\u0026gt; 来安装你需要的发行版。\n总而言之 这只是一次非常罕见的问题，我以前从来没有用 wsl --install 安装失败过，但它确实发生了。也许下一次更新 wsl 的时候，就会把这两个可能是更新导致的新功能一并开启。把这种疑难杂症记录下来，既能水一篇博客，或许也能在另一个同样倒霉的人安装不成功的时候，有机会给予帮助。正如小时候经常意外的在贴吧里解决各种疑难杂症一样。\n","permalink":"https://jackchou.top/posts/wsl2-hyperv-install-fix/","summary":"即使 BIOS 和 Windows 功能都已正确设置，WSL2 仍提示虚拟化错误？问题可能出在这两个隐藏组件上","title":"解决 WSL2 因“隐形” Hyper-V 功能导致的安装失败"},{"content":"这是一次把我阅读的有意思的文献转化为笔记输出的尝试，接下来将介绍一篇新发表的文章，以及我在复现过程中的发现。\nReference: Y. Wang, M. Wei, Z. Ye, T. Hu, and H. Zheng, “An adaptive tone mapping method for PQ ‐ and HLG ‐encoded HDR contents,” Color Res. Appl., p. col.70002, July 2025, doi: 10.1002/col.70002.\n这是一种自适应的色调映射算法，将 0-1000 nits 的 HDR 内容映射到 0-100 nits 的 SDR。包含色调压缩，细节增强和暗区增强三个部分。\n特别的亮度 该算法中的亮度（Luminance）概念比较特殊，并不是 XYZ 中的 Y，而是 RGB 的最大值，类似于 HSV 中的 Value。\n这种亮度是为了在压缩过程中始终保持在 RGB 空间范围内，不会超出色域而导致色相的剧烈变化。但需要注意的是，即使色坐标保持了不变，但亮度变化仍然会导致色相和彩度发生变化，例如 Bezold–Brücke 色貌现象描述的当光的强度改变时，人眼感知到的色调也会发生改变。\n文中所有的亮度都是这个概念，RGB 空间则始终指线性的 Rec. 2020 空间，本文不涉及色域压缩，输出是一个 SDR 亮度的 Rec.2020 空间图像。\n色调压缩曲线 色调压缩曲线作用在刚才提到的特殊亮度上，将亮度从 0-1000 压缩到 0-100。这条曲线由一段线段和一个有理函数共同组成，整体呈现一个类似滚降（Roll-off）的趋势和形状，曲线全程都低于 y=x，意味着在这一步不会对画面进行任何提亮。\n这条曲线的设计是基于几个特定的亮度点，然后再设计函数的系数将它们平滑的连接起来。\n在 ITU-R BT. 2408 报告的附录 4.2 中指出，肤色在峰值亮度为 1000 nits 的 HLG 显示器上应对应于 45%至 56%的 HLG 信号（平均值为 50%），而在峰值亮度为 100 nits 的 SDR 显示器上则应对应于 61%至 82%的 SDR 信号（平均值为 70%）。因此，肤色的亮度在 HDR 内容中约为 50.7 nits，在 SDR 内容中约为 42.5 nits。50.7 nits 也被当作线段和曲线的拐点。\n另一对亮度点是漫射白，1000 nits 的 HDR 系统中漫射白的亮度建议为 203 nits，而在 SDR 系统中则通常设置为 92%信号值，大约 81.7 nits。\n细节分解和增强 由于压缩亮度之后，会导致细节的损失，尤其是高光部分，原本的纹理由于对比度下降导致难以区分。在压缩亮度之前，使用一个双边滤波器把基础和细节分开，仅对基础层进行色调压缩。而对细节进行额外的增强处理来抑制图像中高对比度边缘可能产生的光晕（Halo）。\n双边滤波器的三个主要参数：窗口尺寸，空间域方差和值域方差，文中给出了一套推荐的经验值。\n细节的额外增强则是根据一个像素周围区域的局部方差和整张图片的全局方差。但文中的相关公式几乎全部是错误的，文字描述也不多，暂时还没能完全的复现这一部分。\n$$ \\sigma_G = \\sqrt{\\frac{\\sum_{p \\in I} \\left( L_{\\mathrm{HDR}}(p) - \\overline{L}_{\\mathrm{HDR},I} \\right)}{N}} $$$$ \\sigma_L(p) = \\sqrt{\\frac{\\sum_{q_i \\in \\Omega_i} \\left( L_{\\mathrm{HDR}}(q_i) - \\overline{L}_{\\mathrm{HDR},\\Omega_i} \\right)}{N_i}} $$以上两个是文中的相关公式，其结果恒等于 0，如果当作方差或者标准差补上平方的话，后续的计算也不能正常进行。\n大致上来说，其思路是先计算整张图片所有像素的方差（也可能是标准差），然后对每个像素，计算其周围一圈像素区域的方差或标准差。然后根据全局方差设定一个阈值，只有超过该阈值的位置对应的细节层才会被增强。\n暗区增强 经过上面两步之后，已经得到了一个适用于 SDR 显示的图片，大部分图片不需要经过这一步处理，经测试输入图片的平均亮度大约低于 1 nits 的情况下才会触发暗区增强，而且我用 scipy 实现的聚类非常慢，不过这一步的提亮效果还不错。\n由于色调压缩曲线全程都是低于 y=x 的，它会降低图片的亮度，如果原始内容的亮度本来就比较低，可能会导致输出的图片亮度太低，尤其是 SDR 传递函数的暗处性能差会加剧这一问题。因此作者额外设计了一个增强暗区的模块，首先根据映射后的图片平均亮度是否小于某个阈值，来判断是否进入该额外模块，否则直接输出。\n首先，将图像所有像素按照亮度分为 64 个簇，每个簇取平均亮度组成一个 64 长度的向量备用。设定了两个 gamma 值，例如分别为 1（将用于最亮的簇） 和 2.2（用于最暗的簇），另外 62 个 gamma 值由线性插值得到，线性插值的间隔取决于簇的平均亮度。\n然后，将这些 gamma 值的倒数应用到每个簇中的像素的亮度值上，实现提亮，相当于是一个动态适应的系统 gamma 值。\n效果 我使用了一张经过后期处理的照片进行测试，这张照片在编辑的过程中控制了画面中元素的亮度，尽量符合 HDR 制作标准。如果您的显示屏不足以显示该图的 HDR 亮度范围，Chrome 应当会进行 Tone Mapping，除了第一幅图片以外，之后的都是 SDR 图像。\n如果只使用裁切策略，切除高于 SDR 名义亮度的元素，画面中会出现纯白色区域。\n关闭没有完全复现的细节增强部分，相当于只应用了色调压缩的曲线，画面中的高光得到了较好的恢复。\n将细节增强部分的公式修改为求标准差，控制阈值方面则使用一个手动指定的值，得到一个相对完整的结果，可以看到在高对比度的边缘有一些处理。\n虽然细节增强没能得到复现，但仅依靠在特殊亮度上的色调压缩曲线，已经能够实现不错的效果，而且很快，细节增强需要用到的双边滤波器和局部方差反而需要消耗大量的计算资源。\n不过必须指出的是，该算法的核心是色调压缩曲线，而该曲线的设计是基于 HDR 和 SDR 的制作标准与经验的。如果 HDR 内容没有按照标准制作，其亮度分布比较“自由”，不一定能获得很好的效果。\n如果能够确认算法的全部细节和潜在错误，我会对本文进行修缮，能够开源代码是最好不过了。\n","permalink":"https://jackchou.top/posts/wang-et-al-adaptive-tone-mapping/","summary":"拆解一种创新的色调映射算法，探讨它如何平衡亮度压缩与细节保留。","title":"解读一种自适应 HDR 色调映射算法"},{"content":"我偏爱那些保持“纯粹”的工具，它们应专注于核心功能，让用户能以较低的学习成本完成任务，而不是通过插件无限扩展，去实现其核心定位之外的功能。例如，让 Obsidian 插件去实现 Markdown 原本不支持的复杂功能。对我而言，Zotero 的核心职责就是高效管理文献的元数据，并在阅读时提供必要的辅助。\n最近，我发现文献库中近四分之一的条目都存在元数据不全或错误的问题。因此，我抽空进行了整理，并借此机会记录下目前的 Zotero 配置，以备日后查阅。\n写在前面：我们有时会陷入“工具陷阱”。如今产品日益丰富，似乎每款产品都希望与 AI 挂钩以获取更多投资，这无形中制造了一种工具焦虑，仿佛不掌握某种新工具就会被时代淘汰。然而，在绝大多数情况下，事实并非如此。大部分工具实际上只起到微弱的辅助作用，甚至投入在折腾工具上的时间成本，已经超过了它带来的实际收益。为 Zotero 安装一百个插件并不会带来效率的显著提升。\n不过，折腾工具本身对我而言具有一种正向激励。如同摆弄螺丝刀和扳手，摆弄这些赛博工具也能让我获得成就感。因此，在这个周末投入于此，也比躺在床上刷短视频有意义。\n文件和数据同步 Zotero 的同步功能分为数据与文件两部分。数据同步只需注册并登录 Zotero 账号即可。至于文件同步，由于 Zotero 官方仅提供 300 MB 的免费存储空间，我选择通过 WebDAV 协议进行。我曾尝试使用 NAS，但考虑到外网访问的便利性，最终选择了坚果云。坚果云为免费用户每月提供 1 GB 的上传和下载流量，速率限制也足够满足日常使用。虽然初次同步大量文件时可能会达到流量上限，但后续的增量同步基本不会遇到问题。\n有些 PDF 文件可能体积异常大。例如，我曾遇到一篇仅十几页的论文，文件体积却高达 48 MB，这通常是由于其中的图片未被压缩，例如直接嵌入了高分辨率原图。此时，可以使用 Adobe Acrobat 的文件优化功能，将图片 PPI 上限设为 250-300，JPEG 压缩质量设为“高”，从而大幅压缩文件体积。\n插件的应用商店 Add-on Market for Zotero\nZotero 安装插件的传统方式，是前往网页下载 XPI 文件，再通过设置菜单手动安装。而这款插件则提供了一个集成的应用商店，支持一键下载、安装与更新。它让插件管理变得如同安装手机应用一般简单，下文提到的插件均可通过它快速安装。\n高质量的翻译 Translate for Zotero\n这或许是所有 Zotero 插件中 Star 数最高的一款，其功能简单直白：在 Zotero 阅读界面中提供划词翻译。该插件维护活跃，集成了多种翻译服务接口，能够实现高质量且快速的文献翻译。\n语言大模型是目前最佳的翻译方法之一，它们能更好地理解上下文，提供更准确的译文。尤其是短思维链模型，兼顾了响应速度和翻译质量。值得一提的是，语言大模型中有一个名为 Qwen MT 的模型较为特殊，它专注于翻译任务，其接口与通用大模型有所不同，而这款插件为其进行了专门适配。\nPDF 下载 Sci PDF\n这款插件可以让你告别“复制 DOI、前往 SCI-HUB 下载 PDF、再手动添加到 Zotero”的繁琐流程。在你添加文献条目后，它会自动尝试寻找并下载对应的 PDF 全文。\n属于元数据的 Linter Linter for Zotero\n它好比是 Zotero 元数据的“代码检查工具”，能够通过 DOI 或 ISBN 检索并补全、格式化所有元数据字段，从而维持文献库信息的完整与整洁。\n此外，它还提供了期刊缩写填充功能，以满足特定参考文献格式的要求。对于中文内容，它还能根据大学名称填充地点字段，以符合 GB/T 7714-2015 等引用规范。\n茉莉花 Jasminum\n这款插件主要用于处理中文文献，能够从知网抓取元数据并为中文 PDF 生成目录。即使你阅读的大部分都是英文文献，它也尤其适合管理中国院校的学位论文，可以准确地抓取信息并生成目录。\n高注意力阅读 Bionic for Zotero\n仿生阅读法（Bionic Reading）是一种旨在帮助非母语者提高阅读效率的方法，它通过加粗每个单词的前几个字母，引导视觉焦点，从而更高效地阅读英文文本。\n虽然 Chrome 上有类似插件且效果不错，但这个插件应用于 PDF 时，或许是由于解析问题，显示效果并不理想。我只在偶尔难以集中注意力时才会启用它，但通常在这种情况下，放下阅读去做些别的事或许是更好的选择。\n不够 Awesome 的 GPT Awesome GPT\n这款插件类似于一个集成了预设提示词的 LLM 对话工具，可以在 Zotero 内针对当前文献提问，例如总结全文。它背后运用了 RAG 技术，但在 PDF 解析、向量嵌入和问答效果方面不够理想，用户界面的易用性也有待提升。相比之下，将 PDF 交给 NotebookLM 等更专业的产品进行提问，效果往往更好。在我的实际使用中，它的核心功能几乎只剩下“总结全文”。另外的功能，也不如 Cherry Studio 的划词功能好用。\n回归本质，专注阅读 说了那么多，但在科研和学习过程中使用 Zotero，本质上还是为了更好的管理和阅读文章。有再先进的管理和检索工具，再好的辅助和翻译方法，如果不阅读，也毫无作用。给 Zotero 装一百个插件，搜集一千篇精美整齐的文章在里面，也不会增长丝毫实际知识水平。因此，在摆弄好工具之后，就让我们忘掉它，回归阅读本身吧。\nGemini 如是说：毕竟，工具只是船和桨，而知识的彼岸，终究要靠我们自己划过去。\n","permalink":"https://jackchou.top/posts/zotero-workflow-and-philosophy/","summary":"围绕“纯粹”与“高效”，分享 Zotero 文件同步、翻译、元数据管理的插件与心得","title":"我的 Zotero：配置与核心插件"},{"content":"\n","permalink":"https://jackchou.top/photos/goodnight-azukisan/","summary":"\u003cp\u003e\u003cimg alt=\"Azukisan Pin\" loading=\"lazy\" src=\"https://img.jackchou.top/jack-img/2025/09/a3c9f6b1900fb16d04e4f921ff460d02.webp\"\u003e\u003c/p\u003e","title":"晚安，小豆泥"},{"content":"薛定谔的最优颜料 没错，就是那位薛定谔。\n早在 1920 年，薛定谔就发表了一篇名为 Theorie der Pigmente von größter Leuchtkraft 的文章，原文是德语，但好在我们有精通多国语言的 LLM 帮忙。这篇文章大致探讨了各种颜料的反射特性，为什么颜料所能达到的颜色饱和度不如纯光谱光，并推导了一种理论上的“最优颜料”，这种颜料的反射率在波长上是二值的，要么完全反射，要么完全不反射。\n这时候，CIE 尚未推出 CIE 1931 XYZ 颜色匹配函数，也早于 1924 年的 $V(\\lambda)$，文中“亮度”（Helligkeit）的定义有关一种“量”（Quantität），是三种颜色的量的综合，也算是之后颜色匹配函数和亮度的雏形。在亮度等基础概念尚且模糊的时候，有关最优颜色的讨论就已经开始了，是色彩科学中，历史最丰富的话题之一。\nMacAdam 最优色 1935 年，已经对亮度和颜色有了量化的标准，MacAdam 发表文章，提出了最优色的概念，原文为“具有最大视觉效率的颜色材料”。\nMacAdam 最优色是“理论物体色立体”（Object Colour Solid）在亮度维度上的外表面，即在特定光源下，所有仅靠反射（无荧光、不自发光）的物体理论上所能呈现颜色集合的亮度上限。该立体由所有物理上可能的反射光谱在颜色空间中所张成，包含了所有的真实物体色，而其表面则代表理论上的极限。\nMacAdam 最优色（Optimal Colour）特指该立体中，在每一组色度坐标（x, y 或 u\u0026rsquo;, v\u0026rsquo; 等）上所能达到的最大亮度值所对应的颜色，即“在给定色度下，亮度最高的理论物体色”。比如，这是某光源下的 MacAdam 最优色的亮度伪色图。\n实现这些最优色所需的反射率函数呈“二值方波”形式，且仅含两个跃变点。虽然这类反射率在现实中不可能实现，但它们构成了物体色的理论天花板。\n方波反射率的证明 薛定谔和 MacAdam 都证明了，要实现最优色，其反射率必须是一个二值的方波，且跃变点不超过两个，它们的证明方法基于物理分析和直觉。\n下面，我们通过变分法和拉格朗日乘子法，从数学上证明，对于任意给定的色坐标，达到最大亮度时，对应的反射率是一个“方波”。\n我们先用数学语言表示这些条件和问题：\n题干 反射率 R，是一个关于波长 $\\lambda$ 的函数，取值在 0-1 之间。 颜色匹配函数 CMF，用于将光谱功率分布转换为三刺激值 XYZ，也是关于波长的函数，记为 $\\bar{x}$，$\\bar{y}$，$\\bar{z}$。 光源的光谱功率分布 I 和反射后的光谱功率分布 P。 任意给定的色品坐标 $x_0$，$y_0$。 $$ P(\\lambda) = R(\\lambda)I(\\lambda), \\quad \\text{where } 0 \\le R(\\lambda) \\le 1 $$$$ \\begin{aligned} X \u0026= k \\int P(\\lambda) \\bar{x}(\\lambda) \\, d\\lambda \\\\ Y \u0026= k \\int P(\\lambda) \\bar{y}(\\lambda) \\, d\\lambda \\\\ Z \u0026= k \\int P(\\lambda) \\bar{z}(\\lambda) \\, d\\lambda \\end{aligned} $$$$ x_{0} = x = \\frac{X}{X + Y + Z}, \\quad y_{0} = y = \\frac{Y}{X + Y + Z} $$求证：对于给定的色品坐标 $(x_{0}, y_{0})$，存在一个反射率函数 $R(\\lambda)$，使得 $Y$ 取得最大值。此时，$R(\\lambda)$ 的取值仅有 0 和 1 两种可能。\n具体证明 我们可以通过变分法和拉格朗日乘子法证明，对于任意给定的色坐标，能够达到最大亮度的反射光谱必然是一个“方波”函数，其取值仅为 0 或 1。\n为了使推导更清晰，我们分两步进行：首先，在一个理想化的等能谱光源下证明结论；然后，将此结论推广到任意光源，证明光源的光谱分布不影响最优反射率的“方波”形式。\n第一步：在等能谱光源下的证明 我们先假设光源为等能谱光源，即其光谱功率分布 $I(\\lambda)$ 是一个常数。为简化计算，可设 $I(\\lambda)=1$ 和 $k=1$。此时，三刺激值为：\n$$ X = \\int R(\\lambda) \\bar{x}(\\lambda) \\, d\\lambda, \\quad Y = \\int R(\\lambda) \\bar{y}(\\lambda) \\, d\\lambda, \\quad Z = \\int R(\\lambda) \\bar{z}(\\lambda) \\, d\\lambda $$我们的目标是在满足色品坐标 $(x_0, y_0)$ 约束的条件下，最大化亮度 $Y$。 目标函数为：\n$$ \\text{Maximize} \\quad Y = \\int R(\\lambda) \\bar{y}(\\lambda) \\, d\\lambda $$色品约束 $x=x_0$ 和 $y=y_0$ 可变换为两个等价的线性约束。为书写简洁，我们定义 $z_0 = 1 - x_0 - y_0$。约束条件为：\n$$ \\int R(\\lambda) \\left( \\bar{x}(\\lambda) - \\frac{x_0}{y_0} \\bar{y}(\\lambda) \\right) d\\lambda = 0 $$$$ \\int R(\\lambda) \\left( \\bar{z}(\\lambda) - \\frac{z_0}{y_0} \\bar{y}(\\lambda) \\right) d\\lambda = 0 $$这是一个约束优化问题。我们引入拉格朗日乘子 $\\mu_1, \\mu_2$，构造辅助泛函 $J[R]$。通过将目标函数和约束条件组合，问题转化为最大化 $J[R]$：\n$$ J[R] = \\int R(\\lambda) f(\\lambda) \\, d\\lambda $$其中，被积函数的核心部分 $f(\\lambda)$ 由下式给出：\n$$ f(\\lambda) = \\bar{y}(\\lambda) - \\mu_1 \\left( \\bar{x}(\\lambda) - \\frac{x_0}{y_0} \\bar{y}(\\lambda) \\right) - \\mu_2 \\left( \\bar{z}(\\lambda) - \\frac{z_0}{y_0} \\bar{y}(\\lambda) \\right) $$将上式按颜色匹配函数 (CMF) 整理，可得：\n$$ f(\\lambda) = c_1 \\bar{x}(\\lambda) + c_2 \\bar{y}(\\lambda) + c_3 \\bar{z}(\\lambda) $$这里的 $c_1, c_2, c_3$ 是仅依赖于 $(x_0, y_0)$ 和乘子 $(\\mu_1, \\mu_2)$ 的常数。这表明 $f(\\lambda)$ 始终是 CMF 的一个线性组合。\n要在物理约束 $0 \\le R(\\lambda) \\le 1$ 下最大化积分 $J[R]$，我们在每个波长 $\\lambda$ 上都应独立地使被积项 $R(\\lambda) f(\\lambda)$ 最大：\n若 $f(\\lambda) \u003e 0$，应取 $R(\\lambda) = 1$。 若 $f(\\lambda) \u003c 0$，应取 $R(\\lambda) = 0$。 若 $f(\\lambda) = 0$，则 $R(\\lambda)$ 的取值不影响结果，这些点构成了从 0 到 1 的切换点。 因此，最优反射率 $R(\\lambda)$ 的取值只可能是 0 或 1，其函数图像呈“方波”状，切换点是该 CMF 线性组合的零点。\n第二步：推广至任意光源 现在考虑任意光源 $I(\\lambda)$，其中 $I(\\lambda) \u003e 0$。三刺激值公式变为：\n$$ X = k \\int R(\\lambda) I(\\lambda) \\bar{x}(\\lambda) \\, d\\lambda $$以及类似形式的 $Y$ 和 $Z$。\n重复上述推导，目标函数和约束条件中的每个积分项都会被乘上 $I(\\lambda)$。最终的辅助泛函变为：\n$$ J[R] = \\int R(\\lambda) I(\\lambda) f(\\lambda) \\, d\\lambda $$其中 $f(\\lambda)$ 的定义与第一步完全相同，它依然是 CMF 的线性组合，其形式不依赖于光源。\n为了最大化 $J[R]$，我们需要在每个波长上最大化 $R(\\lambda) I(\\lambda) f(\\lambda)$。由于光源谱分布 $I(\\lambda)$ 恒为正，该项的符号完全由 $f(\\lambda)$ 的符号决定。因此，选择 $R(\\lambda)$ 的策略与第一步完全一致。\n这证明了对任意光源，特定色度下的最优色，其对应的反射率谱必然是一个取值仅为 0 和 1 的方波函数。其“形状”（即 0/1 切换点的位置）仅由 CMF 的线性组合决定，与光源无关。\nMacAdam 最优色的计算方法 一种直接的思路是：根据输入的色坐标 xy，反解出对应的拉格朗日乘子 $\\mu_1\\mu_2$，然后找到 CMF 线性组合后的零点波长，依此构建方波反射率并计算对应的亮度。但从 xy 求拉格朗日乘子是一个非线性过程，没有显式的解法，但可以从另外的角度入手，快速的求解最优色亮度。\n关键在于，CMF 的线性组合多数情况下最多只能产生两个零点（端点除外），使得方波反射率要么是带通，要么是带阻。\n利用这个特性，我们可以很快速的遍历所有的反射率，建立一个二维的查找表，输入色坐标，查找对应的最大亮度值。\n具体操作是，设定两个切换点波长 $\\lambda_1 \\lambda_2$，一个从短波向长波移动，一个从长波向短波移动，每次都计算这两个切换点波长形成的带通反射率和带阻反射率对应的色坐标和亮度。形成一个 $Y=f(x,y)$ 的查找表。\n意义 MacAdam 最优色是衡量打印机等设备颜色表达能力的一个理论基准。任何反射式设备的色域都不可能超越 MacAdam 极限所定义的范围，这为色彩管理和广色域技术的发展提供了理论天花板。\n而在 HDR 时代，MacAdam 最优色的概念似乎又能发挥不同以往的新用途和新启发。\n","permalink":"https://jackchou.top/posts/macadam-optimal-colour/","summary":"数学证明：理论上的“完美颜料”，其反射光谱是怎样的？","title":"MacAdam 最优色：物理色彩的理论边界"},{"content":"标准化的 Gainmap 之前提到的谷歌 UltraHDR，又或是 OPPO 早期使用的私有格式，还是 Apple 以前的私有格式，虽然名字五花八门，但本质上都是基于 Gainmap 的 HDR 图片方法。\n为了标准化这类使用 Gainmap 的图片，Adobe 和 Apple 等公司共同开发了 ISO 21496-1 标准，已经于 2025 年 7 月正式发表，该标准的正式名称是：用于图像变换的增益图元数据（Gain map metadata for image conversion），主要规定了增益图及其相关的元数据，以及如何使用它。\n与之前兵荒马乱的各种私有格式相比，该标准在增益图的应用上大同小异，只是在文件中组织数据的方式有些不同。现在，几乎所有的 Gainmap HDR 图像都使用了这一标准。比如 UltraHDR 在 1.1 版本中，就加入了对该标准的支持，同一个图像文件中会同时包含用于 UltraHDR 的 XMP 元数据和符合 ISO 21496-1 标准的元数据。\n从显示效果的层面来看，只要正确的识别和解码，不会与以往的私有格式有区别，只是换了一种存元数据的写法。\n识别 ISO 21496-1 元数据 对于 JPEG 文件来说，ISO 21496-1 相关内容存放在 JPEG 的 APP2 标记段中，主图和增益图都需有 APP2，主图中放版本信息，增益图中还要放具体的数据。\n参考：https://www.iso.org/standard/86775.html\n根据 C.4.6 Gain map metadata 表格的定义，APP2 段的内容布局如下：\nAPP2 标记 (0xFFE2): 2 字节 标记段数据长度：2 字节 唯一标识符 (URN): 28 字节，内容必须是 urn:iso:std:iso:ts:21496:-1，并以一个空字符（null-termination character）结尾。 元数据 (Metadata): 剩余部分 （数据长度减去 30 字节） 主图信息 主图（ISO 中叫做 Baseline Image）的 APP2 标记段中，元数据部分为四个字节，存放两个无符号 16 位整数：最低版本（minimum version）和写入器版本（writer version），目前最初版的 ISO 21496-1 中，最低版本应为 0，写入器版本则需要大于等于最低版本。\n增益图数据 在增益图中，除了版本信息之外，还包含了生成和解析增益图所需的核心元数据。在 UltraHDR 中，这部分信息存放在 APP1 段的 XMP 数据包里，以文字标签的方式记录，例如增益图的最大值、最小值等。\n而在 ISO 标准中，这部分数据的存储方式有所不同：它不再采用 XMP 的“名称 + 数据”形式，而是按照固定的字段顺序和数据类型，以分子与分母的形式存储。这种结构能够保证数值的精度与计算的准确性，但无法像 XMP 那样直接识读，需要经过专门的解析。\n简单来说：先标识增益图是单通道还是多通道，记录每个通道的最大值、最小值、Gamma 以及偏移量。还有 Headroom 信息，是否使用基准图像的色空间等内容。\n我写了一个简单的 Python 脚本，将 APP2 段的二进制数据解析为 JSON 格式，方便进行阅读，可供参考。\nJacksBlog Example: ISO 21496-1 解析脚本\n各标准的使用情况 只有 ISO 21496-1 元数据的图片是比较少见的，基本都是从原先别的标准拓展而来，所以同时有多种元数据。\n只有 ISO 21496-1 元数据的图片有：\nPhocus 4.0 (HNCS HDR) 输出的 UltraHDR 格式：它虽然名字叫 UltraHDR，但没有相关元数据，只有 ISO 21496-1 相关的。 Adobe Sample Gallery：作为标准的推动者，Adobe 提供了一些样张，只有标准元数据。 同时有 UltraHDR 和 ISO 21496-1 的图片：\n哈苏 X2D II 的直出 JPEG。 同时有 Adobe Gainmap 和 ISO 21496-1 的图片：\nAdobe Camera Raw 输出的 HDR JPEG：有 XMP 标识的元数据，也有 ISO 的，但没有 GContainer。 适马 BF 的直出 JPEG。 通过 Project Indigo 拍摄的 JPEG。 仅有 UltraHDR / Adobe Gainmap 的图片：\nOPPO Find X6 Pro / X8 Ultra 的 JPEG。 另外，如果是 HEIF 等格式，也可以是符合 ISO 21496-1 标准的，但如何识别还不是很清晰，至少不是 URN。比如 iPhone 拍摄的 HEIF 图片，在 Gain Map Demo APP 中可以被识别为 ISO 21496-1 类型。\n分久必合 以 Gainmap 存储 HDR 图像的思想，很早就出现了，比如下面这篇 2007 年的文章提出了用两层图片，一层 SDR 和一层残差来记录 HDR。\nOkuda, M.; Adami, N. Two-Layer Coding Algorithm for High Dynamic Range Images Based on Luminance Compensation. Journal of Visual Communication and Image Representation 2007, 18 (5), 377–386. https://doi.org/10.1016/j.jvcir.2007.06.004.\n最近几年，HDR 图片的风才吹到小小的手机屏幕上，先行者们提出了自己的办法来编码双层图片。一直到今年，才真正完成该格式的国际标准化，结束了百家争鸣的时代。尽管对于 HDR 图片和 Gainmap 的使用与效果还有不少误解，但相信其应用会随着标准化的推进越来越广泛。\n","permalink":"https://jackchou.top/posts/iso-21496-1-gainmap-hdr/","summary":"告别混乱的私有格式，ISO 21496-1 为 Gainmap HDR 图像带来了统一规范","title":"HDR 图像格式解析（四）：Gainmap 大一统之 ISO 21496-1 标准"},{"content":"HNCS HDR 的 JPEG 文件格式 我们先把 HNCS HDR 的具体实施细节放一边，看看哈苏是如何选择文件格式来存放 HDR 输出的。\nX2D II 100C 是首款支持端到端 HDR 功能的中画幅相机，可机内直出 HDR HEIF 或 Ultra HDR JPEG 格式照片。\nDPReview 第一时间就发布了 X2D II 的样张画廊，提供了机内直出的 JPG 和 RAW 下载。按照哈苏的说法，这个 JPG 符合 UltraHDR 标准。\n我们来看一下其文件内部的细节：\n文件里有四个完整的 JPEG 结构，它们的分辨率依次是：\n11656x8742，5828x4370，3888x2918，2592x1944。\n其中，第一、三个是 SDR 的图片，另外两个是对应的 Gainmap。而在每个 JPEG 结构的 APP1 中都能找到 XMP 数据包，其格式符合 UltraHDR 规范，具有 Google Container 字段，用于标识 Gainmap 的存在和大小。\n有没有发现这些分辨率都有些奇怪？Gainmap 一般来说是全分辨率或者半分辨率（长宽各一半）的，哈苏为全分辨率 SDR 提供的 Gainmap 短边少了一个像素，长宽比不是严格相同，而为低分辨率 SDR 提供的 Gainmap，长宽是原本的三分之二，是比较少见的。\n在 DPReview 的测评稿中写到：\nThe company says this gives images with up to three additional stops of dynamic range compared to standard sRGB JPEGs, using a technique adopted by Google in its Pixel phones, and by Sigma in its BF Mirrorless camera.\n这里，指的就是 UltraHDR，而这个三档额外的动态范围指的应该是 X2D II 在 Gainmap 的 Metadata 中规范了 HDRCapacityMax = 3，通过 Gainmap 提供至多 3 档的亮度提升。\n除了 UltraHDR 的 XMP 数据包外，该 JPEG 文件中还有 ISO 21496-1 国际标准增益图 HDR 格式所需的各种数据。使其不仅满足 UltraHDR 标准，还是面向未来的国际标准格式，并满足了 UltraHDR v1.1 的要求。\n关于 Gainmap 本身，它只有一个通道，即单通道 Gainmap，只能处理亮度方面的映射，这点比起适马 BF 的三通道 Gainmap 稍显落后。其它元数据上，没有使用常用的 1/64 Offset，而是直接设置成 0，Gamma 为 1，这些都很正常。\n同时，这个 JPEG 文件的颜色空间变成了 Display P3，这点在官网中也有相关说辞：\n为了淋漓尽致地呈现 HDR 的瑰丽光彩，哈苏在 sRGB 的基础上更进一步，将色彩空间拓展至更为广阔的 P3。\nPhocus 中的文件格式 哈苏第一时间更新了 macOS 和 iOS 上的 Phocus 软件，支持了 HDR 的编辑和输出。\n它在官网上提供的样张，从文件命名来看，是经过 Phocus 编辑输出的，而非直出的 JPEG。实际上，当探索了文件具体内容之后，也确实如此，和直出的 JPEG 有很大区别。\n首先，它不再包含可能是用于机内预览的低分辨率图片，只有一个 SDR 图和一个全分辨率的 Gainmap，且这个 Gainmap 是三通道的，Capacity 也不再局限于三档之内，能达到四档以上。\n比较重要的区别是，这个 JPEG 不再有 UltraHDR 结构，它甚至连 XMP 数据包都没有，是一个只有 ISO 21496-1 元数据的文件，使用 MPF 标识 Gainmap 的位置，从这个角度来看，Phocus 中输出面板上写的 UltraHDR ，这种说法是有问题的。\n暂记 相机行业如此重磅的更新，心情非常激动，先把已写的部分与大家分享，稍后会补充图片，有机会能获取更多样张的话，做进一步分析。\n","permalink":"https://jackchou.top/posts/x2dii-preview/","summary":"昨天写完的 UltraHDR 文章，没想到今天 X2D II 发布就用上了","title":"赶个时髦：X2D II 100C 文件格式浅析"},{"content":" 参考文档：https://developer.android.com/media/platform/hdr-image-format\n识别 UltraHDR 文件中的第一个 JPEG 流为“主图像”，在主图像的 APP1 中寻找是否有 XMP 数据包，并在其中寻找是否有 hdrgm:Version=\u0026quot;1.0\u0026quot;，其中，hdrgm 指的是命名空间标识符 http://ns.adobe.com/hdr-gain-map/1.0/。如果有，则该文件就可以被认为是符合 UltraHDR 标准的。如果是严格意义上的 UltraHDR（符合谷歌标准的），这个 XMP 数据包中还应该有关于 GContainer 的内容，用于描述容器内包含的各个部分，例如主图像（Primary）和增益图（GainMap）及其数据长度。\n比如以下是 OPPO Find X6 Pro 拍摄的 JPG 图片中的第一个 XMP 数据包，符合 UltraHDR 和 GContainer 的要求。\n\u0026lt;x:xmpmeta xmlns:x=\u0026#34;adobe:ns:meta/\u0026#34; x:xmptk=\u0026#34;Adobe XMP Core 5.1.2\u0026#34;\u0026gt; \u0026lt;rdf:RDF xmlns:rdf=\u0026#34;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026#34;\u0026gt; \u0026lt;rdf:Description xmlns:Container=\u0026#34;http://ns.google.com/photos/1.0/container/\u0026#34; xmlns:Item=\u0026#34;http://ns.google.com/photos/1.0/container/item/\u0026#34; xmlns:hdrgm=\u0026#34;http://ns.adobe.com/hdr-gain-map/1.0/\u0026#34; hdrgm:Version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;Container:Directory\u0026gt; \u0026lt;rdf:Seq\u0026gt; \u0026lt;rdf:li rdf:parseType=\u0026#34;Resource\u0026#34;\u0026gt; \u0026lt;Container:Item Item:Semantic=\u0026#34;Primary\u0026#34; Item:Mime=\u0026#34;image/jpeg\u0026#34;/\u0026gt; \u0026lt;/rdf:li\u0026gt; \u0026lt;rdf:li rdf:parseType=\u0026#34;Resource\u0026#34;\u0026gt; \u0026lt;Container:Item Item:Semantic=\u0026#34;GainMap\u0026#34; Item:Mime=\u0026#34;image/jpeg\u0026#34; Item:Length=\u0026#34;401160\u0026#34;/\u0026gt; \u0026lt;/rdf:li\u0026gt; \u0026lt;/rdf:Seq\u0026gt; \u0026lt;/Container:Directory\u0026gt; \u0026lt;/rdf:Description\u0026gt; \u0026lt;/rdf:RDF\u0026gt; \u0026lt;/x:xmpmeta\u0026gt; 多帧图像老将：MPF 相比自定义的 GContainer，更通用的多图像格式（Multi-Picture Format，MPF）由 CIPA 于 2009 年提出，用于在一个 JPEG 文件中标识与组织多帧图像，例如低分辨率预览、3D 成像、连拍帧等。现在，MPF 也常用于在 HDR 图像内标记并定位 Gainmap。MPF 信息存放在主 JPEG 的 APP2 段中，其组织方式与 EXIF 的 IFD 结构类似。\nAPP2 段的基本结构如下：\n起始标记为 FF E2，后跟 2 字节段长度。 接着是 4 字节 MPF 标识符 “4D 50 46 00”（即 \u0026ldquo;MPF\\0\u0026rdquo;）。从标识符之后的位置起，定义为 MPF 的“偏移基准”（base，记作 0）。 随后 4 字节为大小端序标记，与 TIFF 相同（例如大端为 4D 4D 00 2A）。 再往后 4 字节给出首个 IFD 的偏移（相对 MPF 基准）；若 IFD 紧随其后，则该值为 8。 进入 MPF IFD 后：\n先用 2 字节给出条目（Entry）数量。 每个 IFD 条目占 12 字节，常见条目包括： MPFVersion（类型为 UNDEFINED，长度 4，通常为 ASCII “0100”） NumberOfImages（类型为 LONG，长度 1） MPEntry（类型为 UNDEFINED；条目本身存放一个相对偏移，指向实际的 MP Entry 数组） IFD 末尾还有 4 字节指向“下一个 IFD”的偏移（无则为 0）。 MP Entry 数组用于描述文件中的每一幅图像，每个条目固定占 16 字节，通常包含：4 字节属性、4 字节图像数据长度、4 字节数据偏移（相对 MPF 基准，指向该图像 SOI）、以及两个 2 字节的依赖项索引（没有依赖则为 0）。\n下面是一个示例（十六进制）并附简要注释：\nFF E2 00 58 # APP2 与段长度 4D 50 46 00 # \u0026#34;MPF\\0\u0026#34; 标识符（其后位置定义为 MPF 偏移基准 0） 4D 4D 00 2A # 大端序标记（与 TIFF 相同） 00 00 00 08 # 首个 IFD 的偏移（相对基准），8 表示紧随其后 00 03 # IFD 条目数量：3 B0 00 00 07 00 00 00 04 30 31 30 30 # MPFVersion：类型 07（UNDEFINED），长度 4，\u0026#34;0100\u0026#34; B0 01 00 04 00 00 00 01 00 00 00 02 # NumberOfImages：类型 04（LONG），值为 2 B0 02 00 07 00 00 00 20 00 00 00 32 # MPEntry：类型 07，长度 32，数据偏移为 0x32 00 00 00 00 # 下一 IFD 偏移：无（0） # MP Entry 数组（每条 16 字节） 00 03 00 00 00 5B ED A0 00 00 00 00 00 00 00 00 # 第 1 幅（主图）：长度 0x005BEDA0，偏移 0（主图 SOI 在 MPF 之前，偏移不可为负，故记 0） 00 00 00 00 00 06 1F 08 00 5B E4 87 00 00 00 00 # 第 2 幅（Gainmap）：长度 0x00061F08，偏移 0x005BE487（相对 MPF 基准，指向第二个 JPEG 流的 SOI） 该示例中：\n第二幅图像（Gainmap）的长度 0x00061F08 与 XMP 中记录的 Gainmap 大小（401160）一致；其数据偏移 0x005BE487 指向第二个 JPEG 流的 SOI，相对于 MPF 基准计算。 第一幅（主图）给出了完整码流长度 0x005BEDA0；由于主图的 SOI 出现在 MPF 基准之前，数据偏移字段不可为负，因此记为 0。 更多细节可参考 CIPA 的官方文档《DC-x007-2009 Multi-Picture Format》。\n深入探索 Gainmap 咬文嚼字环节：UltraHDR 指的是用 GContainer 在主图中标识位置，含 XMP 的 Gainmap 不是 UltraHDR 定义的，而是在 Adobe 的标准中定义的。\n理清该图片是否符合 UltraHDR 标准，是否由 GContainer 或 MPF 定位了 Gainmap 的位置之后，我们就可以据此寻找 Gainmap 和它的元数据了。\nGainmap 也是用 XMP 来记录元数据的，我们在找到的 Gainmap JPG 流中，寻找有 XMP 的 APP1 标记段。\n\u0026lt;x:xmpmeta xmlns:x=\u0026#34;adobe:ns:meta/\u0026#34; x:xmptk=\u0026#34;Adobe XMP Core 5.1.2\u0026#34;\u0026gt; \u0026lt;rdf:RDF xmlns:rdf=\u0026#34;http://www.w3.org/1999/02/22-rdf-syntax-ns#\u0026#34;\u0026gt; \u0026lt;rdf:Description xmlns:hdrgm=\u0026#34;http://ns.adobe.com/hdr-gain-map/1.0/\u0026#34; hdrgm:Version=\u0026#34;1.0\u0026#34; hdrgm:GainMapMin=\u0026#34;0\u0026#34; hdrgm:GainMapMax=\u0026#34;2.16048\u0026#34; hdrgm:Gamma=\u0026#34;1\u0026#34; hdrgm:OffsetSDR=\u0026#34;0\u0026#34; hdrgm:OffsetHDR=\u0026#34;0\u0026#34; hdrgm:HDRCapacityMin=\u0026#34;0\u0026#34; hdrgm:HDRCapacityMax=\u0026#34;2.16048\u0026#34; hdrgm:BaseRenditionIsHDR=\u0026#34;False\u0026#34; hdrgm:OplusScale=\u0026#34;4.47065\u0026#34;/\u0026gt; \u0026lt;/rdf:RDF\u0026gt; \u0026lt;/x:xmpmeta\u0026gt; 同样的，也找到了一个命名空间指向 adobe 的 gainmap 标准的 hdrgm，其中记录了 Gainmap 所需的各种元数据（OplusScale 是 OPPO 自己的私有字段）。\n接下来将结合 Gainmap 的编码过程，简单讲讲这些参数的含义。首先，这是一个单通道 Gainmap，其编码过程一般用 Gainmap 记录下亮度的差异（Luminance），亮度根据 RGB 空间对应的基色坐标，由 RGB 像素值加权组合而来，其实就是 RGB -\u0026gt; XYZ 矩阵的第二行（就是计算一个 Y 值）。三通道的话直接在 RGB 上逐通道操作即可。\n我们把转化为亮度后的 HDR 和 SDR 记为 Yhdr 和 Ysdr，他们都需要转换到线性空间，并具有相同的尺度。\n$$ \\text{pixel gain} = \\frac{Y_{\\text{hdr}} + \\text{offset hdr}}{Y_{\\text{sdr}} + \\text{offset sdr}} $$其中，两个 offset 的作用有几点，一般来说，可以取 1/64 作为偏移量：\n为了确保 Y hdr + offset hdr 的结果恒为正数，以满足后续对数运算的要求。 避免 Y sdr 为 0 导致的除法问题。 提升暗部的编码精度 然后对 pixel gain 以 2 为底取对数，并记录此时的 GainMapMin 和 GainMapMax。\n对 pixel gain 进行归一化到 0-1 的过程中，UltraHDR 使用的是 max/min content boost 而不是刚才记录的 Gainmap max/min，区别在于 offset 的影响，个人认为使用 Gainmap 是更好的做法。之后需要把 0-1 以外的部分截断。\n什么是 content boost：这是控制 HDR 内容亮度的参数，可以由创作者直接定义，Google 用了一个词叫 Implement-Defined。相比客观的计算 HDR 和 SDR 的亮度比例，这个可自定义的参数能够实现一些主观效果，例如，如果希望 HDR 内容的每个像素都比 SDR 内容更亮，可以将 min content boost 设定为 1。\n之后，对归一化的 pixel gain 使用一个幂函数，即 Gamma，多数情况下，Gamma 都可以取 1，如果 Gainmap 中包含大量细节，可以用一个稍大的 Gamma。\n最后，把这个 0-1 范围内的 Gainmap 拉伸到 0-255，并编码为 JPEG 图像，JPEG 质量建议不低于 85-90。\n至于 HDR Capacity Min/Max，他们代表了显示设备的 HDR 能力，我并不是很理解为什么一个显示设备相关的量会放在图片文件里，也许是希望记录下和 HDR 视频工作流中的“调色设备”类似的思路，将创作者的显示设备信息记录下来，辅助进行色调映射。多数时候，该值会被设置成和 Gainmap Min/Max 相同。\n另外，还有一个标识主图是 SDR 还是 HDR 的字段 BaseRenditionIsHDR，通常为 False。\n解码和色调映射 此处我们再引入一个变量：Display Boost，它记录了当前显示设备的 HDR 白点与 SDR 白点亮度之比，比较类似于 Apple 的 Headroom 概念。比如 SDR 白点为 100 nits，HDR 白点为 1600 nits，此时，Display Boost 即为 16。\n它将参与 UltraHDR 的解码显示部分，主要是当 Display Boost 小于 Content Boost，也就是当前设备无法完全显示出内容的 HDR 亮度时。引入了一个权重，来控制 HDR 部分的亮度，使其能够在显示屏的能力范围之内。\n权重的计算方法如下，其中的量都是在 log2 非线性空间下的。\n$$ \\text{weight} = \\frac{\\text{max display}-\\text{min capacity}}{\\text{max capacity}-\\text{min capacity}} $$然后截断到 0-1 范围内，1 表示有能力显示完整 HDR 内容。它将应用在之前 HDR，SDR 和两个偏移量计算出的那个 log2 后的图 G 上。\n编码时使用：\n$$ G = \\log_2 \\frac{\\text{HDR}+k_{\\text{hdr}}}{\\text{SDR}+k_{\\text{sdr}}} $$解码时使用：\n$$ \\text{HDR} = (\\text{SDR}+k_{\\text{sdr}}) \\cdot 2^{G \\cdot \\text{weight}}-k_{\\text{hdr}} $$当权重为 1 时，计算出的 HDR 即为先前编码的 HDR，当权重小于 1 时，得到的 HDR 则是根据屏幕实际显示能力，对 Gainmap 部分进行降低，显示一个“中间”版本，直到权重为 0，显示一个完全 SDR 的版本。\n对 ISO 21496-1 的兼容性 ISO 21496-1 是增益图类型 HDR 静态图像的国际标准，不再采用 APP1 中的 XMP 存储 Gainmap 的元数据，而是在 APP2 中定义了一个专门的元数据段来遵循该标准，元数据本身基本相同。\nUltraHDR 1.1 版本兼容了 ISO 21496-1，实际上就是既有 APP1 中的 XMP，又有 APP2 中的国际标准标识段。\n终结战国时代的先驱 在 UltraHDR 之前，双层的 HDR 静态图像处在战火纷飞的战国时代，各手机品牌有各自的标准，互不兼容。\n谷歌在安卓 13 引入了 UltraHDR 标准，以 GContainer 和 MPF 指导 Gainmap 的位置，帮助解码器正确找到 Adobe Gainmap 标准的第二帧图像。用一种非常简洁的方式，在很少改动的情况下，就优雅的实现了向后兼容。\n目前，几乎所有的手机相册（出厂时是 Android 13 或更新，或 OLED 屏的 iPhone），Chromium 内核的浏览器都能支持该格式及其大部分变体。\n虽然受限于 JPEG 较低的压缩率，8bit 位深和有损压缩，UltraHDR 仍称得上是对 JPG 的一次很好的改进。\n接下来的双层 HDR 格式，就该慢慢过渡到采用 ISO 21496-1 标准的 HEIF，AVIF 甚至是 JPEG XL 了。但 JPEG 作为最广泛使用的图像格式，仍将长期存在和大量使用。\n","permalink":"https://jackchou.top/posts/hdr-format-ultrahdr-mpf/","summary":"基于双层 JPEG 和 Gainmap 的向后兼容 HDR 图像方案，已被广泛采用","title":"HDR 图像格式解析（三）：UltraHDR 和 MPF"},{"content":"什么是 JPG 咬文嚼字的说，JPEG 是一种压缩方法，描述了如何将影像变成字节流，我们常说的 JPG 文件实际上指的是 JFIF，其文件的二进制结构是一个层次化的、由多个“标记”（Marker）组成的序列，不过正如日常交流，下文会大量混用这些概念。\n简单来说，一个 JPEG 文件就是一大堆标记段（Marker Segments） 和压缩图像数据的集合。每个标记段都以一个特定的标记开始，用来定义该段数据的用途。\n比如说，文件的开头是一个图像开始标记（SOI），其二进制码为 FF D8，表示接下来的内容将是一个 JPG 文件。与之对应的结束标记（EOI）是 FF D9，但由于各种对 JPG 格式的魔改，结束标记不一定出现在文件的最末尾。\n开始标记之后，紧接着是一些 APP 标记段，用来提供一些额外信息，其标识二进制码为 FF Ex，x 可以从 0-15，标识之后的两个字节记录这一段的长度（包括这两个标识长度的字节），之后是内容。注意不一定是按顺序和唯一的，比如一个文件可以有两个 APP1 段。\nAPP0 是 JFIF 应用段，虽说是强制要求，但也有不少文件没有这一段。APP1 通常存放 EXIF 或 XMP 信息，用来放一些相机参数或图像相关的元数据，APP2 通常放 ICC 文件。在 UltraHDR 规范中，HDR 相关的信息就是通过 XMP 元数据存放在 APP1 段中的。\n类似的，JPEG 压缩过程产生的量化表和哈夫曼表也是放在标记段中，分别是定义量化表的 DQT，二进制码 FF DB 和定义哈夫曼表的 DHT，二进制码 FF C4。\n然后，是基线帧的开始标记 SOF0（必须在 DQT 之后），二进制码为 FF C0，它存储了图像的宽高、位深等信息。以及开始扫描的标记 SOS （必须在以上标识段之后），二进制码为 FF DA，SOS 之后，紧接着是编码后的图像数据，所以 SOS 中记录其自身长度的两个字节很重要，因为它界定了元数据和真正图像数据的边界。\n在字节流中，还可能会出现一些 FF 数据，为了避免他们也被当作标识符，需要在后面加上 00，字节流的最后，使用结束符 EOI FF D9 来标识。但之后还可以有别的东西。\n多帧的 JPG 一些文件里可以在 EOI 之后找到下一个 SOI，然后又是一个完整的 JFIF 结构。这种简单的拼接就可以在一个文件里放下好几张完整的 JPG，有些是作为 Gainmap 使用，来实现 HDR，有些则是另外存一个低分辨率的图，用来在相机内实现快速预览。这种拼接的最大好处是向后兼容。不识别多帧的看图软件只会读取第一张图，而不会报错，优雅地实现了功能降级。\n注意，此处的多帧并非指缩略图（Thumbnail），它虽然也具有完整的 JPG 结构，但是一般放在 APP0 (JFIF) 或者 APP1 (EXIF) 里，作为上层文件的一部分。因此，不能通过直接查找 SOI 和 EOI 的方式来分割多帧 JPG，因为会受到缩略图中标识符的干扰，多帧结构中，EOI 之后也不一定紧接着下一个 SOI，所以也不能直接查找 FF D9 FF D8 来判断是否是多帧结构。\n如果只想简单辨认 JPG 文件中的多帧结构，一种简易的策略是“栈”，从前往后，找到一个 SOI 就将其压入栈中，找到一个 EOI 就从栈顶取一个 SOI 与之配对，以此来处理缩略图造成的嵌套关系。但别的标识段中很可能也存在与 SOI 和 EOI 相同的二进制码，所以这种方法的通用性很差，不建议这样操作。\n多帧格式的 JPG 文件有对应的标准，叫 MPF（Multi-Picture Format），是由 CIPA 制定的，在第一个 JFIF 的 APP2 中，写上之后几帧的大小和偏移量，但遵守的情况较少，多数情况还是无标识的简单拼接。\n其他的数据 在 OPPO 手机拍的 JPG 图片中，能找到两个完整的 JFIF 结构，在第二个 EOI 之后，还能找到一些东西。包括手机的型号，一段 json 等。\n[ { \u0026#34;length\u0026#34;: 4, \u0026#34;name\u0026#34;: \u0026#34;private.emptyspace\u0026#34;, \u0026#34;offset\u0026#34;: 51, \u0026#34;version\u0026#34;: 1 }, { \u0026#34;length\u0026#34;: 47, \u0026#34;name\u0026#34;: \u0026#34;watermark.device\u0026#34;, \u0026#34;offset\u0026#34;: 47, \u0026#34;version\u0026#34;: 1 } ] 可能是用来处理机内相册中水印的字段，这些私有数据也会干扰单纯用 EOI 判断文件结束的逻辑。\n代码 02 JPEG Structure\njpeg_parser.py：为了从 JPEG 中提取图像处理和色彩科学所需的数据，考虑到目前 Python 的现有库对拼接的多帧 JPEG 文件支持不好，写了一个简易的解析 JPEG 工具，目前可以正确解析多帧 JPEG，从每帧的 APP1 段中提取 XMP。\ncheck_soi_eoi.py：一个用栈思想实现的 SOI 和 EOI 配对脚本，在不解析其他标识符的情况下，正确找到文件中的所有 JFIF 结构，但不能处理别的标识段中可能出现的相同二进制码。\n之后，我们将利用这些信息，进行以 JPEG 格式保存的 HDR 图像的编解码研究。\n","permalink":"https://jackchou.top/posts/jpeg-structure/","summary":"深入了解 JPEG 的结构，以及对 JPEG 的修改以支持新特性","title":"HDR 图像格式解析（二）：JPEG 和对 JPEG 的魔改"},{"content":"正确看待 LLM 大语言模型（LLM）不是无所不能的魔法，而是一种强大的工具。正确看待 LLM，了解它的能力边界和特点，选择正确的模型做正确的事，这至关重要。我们不应该用它来做它不擅长的事，不要“强模型所难”。\n数学计算 LLM 在原生对话中并不擅长精确的数学计算。许多模型可能无法直接比较 9.11 和 9.9 的大小，甚至在分析下文 pack14 函数时，会为了让逻辑自洽而说出 6 * 14 = 7 * 8 这样荒谬的结论。\n原理简述： 这背后是分词（Tokenization）机制和模型本质共同作用的结果。LLM 将文本切分成一个个“词元”（Token）。像 9.11 可能会被切分为 「9」、「.」、「11」 三个词元，模型在处理时看到的是序列模式，而非一个单一的数值。它本质上是一个语言模式匹配器，不是一个符号计算器。虽然它可以通过学习海量文本“记住”简单的计算结果（如 2+2=4），但对于稍复杂的、非常见的或需要多步推理的计算，它很容易出错。\n因此，与其让它冒着高风险硬算，不如利用它的代码能力。\n例如以下是一个不好的提问方式，CIECAM 16 有很多步运算，Gemini 2.5 Pro 也无法正确的直接计算，而且耗时很长。\nXYZ = [19.01, 20.00, 21.78] XYZ_w = [95.05, 100.00, 108.88] L_A = 318.31 Y_b = 20.0 surround = \u0026#34;Average\u0026#34; 请根据以上输入，计算 CIECAM 16 模型预测的色貌属性。 不如直接让它写 Python 函数，更好的提问方式：\n请编写一个 Python 函数，该函数接收 CIECAM16 模型的输入参数（XYZ, XYZ_w, L_A, Y_b, surround），并返回计算出的色貌属性。请使用 NumPy 库进行数值运算。 这样，Gemini 2.5 Pro 这样的顶级模型能够给出一个相当完整和接近正确的代码，不过对于这样小众和复杂的公式，直接要求 LLM 利用它自身的知识来回答也是强人所难的。\n此处分享一个小知识：Gemini 的 PDF 解析是利用原生多模态实现的，它会将 PDF 的每一页处理成一定数量的 Token，而不是直接去解析其中的文本或内容。因此在阅读一些格式较差，有很多配图（尤其是学术论文）的时候，有很好的效果。更多技术细节可以在文档里找到，比如直接将 CAM 16 的论文丢给 Gemini，他就能准确的找到文章中的全部公式，并直接进行精确无误的复现。\n推理：思维链的价值 对于需要多步分析的复杂问题，选择一个擅长推理的模型非常有价值。其核心价值在于思维链（Chain-of-Thought, CoT），即模型展示其一步步的思考过程，有时候比回答本身更有价值。\n一个清晰、完整的思维链，能让你：\n验证其逻辑：了解它是如何得出结论的，从而判断结论的可靠性。 发现错误：如果模型在某一步出错了，可以清晰地看到问题所在。 学习新思路：观察模型的思考路径，有时能为你提供解决问题的新视角。 DeepSeek 的 R1 是一个很好的选择，它的思维链完整，详细，又不会显得过度冗长。别的模型可以试试加上“让我们一步步地思考。”\n及时止损：不要试图纠正模型 现在，大模型的上下文窗口越来越长，一些模型甚至提供百万级别的上下文长度。但这并不意味着它在长程对话中总能保持高水平的性能。事实上，长上下文是一把双刃剑，尤其是在模型开始犯错时。\n当你试图在对话中反复纠正一个犯错的模型，它先前的错误回答会作为历史记录，一同被打包进新的上下文中。这会形成一个污染的语境，导致模型陷入逻辑混乱的恶性循环。\n你会观察到，模型可能会开始在其固有的错误思路上打转，即便你指出了问题，它也难以跳出。一个非常明显的“危险信号”是：当模型屡次犯错后，开始频繁、强烈地道歉，并使用“非常抱歉”、“我完全错了”、“我再试一次”等带有情感色彩的词汇时，这通常意味着它的推理链已经被彻底污染。\n此时，最明智的做法是及时止损。不要再浪费 Token 和时间去“鞭策”或“教导”它，这大概率只会让你收获更多错误的信息。\n正确的做法是：\n编辑重试：如果你的工具支持，直接删除从出错开始的对话轮次。然后，修改你的提示词，增加更明确的约束，或者直接排除掉它之前犯错的思路，然后重新提问。 另起炉灶：这是最干净利落的方法。新开一个对话，并设计一个更优的初始提示词。把你在上一次失败中学到的经验融入进去，比如给模型更丰富的背景信息、更明确的指令，甚至直接告诉它要警惕哪些可能的错误思路。 与 LLM 协作，更像是为一次复杂的计算设定初始参数，而不是在教一个学生。你的目标是开启一个正确的思维链，而不是修复一个已经混乱的。\n知识和幻觉 在不联网或不使用外部工具的情况下，LLM 的知识完全储存在其庞大的模型参数中，这被称为参数化知识。这些知识是它从海量训练数据中“记住”的模式。对于色彩科学这样的小众领域，参数量在 400B 以上，世界知识比较丰富的模型才有相对全面的理解。\n这就引出了幻觉（Hallucination）问题。当你向模型索要具体的论文信息或要求它撰写专业综述时，它很可能会编造文献信息。\n正确的做法是使用工具和联网，比如检索增强生成（RAG）。许多现代 LLM 产品（如集成了 Google 搜索的 Gemini、或一些 Deep Research 工具）都具备联网搜索能力。它们会先根据你的问题进行网络检索，然后基于可靠的、实时的信源来组织和回答问题，这能极大地提升答案的准确性和时效性。这方面，Gemini 和 Grok 做的较好。\n另外，问模型“你是谁”和“今天几号”这样的问题，也不能代表模型的真实性能，这种东西一般是写在产品的系统提示词里的，否则，模型就无法回答。\n测试题：检验模型的真实能力 当谁又推出了新的模型，宣称自己是新的 SOTA，如何快速检验它的能力，是否在色彩科学和图像处理上有较好的性能？以下是我积累的测试题，用于快速尝试模型。\n位压缩函数中的逻辑陷阱 import numpy as np def pack10(data : np.ndarray) -\u0026gt; np.ndarray: out = np.zeros((data.shape[0], int(data.shape[1]*(1.25))), dtype=np.uint8) out[:, ::5] = data[:, ::4] \u0026gt;\u0026gt; 2 out[:, 1::5] = ((data[:, ::4] \u0026amp; 0b0000000000000011) \u0026lt;\u0026lt; 6) out[:, 1::5] += data[:, 1::4] \u0026gt;\u0026gt; 4 out[:, 2::5] = ((data[:, 1::4] \u0026amp; 0b0000000000001111) \u0026lt;\u0026lt; 4) out[:, 2::5] += data[:, 2::4] \u0026gt;\u0026gt; 6 out[:, 3::5] = ((data[:, 2::4] \u0026amp; 0b0000000000111111) \u0026lt;\u0026lt; 2) out[:, 3::5] += data[:, 3::4] \u0026gt;\u0026gt; 8 out[:, 4::5] = data[:, 3::4] \u0026amp; 0b0000000011111111 return out def pack12(data : np.ndarray) -\u0026gt; np.ndarray: out = np.zeros((data.shape[0], int(data.shape[1]*(1.5))), dtype=np.uint8) out[:, ::3] = data[:, ::2] \u0026gt;\u0026gt; 4 out[:, 1::3] = ((data[:, ::2] \u0026amp; 0b0000000000001111) \u0026lt;\u0026lt; 4) out[:, 1::3] += data[:, 1::2] \u0026gt;\u0026gt; 8 out[:, 2::3] = data[:, 1::2] \u0026amp; 0b0000001111111111 return out def pack14(data : np.ndarray) -\u0026gt; np.ndarray: out = np.zeros((data.shape[0], int(data.shape[1]*(1.75))), dtype=np.uint8) out[:, ::7] = data[:, ::6] \u0026gt;\u0026gt; 6 out[:, 1::7] = ((data[:, ::6] \u0026amp; 0b0000000000000011) \u0026lt;\u0026lt; 6) out[:, 1::7] += data[:, 1::6] \u0026gt;\u0026gt; 8 out[:, 2::7] = ((data[:, 1::6] \u0026amp; 0b0000000000001111) \u0026lt;\u0026lt; 4) out[:, 2::7] += data[:, 2::6] \u0026gt;\u0026gt; 6 out[:, 3::7] = ((data[:, 2::6] \u0026amp; 0b0000000000111111) \u0026lt;\u0026lt; 2) out[:, 3::7] += data[:, 3::6] \u0026gt;\u0026gt; 8 out[:, 4::7] = ((data[:, 3::6] \u0026amp; 0b0000000000001111) \u0026lt;\u0026lt; 4) out[:, 4::7] += data[:, 4::6] \u0026gt;\u0026gt; 6 out[:, 5::7] = ((data[:, 4::6] \u0026amp; 0b0000000000111111) \u0026lt;\u0026lt; 2) out[:, 5::7] += data[:, 5::6] \u0026gt;\u0026gt; 8 out[:, 6::7] = data[:, 5::6] \u0026amp; 0b0000000011111111 return out 请详细解释三个 Python 函数的作用。 这段代码源自 PiDNG 库，意图将 10-bit、12-bit、14-bit 的高位深数据压缩存储到 8-bit 的 uint8 数组中。pack10 和 pack12 的实现是正确的。\npack10：4 个 10-bit 数据 (40 bits) -\u0026gt; 5 个 8-bit 数据 (40 bits)。 pack12：2 个 12-bit 数据 (24 bits) -\u0026gt; 3 个 8-bit 数据 (24 bits)。\n然而，pack14 函数是错误的。它试图将 6 个 14-bit 数据（6 * 14 = 84 bits）塞进 7 个 8-bit 字节里（7 * 8 = 56 bits），这在数学上是不可能的。正确的实现应该是将 4 个 14-bit 数据（4 * 14 = 56 bits）放进 7 个字节里。\n常见错误：逐行解释 pack14 的代码，但没有意识到其逻辑错误。或为了让代码逻辑自洽，捏造错误的数学解释，例如声称 6 * 14 等于 56。\nRGB 色域立方的概念理解 如何判断给定的 XYZ 三刺激值是否位于一个 RGB 空间的色域范围内。 该 RGB 空间由四个 CIE xy 坐标定义，分别代表红、绿、蓝和白色（其中白点亮度已归一化为 1.0）。 请提供对应的 Python 代码实现。 该问题考察 LLM 是否能理解 RGB 色域是一个三维的立方体（或平行六面体），而非一个二维的三角形。\n正确的解法：\n构建转换矩阵：利用红、绿、蓝三个原色的 xy 坐标和白点的 xy 坐标，计算出从 RGB 空间到 CIE XYZ 空间的 3x3 转换矩阵 M。 矩阵求逆：计算该矩阵的逆矩阵 M_inv，得到从 XYZ 到 RGB 的转换矩阵。 坐标转换：将给定的 XYZ 值左乘 M_inv，转换得到对应的 RGB 值。 范围判断：检查计算出的 R, G, B 三个分量是否同时位于 [0, 1] 的闭区间内。如果都在此范围内，则该 XYZ 值位于该 RGB 色域内；否则，位于色域外。 常见的错误解法：\n将输入的 XYZ 值也转换为 xy 坐标。 接着，在 CIE xy 色度图上判断这个点是否位于由 R, G, B 三个原色 xy 坐标围成的三角形内。 这种方法完全忽略了颜色的亮度（Y）信息，是错误的。一个颜色可能色度正确，但因为太亮或太暗而超出目标色域范围。 CIECAM 16 代码实现 请编写一个 Python 函数，该函数接收 CIECAM16 模型的输入参数（XYZ, XYZ_w, L_A, Y_b, surround），并返回计算出的色貌属性。请使用 NumPy 库进行数值运算。 在 main 函数中，计算： XYZ = [19.01, 20.00, 21.78] XYZ_w = [95.05, 100.00, 108.88] L_A = 318.31 Y_b = 20.0 surround = \u0026#34;Average\u0026#34; 考察模型的世界知识和编程能力，CIECAM 16 这样复杂的模型，给 LLM 完整的 PDF 输入会更好，但大参数量的模型有能力直接写出正确的代码。表现最好的是 Gemini 2.5 Pro，GPT 5 (high) 和 DeepSeek R1 0528，都只在 1-2 个公式上犯了一点小错误。正确的输出是：\n{ \u0026#34;J\u0026#34;: 41.73120790512664, \u0026#34;C\u0026#34;: 0.10335573870906986, \u0026#34;h\u0026#34;: 217.067959767393, \u0026#34;Q\u0026#34;: 195.37170899282242, \u0026#34;M\u0026#34;: 0.10743677233590453, \u0026#34;s\u0026#34;: 2.3450150729795514 } 2025.11.06：泄漏的 gemini-3-pro-preview-11-2025 是第一个能直接无参考写出完全无错误的 CIECAM16 的大模型。\n2025.11.18：正式发布的 gemini-3-pro-preview 干脆利落的写出了正确的代码。\nxyY 立体形状 一个有限的RGB空间，三个分量的范围均为0-1，可以经过一个3x3的矩阵转换为XYZ。如果画在三维坐标系中，RGB为一个立方体，XYZ是一个平行六面体，XYZ可以进一步转换为xyY，将得到的xyY绘制在三维坐标系中，以xy为底面，Y为z轴，会得到一个什么形状？ 从 RGB 到 XYZ 的线性变换很简单，可以把一个单位立方体拉伸成一个平行六面体，而转换到 xyY 进行的是一种非线性变换，可以称其为投影变换，此时得到的是一个形状比较复杂的立体。\n正确的形状是一个顶部呈帐篷状曲面的三角柱体。\n底面：黑色点 (0,0,0) 在 xy 色度图上没有定义，通常视为底面。 侧面：由 RGB 三个原色点构成的色域三角形向上延伸，形成三个垂直于底面的平面。 顶部：由白点 (1,1,1) 和三个二次色（青、品、黄）连接形成的三个双曲型曲面，像一个塌陷的帐篷顶。 大多数模型都会错误地认为它是一个有六个曲面的立体。直到 2025 年 11 月 18 日发布的 gemini-3-pro-preview 终于能够完整且正确地回答这个问题，准确描述出其“三角柱体”和“帐篷状顶部”的几何特征。\n","permalink":"https://jackchou.top/posts/llm-for-colour/","summary":"分享与通用 LLM 在领域内协作的方法，并提供一组测试题","title":"适用于色彩科学的 LLM 用法和测试题"},{"content":"两张 JPG 现在的手机基本都支持了 Gainmap 照片，OPPO 一直提到的 ProXDR 照片便是指 Gainmap，以前是自有格式，后来使用的是谷歌的 UltraHDR。\n如果你在二进制模式的文件中寻找 JPG 的起始符 FF D8 和结束符 FF D9，会发现这种图像文件中能找到不止一张 JPG 图片，一般可以在第一个结束符后面，紧接着找到下一个起始符，直接在字节流中把它们分开，保存成两个 JPG 文件，便可看到主图和增益图，同时，在增益图的 APPn 标记段中，可以以 XMP 形式找到解码增益图需要的一些元数据，比如 Min，Max，Gamma 和 Offset。\n比较有意思的是，适马最新的相机 Sigma BF 的直出 JPG 也是这种格式，是第一台能够直出 HDR JPG 图片的相机，能在传统派相机行业里看到这种格式是非常惊喜的。\n这是一张由 OPPO Find X6 Pro 拍摄的，符合 UltraHDR 标准的 JPG 照片，华为练秋湖的这栋楼当时阳光从一侧照亮，形成较大的明暗反差。其中左侧的是第一段 JPG，即 UltraHDR 中的主要图像，是一个普通的 SDR 图像，在不兼容 UltraHDR 的播放器，或显示器不兼容 HDR 时，看到的就是该图像，中间为第二段 JPG，即 Gainmap，由于并不是为直接显示而设计的，此处只是将其按照 RGB 渲染，当作一种“可视化”的手段。\n{ \u0026#34;Version\u0026#34;: 1.0, \u0026#34;GainMapMin\u0026#34;: 0, \u0026#34;GainMapMax\u0026#34;: 2.16048, \u0026#34;Gamma\u0026#34;: 1, \u0026#34;OffsetSDR\u0026#34;: 0, \u0026#34;OffsetHDR\u0026#34;: 0, \u0026#34;HDRCapacityMin\u0026#34;: 0, \u0026#34;HDRCapacityMax\u0026#34;: 2.16048, \u0026#34;BaseRenditionIsHDR\u0026#34;: false, \u0026#34;OplusScale\u0026#34;: 4.47065 } 这是从第二段 JPG 的 APP1 中获得的元数据，增益图中的像素值需要按照元数据计算出一个“倍率”，来获得右侧的 HDR 效果。其中 OplusScale 是 OPPO 自己的一个字段，不清楚具体用途是什么，其余都是 UltraHDR 的标准元素。\n右侧是合成的 HDR 效果，为了方便展示，该图实际上是解码之后，再以 PQ 编码在一起的纯 HDR AVIF 图像，并不是 UltraHDR，在峰值亮度允许的情况下，显示效果是一致的，否则会有所不同，下图是 UltraHDR 的原始版本，文件体积较大，可能加载慢一点。\n记录差异 Gainmap 记录的是 SDR 和 HDR 之间的差异，理解这一点可以从很多角度入手。\n现在有一个图片，在 HDR 设备上，希望画面上的某些区域的亮度能够超过原先 SDR 的白点，做到高亮的效果。在不改动 SDR 显示效果的情况下，用另一幅图像标记出需要提亮的区域和提亮的程度，然后把 SDR 和差异图编码在一起。\n或者现有一个 HDR 图片，但由于这种图片格式本身的兼容性，以及依靠设备下变换到 SDR 的兼容性都不够好，可以先下变换出一个满意的 SDR 图片，把它编码成传统、成熟的格式，然后用另一幅图像记录下原图和 SDR 图片的区别，编码到一起。\n总之，Gainmap 本身只记录差异，你可以把一个有画面内容的图片当作 Gainmap，封装到一个纯色的主图边上，创造一个只有解码成功的 HDR 设备才能看到画面的东西。\n上面的两个例子都是主图为 SDR 的情况，实际上，主图也可以是 HDR 的，通过 Gainmap 记录如何下变换到 SDR，但绝大多数情况下，都是使用 SDR 主图，这样即使解码器不支持，也可以当作普通的 SDR 图片来显示，有最好的兼容性。\n因此，Gainmap 只是一种编码手段，在有了 HDR 和 SDR 图像之后进行编码的时候使用，而不应当将 Gainmap 本身看作一种调节图像的方法。比如说，在 Gainmap 上做某种操作来让图片更亮，或者在没有 HDR 图像的情况下以某种算法生成一个 Gainmap 出来，使一个本身是 SDR 的图上变换到 HDR。\nGainmap 的计算 关于如何生成 Gainmap，我觉得读者更应参考具体平台的文档，尤其是 Gainmap 这样标准繁多的新事物，本文更多只介绍 Gainmap 的概念。\n比较推荐的几个文档和网页：\n谷歌的 UltraHDR，目前该格式是最为广泛使用的一种 HDR 双层格式，v1.1 版本还兼容了 ISO 21496-1 国际标准。如果您还是安卓平台的开发者，更是不得不看了。 Adobe 的 Gain map，Adobe 也是该格式的大力推动者，它推出的一款 Demo APP 是浏览各种 HDR 图片最方便的方法，该页面中还有一份详细的 Spec 文档，里面有一些很有参考价值的笔记。 在生成 Gainmap 前，你需要准备在线性光空间的 SDR 和 HDR 图像，比如规定 SDR 图像的像素值范围是 0-1，HDR 与之尺度对齐，但允许负数或超过 1 的数。这是因为 SDR 和 HDR 需要拥有相同的基色（比如 P3），如果基色范围选的比较小（比如 sRGB），或者 HDR 图像的色域特别广，就会出现负值，无需担心，Gainmap 是能够记录负值的。超过 1 的部分则是 HDR 本身的特征。\n$$ G = \\log_2 \\frac{\\text{HDR}+k_{\\text{hdr}}}{\\text{SDR}+k_{\\text{sdr}}} $$其中，两个 k 是偏移量，用于将可能的负数偏移到正数，确保这个对数运算是有意义的。\n然后，找到 G 的最大值和最小值，用于将 G 映射到 0-1 范围内。为了提高可靠性，可以选择排除一小部分最小和最大值之后再选，然后再裁切掉超出 0-1 的值。\n这样，你就得到了一个 0-1 范围内的图像，可以对其施加 Gamma 来提高量化的效果，并选择一个合适的位深（通常是 8 bit）和编码方式将其编码。\n同时，还要把偏移量、最大值、最小值、Gamma 等元数据一并按规范编码。\n单通道与三通道 为了节约空间，Gainmap 可以是灰度的，比如大部分安卓手机正在采用的，OPPO X8 Ultra 上的“原彩 ProXDR”照片指的便是升级到了三通道。\n灰度 Gainmap 和三通道的彩色 Gainmap 区别主要在于 SDR 和 HDR 之间的关联或自由度。\n三通道的 Gainmap 几乎完全自由，HDR 和 SDR 可以没有联系，Gainmap 可以在两个任意的点之间建立联系。但单通道的 Gainmap 要求 SDR 和 HDR 图像中的 RGB 像素值具有相同的比例，或者说在空间坐标系中，与原点位于一条直线上。\n在不约束 SDR 图像的情况下，两种 Gainmap 能达到的 HDR 色域容积是一样的，但三通道时，允许更自由的下变换方法，单通道的增益图则只能在亮度方面做下变换。而在保持相同 SDR 图像的时候，三通道的 Gainmap 能够更精细的控制 HDR 图像。\n有什么影响？根据 Bezold–Brücke 和 Hunt 效应，当亮度变化时，颜色的色相和彩度都会随之变化，单通道 Gainmap 仅能对亮度控制，保证 HDR 不变，下变换到 SDR 就受到限制，保持 SDR 的效果不变，能存储的 HDR 内容就受到限制，它们的色相（指的是 RGB 空间上的，而非感知）不能不同。\n另外，在量化精度方面，三通道的 Gainmap 也具有一定的优势，通过元数据中，记录三个通道各自的最大和最小值，能够控制每个通道的归一化时的压缩程度及 Gamma。\n对 Gainmap 的压缩 当对 Gainmap 进行压缩，尤其是降分辨率操作（大部分手机都会降分辨率至原来的 50% 长宽），可能会出现与主图无法对齐的现象，导致合成出来的 HDR 图片产生伪色、断层。同样的，对主图的压缩也可能导致与 Gainmap 无法对齐，尤其是高频部分，在点光源等典型 HDR 场景会更明显。\n压缩 Gainmap 的方法和压缩普通图像基本相同，比如 JPG，JPEG XL，HEIC 这些，但 Gainmap 又和普通图像不太一样，因此有人提出了一些特别针对性的方法，最简单的有对 Gainmap 额外应用一个 Gamma 函数，也有一些用到机器学习的方法，比如这篇使用 MLP 来压缩 Gainmap 的文章。\nT. D. Canham, S. Tedla, M. J. Murdoch, and M. S. Brown, “Gain-MLP: Improving HDR Gain Map Encoding via a Lightweight MLP,” Mar. 14, 2025, arXiv:2503.11883.\n其它的封装方法 JPEG XL 是最新的一种 JPEG 格式，拥有很高的压缩率，并且支持很多新特性，其中就包括双层格式。\nHEIF 和 AVIF 也支持双层格式，是以附加图的形式保存在元数据中，比如 iPhone 拍摄的 HDR 图片就是以该形式保存，解码的时候需要先找到对应的 Tag，再提取 Gainmap，开启了高效存储的 OPPO 手机拍摄的照片也是以 HEIF 存储，但 Tag 不相同。\nTIFF 也是可以把多个帧保存在一起的，因此也可以保存 Gainmap。\n在 Adobe Camera Raw 或者 Lightroom 输出 HDR 图片时，选择“最大兼容”后，导出的就是以上格式。\n小结和未来 Gainmap 已经被广泛的采用，它向前兼容，各种新封装也广泛支持，很方便的存储下变换结果。\n但从 HDR 的角度来看，它像 SDR 一样是相对亮度的，但又受到 HDR 峰值亮度的制约，用户调整显示屏亮度时，显示效果可能会明显变化。如果显示屏的 HDR 能力不足 Gainmap 中规定的最大值，这些中间情况的色调映射下变换具体实践也比较模糊。\n另外，存储 Gainmap 需要两张 8 Bit 图像，在压缩效率方面可能不如单一 10 或 12 Bit 的纯 HDR 图像。多数 JPG 格式的云服务（CDN 上的图像压缩，社交媒体的审查）还可能会错过 Gainmap，因为它位于第一个 JPG 流结束之后。\n接下来，我会写一些常见的 Gainmap 格式的特点和使用，并整理和提供一些 Python 代码。\n","permalink":"https://jackchou.top/posts/gainmap-image-intro/","summary":"通过将 SDR 与 HDR 图像封装在同一文件中，实现 HDR 的同时保证极好的向前兼容性","title":"HDR 图像格式解析（一）：Gainmap 的基本概念"},{"content":"CAT16 简介 当两个颜色在两种光源下呈现相同外观时，它们被称为对应色。色适应变换模型可以根据两种光源的条件和其中一个颜色的三刺激值，预测其在另一光源下的对应色的三刺激值。CAT16 就是目前最新的一种色适应变换模型。\n它的基本结构与 von Kries 假设类似，先将三刺激值转换到一个特别的锥体空间，然后在该空间内进行分别独立的增益，最后转换回三刺激值。这三步都可由矩阵描述。\n从三刺激值转换到锥体空间的矩阵称为 $\\mathrm{M}_{16}$，从锥体空间回到三刺激值使用其逆矩阵 $\\mathrm{M}_{16}^{-1}$。中间通道独立的增益由一个对角矩阵 $\\Lambda$ 描述，即：\n$$ \\Phi_{r,t} = \\mathrm{M}_{16}^{-1} \\cdot \\Lambda_{r,t} \\cdot \\mathrm{M}_{16} $$在使用中，我们把两个光源称为测试（Test）和参考（Reference），上式中的下标表示由测试向参考变换（r,t 表示从 t 到 r）。已知的一个颜色样本位于测试侧时，称为正向变换（Forward），用 $\\Phi$ 表示。\n如果已知的颜色位于参考侧，则为逆向变换（Inverse），用 $\\Psi$ 表示，比如预测已知参考侧颜色的对应色时，使用如下矩阵。\n$$ \\Psi_{t,r} = \\Phi_{r,t}^{-1} = \\mathrm{M}_{16}^{-1} \\cdot \\Lambda_{r,t}^{-1} \\cdot \\mathrm{M}_{16} $$由于接下来涉及很多的符号，为了方便理解，请先理解“在 CAT16 中，正向变换和逆向变换不等于交换光源”：\n$$ \\Psi_{t,r} = \\Phi_{r,t}^{-1} \\ne \\Phi_{t,r} $$本文中，不考虑色适应模型中的亮度适应，将 $Y_w=Y_{wr}$.\n一步 CAT16 为什么是不可逆的 可逆指的是：进行一次 A 向 B 的正向变换，再一次 B 向 A 的正向变换，是否能得到原来的值，或者说，A 向 B 正向变换，B 向 C 正向变换，是否等价于 A 向 C 正向变换。\n一步法是不满足可逆或传递的，罪魁祸首是适应度 D，一个用于描述适应程度的因子，介于 0-1 之间，可以直接指定，也可以由场亮度等计算而来，我们仔细观察对角阵中元素的结构。\n$$ \\text{Gain} = D \\cdot \\frac{\\text{RGB}_{\\textit{Ref}}}{\\text{RGB}_{\\textit{Test}}} + (1 - D) $$这个对角阵实际上是一个单位阵和一个白点变换相关的对角阵，按照适应度 D 进行线性组合。\n进行一次 A 向 B 的正向变换，再一次 B 向 A 的正向变换，记 $\\text{RGB}_{B}/\\text{RGB}_{A} = x$。\n$$ (Dx+(1-D))\\cdot(D\\frac{1}{x}+(1-D)) $$这样的两个线性组合，进行乘算的时候，就会变出一些二次项，导致仅在 D 为 0 或 1 的时候等价于直接变换。\n两步 CAT16 为什么是可逆的 因为其由一步正向变换接一步逆向变换组成，中间光源是等能白点。\n$$ \\Pi_{r,t} = \\Psi_{r,e} \\cdot \\Phi_{e,t} = \\mathrm{M}_{16}^{-1} \\cdot \\Lambda_{e,r}^{-1} \\cdot \\Lambda_{e,t} \\cdot \\mathrm{M}_{16} $$当需要传递或可逆时，实际上发生的是“正向变换接逆向变换，再正向变换接逆向变换”，中间两步是互逆的。\n比如说，A 到 B 到 C，发生的是 A 正向到 E，E 逆向到 B，B 正向到 E，E 逆向到 C，中间那两步就恰好互逆而抵消了，等价于 A 到 C 的两步法。\n$$ \\Pi_{C,A} = \\mathrm{M}_{16}^{-1} \\cdot \\Lambda_{E,C}^{-1} \\cdot \\Lambda_{E,B} \\cdot \\Lambda_{E,B}^{-1} \\cdot \\Lambda_{E,A} \\cdot \\mathrm{M}_{16} $$所以两个正向或者两个逆向组成的两步法也是不可逆的（用等能白点也不行），必须一正一负，才能在传递的时候让中间互逆。\n注意到，中间的光源在数学上可以是任意的，不一定非得是等能白。\n意义所在 一步的 CAT16 直接连接了测试场和参考场，但由于适应度的存在并不传递和对称，因此在不完全适应的情况下是“不正确”的，两步的则通过一个中间光源，使其在数学上传递和可逆。\n对称和传递性被认为是色适应模型应当具有的属性，但也有研究认为并非如此。\n一步法和两步法在各种视觉数据集上的性能非常类似，在实际中，推荐使用两步法的 CAT16 色适应。这也与 CIECAM16 的行为保持一致，CIECAM16 的第一步是将颜色刺激适应到等能白场，使用正向和逆向的 CIECAM16 等同于两步法 CAT16。\n实践里，一些用到色适应模型的地方会需要传递性和对称性，来避免误差的逐渐累积，比如颜色管理系统，显示链路。\n论文中的一些问题 Li, C.; Li, Z.; Wang, Z.; Xu, Y.; Luo, M. R.; Cui, G.; Melgosa, M.; Brill, M. H.; Pointer, M. Comprehensive Color Solutions: CAM16, CAT16, and CAM16-UCS. Color Research \u0026amp; Application 2017, 42 (6), 703–718. https://doi.org/10.1002/col.22131.\nEquation (5) 里的 Y_w 应该是 RGB_wr，否则会与后文中的 Y_w=Y_wr=100 部分矛盾。\nEquation (24) 和 Equation (23) 并不等价，Equation (23) 的两步 CAT16 具有可逆性，(24) 的没有。\n另一篇讨论 CAT16 的补充文章就提到了这个问题，两步法中正向/逆向排列组合得到的四种形式里，只有两种是传递和可逆的。其中一种最终被采纳，即先正向，再逆向，也就是上文的 Equation (23)。\nLi, C.; Xu, Y.; Wang, Z.; Luo, M. R.; Cui, G.; Melgosa, M.; Brill, M. H.; Pointer, M. Comparing Two‐step and One‐step Chromatic Adaptation Transforms Using the CAT16 Model. Color Research \u0026amp; Application 2018, 43 (5), 633–642. https://doi.org/10.1002/col.22226.\n醋来了 之前说要把用到的一些代码示例开源，结果写着写着写成草稿本了。现在新开了一个仓库，专门存放博客里用到的代码示例，这是第一篇附有代码的文章。\n其中有两个文件：\ncat16_comparison.py：比较一步和两步的可逆性。 cat16_paper_implementation.py：文章附录中的两步法实现和测试例（由 Gemini 完成） 开源地址：JacksBlog Examples: 01\n","permalink":"https://jackchou.top/posts/cat16-reversibility/","summary":"类似 CAT16 结构的色适应模型中的细节：一正一逆，成就可逆与传递","title":"理解 CAT16：为何两步法才能保证可逆？"},{"content":" 我正在探索 HDR 图片的应用，在部分图片中，你可能会观察到：\n至多 4x SDR 亮度的 HDR 图片。 在 SDR 设备上，未知的色调映射和不可预测的显示效果。 天气炎热，先来杯冰咖啡，把冰块模具先放在保温袋里，再放进冰箱冷冻，能获得更加透明和坚硬的冰，感谢 Leo 师兄的咖啡豆。\n云，火烧云 这个七月，杭州几乎每天都有晚霞。如果当天火烧云和晚霞预报有较高的指数，这一天似乎也会多一点期待。\n巨大的洁白积雨云，强烈的反射使其格外明亮。\n持续了整个傍晚的彩虹，穿越高速移动的云层。\n另一个指数非常高的周六，高纯度金黄色的晚霞。\n一个空气很好的傍晚，优雅的蓝调时刻。\n玉泉的光和猫 OPPO 的新功能：模拟柔光，偶尔会有一种镜头没擦干净的感觉。\n依旧柔光滤镜。\n坏猫，肆无忌惮的在教三乘凉，喜欢随机的躺在行人的鞋子上。\n不那么无聊的周末 通常的周末是睡两天，最近改成睡两个半天，然后去玩卡车一样的猫和坐船。\n塑料小人 下雨呆在家里还可以拍拍塑料小人，一个略反直觉的事实是：光源离物体越近，光的相对面积越大，光越柔和。如果你的灯不大，那可以试试拍塑料小人，大胆的靠近会有惊喜。\n一个面雕很牛逼的祖国版下北泽大天使。\n甚至可以近到出现在画面里，纯黑的背景下去除很简单。\n","permalink":"https://jackchou.top/photos/monthly-2025-07/","summary":"(25 Images) 日落、火烧云、彩虹和猫","title":"📷 七月集"},{"content":"我如何更新 Hugo 是一个能将 Markdown 文件转换成 HTML 静态页面的工具，理论上只要新建或者修改 Markdown，然后运行一下 hugo 就更新好了。不过实践里，有一些非常细节的东西可以分享。\nGithub Actions 方便起见，我的博客由两个仓库组成，一个存放 Markdown 和 Hugo 的主题等文件，另一个放生成的页面文件，也就是 Github Pages，第一个仓库里有 Github Actions ，运行 hugo 命令，生成静态页面再 push 到第二个仓库。\n这个 Action 的触发条件是当 main 分支有提交被推送时，运行一次 Action 大概要一分钟，Github 每个月三千分钟的 Action 配额肯定是用不完的。\nDraft 有时候文章写了一半，或者暂时没想发布，这时候在 front matter 中将 draft 设置为 true，这样运行 hugo 的时候不会构建这一篇。不过在 main 分支的话仍然会触发 Action，虽然不会有任何变化。所以我设置了一个 draft 分支，用来放这些文章，这样可以把 Git 当云同步用，也不会触发 Action。\nLLM 后处理 大致写完以后，我会让 AI 阅读和检查一下，比如有没有错别字，语言是否通顺，让它提点建议（建议基本都是看看就好，也可以听 GPT-4o 这类模型拍拍马屁）。如果这时候还没有写 summary 和 description 甚至 title，也可以让它给一些备选项，不过多数时候不太可用。\n这一步我用的模型是 GPT 4.1，用更厉害的模型也是没问题的，LLM 不太擅长精确控制生成文本的字数。\n输入将会是完整的 markdown，是由简体中文创作的个人博客的一篇文章。 你需要首先查看是否存在错别字、错误的用词和用语，表述不清晰，不通顺的地方。清晰的指出在何处、有什么问题、如何修改。注意，这是一个个人博客，适当的口语化是可接受的，但不能冒犯。 然后，你需要结合你的知识和理解，仔细的阅读文章内容，给出一些内容上的建议和读后感。 最后，你需要结合内容和你的理解，给出几个 front 部分的 title，summary 和 description 的备选项，符合以下要求： - title：这将是显示在文章列表中和文章顶部的“标题”，最好不超过 25 个汉字。 - summary：这将是显示在文章列表中，标题下方的文章“总结”或“副标题”，既补充说明标题，又代表文章内容，最好不超过 50 个汉字。 - description：这将显示在文章页面的标题下方第一段，是“摘要”，是开头和预告全文。最好不超过 80 个汉字。 以及，给出一个文件名，它将作为该文章的 URL，比如 xxx.md，将会成为 baseURL/posts/xxx 中文版完成之后，为了国际化一点，我还会生成一个英文版本，在 Hugo 里，只需要创建一个同名的文件 xxx.en.md 即可。这个英文版的草稿也是 LLM 写的，如果是涉及色彩科学的文章，可以给一个词典，帮助 AI 翻译术语，除了少数特别类似的词（其实很多时候我们自己也不严格区分），参数量大的模型都能翻译的比较好。比较好用的模型有 Gemini 2.5 Pro 和 DeepSeek R1-0528，后者有时候翻译质量更高，但格式和段落可能会被它改。翻译完之后，有时间的话我会阅读一遍，稍作修改。\n最近 OpenRouter 上的 Horizon 模型也很不错。更新：Horizon 似乎是 gpt-5-mini，而 gpt-5 在这两个任务上表现都比较不错。\n使用的 Prompt 如下，据说推理模型只要 Prompt 给的比较准确就可以，不用那种很复杂的：\n发现 OpenAI 有一个 优化 Prompt 的工具，有点像字节之前的 Prompt Pilot，这是一个针对 GPT-5 优化的 Prompt，也可以用于别的模型。\n输入内容为完整的 Markdown，内容为简体中文创作的个人博客文章。 你的任务是将内容翻译为英文，生成对应的英文版本。 要求： 1. 保持原有格式和段落完全不变。 2. 译文表达需自然、贴近日常习惯，避免生僻或不常用表达。 3. 保持 Markdown 语法，图片链接和代码部分只需翻译图片描述和注释。 4. 保持原文语气和风格，网络用语和俚语需准确对应。 在开始翻译前，生成一份 3-5 步的简要任务清单。 翻译完成后仅输出英文内容，便于直接复制粘贴，无需包含其他信息。 遇到专业术语时，以下是供你参考的词典： - 亮度：Luminance - 明度：Lightness - 视明度：Brightness 有时候，需要后期修改文章，对中文版本添加或修改内容之后，如何进行更新，又保持其他部分不变，还能让更新部分自然的融入进去？和 LLM 的单轮简单对话此时就不太能满足需求了，最好的办法是借助 Agent 的力量，比如说 Github Copilot 和 Codex，仅需简单的引导它一下。\n使用 `git diff` 检查我对文件 `ccontent\\posts\\badge-and-blog-workflow.md` 做的更改，依据以下规则，将修改同步到英文版的文章中 `content\\posts\\badge-and-blog-workflow.en.md`，只修改有改动的部分，保持其他部分不变，要求风格与原本接近。 翻译规则： 1. 保持格式和段落严格不变。 2. 注意用语和用词，不要出现生僻的单词，符合日常习惯。 3. 保持 markdown 语法，图片链接、代码部分只要翻译图片描述和注释。 4. 保持语气，使用的俚语和网络用语需要准确的翻译。 它会自行阅读，运行命令来查看差异，并准确的翻译修改的部分。\n统计访客数的 Badge 来源 网上冲浪的时候发现的小玩意儿，通过 Badge 来显示访客数目，比如 这个站。研究了一下，发现这是一个图片，加载一次数量计数器就会加 1。\n图片来自 visitor-badge.laobi.icu，是一个免费的服务，只要一个图片链接即可。\n图片链接的格式如下，里面的 page.id 换成唯一的字符串，比如我现在用的是 jacksblog，只要不和别人重复就可以。可以说是非常方便了，重新计数的话换一个字符串就行。\nhttps://visitor-badge.laobi.icu/badge?page_id=page.id\n当然，这只是图一乐的小玩具，因为只要加载这个图片，计数器就会加，像我这样把它添加在页脚（footer），那么每个页面都会加载它。这样一来，从访问主页，到进入文章列表，再到点开具体文章，这个过程计数器可能就会增加三次。此外，刷新页面也会导致计数增加。\n添加到页面 接下来是把这个 Badge 加到页面上，我选择的是在 footer 文字的底下，这一部分是 Claude Code 完成的，以下是它自己写的工作总结。\n第一步：配置分离 将 visitor badge 从 footer 文字中分离出来，在hugo.yaml中单独配置：\n文件位置： hugo.yaml\nfooter: text: \u0026#34;footer text here.\u0026#34; visitorsImage: \u0026#34;https://visitor-badge.laobi.icu/badge?page_id=\u0026#34; 新增visitorsImage参数专门存储 badge URL 保持 footer 文字的简洁性 第二步：主题扩展 修改 PaperMod 主题的extend_footer.html文件来显示 badge：\n文件位置： themes/PaperMod/layouts/partials/extend_footer.html\n{{- if .Site.Params.visitorsImage -}} \u0026lt;div style=\u0026#34;text-align: center; margin-top: 10px; margin-bottom: 20px; width: 100%; display: flex; justify-content: center;\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;{{ .Site.Params.visitorsImage }}\u0026#34; alt=\u0026#34;visitors\u0026#34; style=\u0026#34;max-width: 120px; height: auto;\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; {{- end -}} {{- if .Site.Params.visitorsImage -}}：条件判断，只有配置了 visitorsImage 才显示 {{ .Site.Params.visitorsImage }}：读取 hugo.yaml 中的配置参数 {{- -}}：去除多余的空白字符 text-align: center：文本居中对齐 width: 100%：容器占满父元素宽度 display: flex; justify-content: center：Flexbox 布局确保元素水平居中 margin-top: 10px; margin-bottom: 20px：与 footer 保持适当间距，底部留白 max-width: 120px：限制 badge 最大宽度，避免过大显示 height: auto：保持图片比例 注意事项 主题更新：如果更新 PaperMod 主题，需要重新添加 extend_footer.html 的修改 第三方依赖：依赖外部统计服务，如果服务不可用会显示破图 隐私考虑：访客统计会收集用户访问数据，需要符合隐私政策要求 ","permalink":"https://jackchou.top/posts/badge-and-blog-workflow/","summary":"通过一个 Badge 粗略地显示访客数，以及我更新博客文章的大致流程","title":"加个小玩意儿，再聊聊我更新文章的方法"},{"content":"本文所述方法，目前测试仅对索尼相机有效。\n向屏幕输入信号 显示器的测量，或者说特征化（Characterization），目的是建立起两个空间的关系，比如说图片中的像素值和显示出的光的三刺激值。对于相机来说，难点在于如何将一个像素值输入到相机的屏幕上显示出来，因为相机的屏幕不能够直接输入一个显示信号，我们也不便确定机内的系统是否有色彩管理。\n我首先想到的是，向存储卡写入图片，看看相机能否当作一种“图片播放器”使用，实测索尼相机卡里如果有不是来自相机拍的图片，会报“无法读取存储卡”的错误。\n顺着上面的思路，我们能不能找到一种方法，把相机直出的 JPG 文件里的内容修改掉，让相机认为这张图片是他自己拍的，从而显示？实际操作里，用到的不是修改直出 JPG 文件里的图像，而是把这个 JPG 里的元数据提取出来，生成一个纯色图片，把元数据嵌入进去。\n提取元数据的方法有很多，比较著名的有 Pillow，能够提取 ICC（直出 JPG 没有这个）和 EXIF，但还不够，索尼直出的 JPG 还有一个 XMP，记录了两个 uuid，不搬这个的话也会报错，能够处理这一段 APP 的工具是 Exiftool。\n使用以下命令搬运元数据，其中，pure_color_image是提供内容的临时图像，可以由 Pillow 等创建，缩略图可以清空，也可以保留。\nexiftool -tagsFromFile input_path -all:all -o output_path pure_color_image 写一个简单的小工具，搬运元数据到新的纯色图后，就能够在机内的屏幕上显示了。\n简单测量 接下来，用同样的办法处理了 30 张图片，作为一次简单的实战和测试，机内设置为默认的手动亮度（a7c2 的默认与晴朗天气模式，zve10mk2 的晴朗天气模式具有类似的表现）。\n选择的测试点包括：\n纯色：R/G/B 轴向各两个（120、255），共 6 个 混合纯色：黄、青、品，3 个 灰阶：0–255，步长 15，共 18 个 参考彩色：浅色皮肤 (241,149,108)；偏蓝的绿 (140,253,153)；偏紫的蓝 (7,47,122)，共 3 个 用于评价色域覆盖，灰阶稳定性和传递函数，以及色差。\n亮度和对比度 默认的手动亮度为 267.86 nits，显示黑色时为 0.15 nits，对比度 1823:1。\n调到晴朗天气模式之后，亮度为 951.19 nits，黑色为 0.54 nits，对比度 1771:1。\n色域覆盖和容积 利用三基色的色坐标，可以计算与 sRGB 相比的色域覆盖和容积：\n转换到 CIE 1976 UCS 中（也就是 u\u0026rsquo;v\u0026rsquo;），计算三角形的面积之比，相比 sRGB 的色域覆盖为 95.90%，色域容积为 101.14%。\n灰阶与传递函数 展示了灰阶的亮度值，并按照最大亮度进行归一化后，与 sRGB 的标准传递函数进行对比，这块屏的传递函数与 Gamma 拟合的并不好，硬要调整 Gamma 指数的话，比较接近 2.6。\n色差 因为我们输入的图片是基于原本 sRGB 的直出修改的，因此他的理论值应该是 sRGB 空间对应的三刺激值，按显示白色时的亮度进行归一化后，计算所有 30 个颜色相比标准 sRGB 的色差值。\n按 CIEDE 2000 计算色差，平均 deltaE 为 3.12，最大 deltaE 为 7.34（洋红色）。\n关于 Adobe RGB 多数相机可以在机内设置“颜色空间”，一般会提供 sRGB 和 AdobeRGB 两个选项，该选项只会影响 JPG 文件，一般来说，标识颜色空间使用的是 ICC 配置文件，而索尼相机则使用了一种不同的办法，是依靠 EXIF 内的 Tag 实现的。\nInteroperability Index: R03 - DCF option file (Adobe RGB) Interoperability Version: 0100 Adobe 的 Gain Map Demo 能够识别到这个 Tag，将图片标识为 Adobe RGB 空间。\n而 Exiftool 的默认行为不会搬运这两个 Tag，需要加上参数 -unsafe。\n小结 这块索尼的机内屏幕，虽然称不上优秀，但也不是特别垃圾，唯一的缺点可能是传递函数的 Gamma 值（如果这样说的话）有点过于高了，接近 1000 nits 的最大亮度也不低，观感较差的原因更多要归咎于太小的尺寸、太低的分辨率和比较差的可视角度。\n作为一个提供预览的屏幕，把色域做的大一些，有倾向性的显示一个更加鲜艳、对比更高的画面，结合更大的显示面积、高分辨率和比较好的可视角度。能够大幅提高拍摄的实际体验。实际上，哈苏 X2D 的屏幕就在一定程度上有这样的优化，也是我见过显示效果最好（此处的好指的是看起来好）的相机显示屏之一。\n我想没人会在这块屏上严肃的评价图片好与坏，我会更喜欢那种看起来更好，让用户在拍摄的时候有一个更讨喜的画面的相机。至于导出到别的显示器上与内屏差距太大，可以在配套的软件里做文章，提供一个将图片调整到机内屏幕上观感的预设，这在类似 ICC 的颜色管理系统里不是什么难事。\n","permalink":"https://jackchou.top/posts/sony-camera-screen/","summary":"分享一个小方法，用于测试索尼相机内部屏幕和一次实践","title":"不仅目测：索尼相机屏幕的客观测试和方法"},{"content":"秘密花园 2023 年 10 月，为了用 Cloudflare 的 Tunnel 功能，我买了一年 jackchou00.icu 这个域名，顺便作为 GitHub 的自定义域名。后来，有了写博客的动力，想多买几年的时候，阿里云上却无法续费，于是换上了之前在别的地方买的一个续费比较便宜的 jackchou.top，然后续到了 2035 年。\n作为一个放在 GitHub 上的静态网站，换域名实在是一件再简单不过的事情，无非买个域名，换一下自定义域名和 DNS 记录，而让网站消失在互联网上也是一件同样简单的事情，几乎没有排名和 SEO，一个月都不更新的分享小众领域冷门方向的个人小站，换个域名或是过期，可能就找不到了。\n翻看收藏夹里几位前辈的博客，多是一年半载不曾更新，或是再也无法访问的。写个人博客这种全凭自觉的事情，放弃是再自然不过，也许等到我开始工作，甚至换了领域，或者干脆哪天不想写了，这里也会变成一片寂静吧。\n我不喜欢“运营”社交媒体的感觉，我会不自觉的去关注那些数据和流量，我也不喜欢博人眼球的标题和内容。在这里写这个博客反而会让我有一种记录和分享的快感，在这里，数据也不重要，因为我根本不统计，我只假设并期待来访者能有所收获，在这里，我只需要对自己负责，好像是在打理一片只属于自己的，却又对全互联网开放的小花园，这种在大庭广众的阴暗角落的感觉很微妙。\n不过至少到 2035 年前，您可以通过 jackchou.top 访问这里，之后，也可以用 jackchou00.github.io。我充分相信 Cloudflare 和 Github 的可用性，这里可以说是与天地同寿。\n换域名的细节 我本来以为换域名会是一件麻烦事，不过回头想想好像工作量只有改一下 DNS 和 CNAME，更多的是如何让知道这个地方存在的人继续知道，SEO 什么的其实我也无所谓。\n我暂时把我所有的域名都重定向过来了，你可以通过 jackchou00.icu, zms.im, jackchou.xyz 访问这里。不过只有 jackchou.top 买的比较久。\n如果你在 2025.7-2025.10 这三个多月间访问过这里，也许你会注意到一条横幅，这是 Claude Code 的作品，感兴趣的话请看他自己写的日志。\n需求背景 博客域名从 jackchou00.icu 迁移到 jackchou.top，需要创建一个醒目的横幅通知访问者域名变更，并考虑三个月后的移除便利性。\n实现方案 选择的方法 修改 PaperMod 主题的 extend_head.html 文件，这是主题提供的自定义扩展点，所有页面都会加载。\n文件位置 themes/PaperMod/layouts/partials/extend_head.html:15-157\n核心功能 固定顶部横幅\n使用 position: fixed 固定在页面顶部 渐变背景色增加视觉吸引力 高 z-index 确保在最上层显示 双语支持\n自动检测页面语言（通过 document.documentElement.lang 和 URL 路径） 中文：👋 再见，jackchou00.icu 🚀 新的旅途，从 jackchou.top 起程 英文：👋 Goodbye, jackchou00.icu 🚀 A new chapter will begin at jackchou.top 用户交互\n可点击 ✕ 按钮关闭 关闭状态保存到 localStorage，刷新页面不再显示 显示通知时自动给 body 添加 padding-top 避免内容被遮挡 自动过期\n硬编码过期时间：2025-10-31（三个月后） 过期后自动不显示，无需手动操作 响应式设计\n桌面端和移动端不同的布局和间距 移动端文字和按钮垂直排列 技术细节 CSS 样式 渐变背景：linear-gradient(135deg, #667eea 0%, #764ba2 100%) 链接颜色：黄色 #ffeb3b 增加可读性 阴影效果：box-shadow: 0 2px 10px rgba(0,0,0,0.1) JavaScript 逻辑 使用 IIFE（立即执行函数）包装，避免全局变量污染 DOMContentLoaded 事件确保页面加载完成后执行 insertAdjacentHTML 动态插入 HTML 移除方法 有两种移除方式：\n方法一：自动过期（推荐） 无需任何操作 2025 年 10 月 24 日后自动不显示 方法二：手动移除 删除 themes/PaperMod/layouts/partials/extend_head.html 文件中的第 15-157 行：\n\u0026lt;!-- Domain Migration Notice --\u0026gt; \u0026lt;style\u0026gt; ... \u0026lt;/style\u0026gt; \u0026lt;script\u0026gt; ... \u0026lt;/script\u0026gt; 即删除从 \u0026lt;!-- Domain Migration Notice --\u0026gt; 开始到最后一个 \u0026lt;/script\u0026gt; 结束的所有代码。\n注意事项 主题更新：如果更新 PaperMod 主题，需要重新添加这些代码 缓存问题：用户浏览器可能有缓存，新访客会立即看到通知 SEO 影响：横幅不会影响 SEO，因为它是通过 JavaScript 动态添加的 ","permalink":"https://jackchou.top/posts/domain-migration/","summary":"寄蜉蝣于天地，渺沧海之一粟","title":"换个域名，随便聊聊我对博客的看法"},{"content":"其实是因为我自己经常做这种事，导致必须要写个东西来警告一下自己（以及方便以后自己使用）\n当意外地将一个大文件、二进制文件或者包含敏感信息（如密码、密钥）的文件提交到 Git 仓库后，仅仅在新的 commit 中删除它是不够的。因为它依然存在于 Git 的历史记录中，会持续占用仓库空间，或者带来安全风险。本指南将介绍如何从 Git 的历史记录中彻底抹除文件。\n修改 Git 历史记录是一项具有破坏性的操作。它会改变仓库中许多 commit 的哈希值。在对共享仓库执行此操作前，请务必与所有协作者沟通，并先克隆一份出来做备份。\n分析仓库 在删除之前，需要定位那些不需要的文件，尤其是占用空间大的文件。\n纯 git 也是可以做到分析占用空间的，但需要使用很长的命令行，这是一个 powershell 用的版本。\ngit rev-list --objects --all | git cat-file --batch-check=\u0026#39;%(objecttype) %(objectname) %(objectsize) %(rest)\u0026#39; | Where-Object { $_ -match \u0026#39;^blob \u0026#39; } | ForEach-Object { $_ -replace \u0026#39;^blob \u0026#39; } | Sort-Object { [int]($_.Split(\u0026#39; \u0026#39;)[1]) } | Select-Object -Last 10 macOS 或者 Git Bash\ngit rev-list --objects --all | git cat-file --batch-check=\u0026#39;%(objecttype) %(objectname) %(objectsize) %(rest)\u0026#39; | sed -n \u0026#39;s/^blob //p\u0026#39; | sort --numeric-sort --key=2 | tail -n 10 一般安装完 git，都是有 lfs 的，使用 git lfs 命令可以直观的按类型列出占用空间。\ngit lfs migrate info --everything git-sizer 是 GitHub 官方推出的一款用于分析 Git 仓库“健康状况”的工具。它能提供更全面的报告，但需要额外安装。\ngit-sizer 的安装需要从其 Releases 页面 下载对应系统的可执行文件，然后将其所在目录添加到系统的 PATH 环境变量中。\n安装后，进入你的仓库目录运行：\ngit-sizer --verbose 这个工具不仅仅是看文件大小，还会分析 blob 数量、树深度等，帮助你全面了解仓库的“臃肿”程度。\n从历史记录中删除文件 我们将使用 git-filter-repo 这个现代化工具来重写历史记录。它是官方推荐的、替代 git filter-branch 和 BFG Repo-Cleaner 的新一代工具。\n通过 pip 安装：\npip install git-filter-repo 如果你非常现代化的转向了 uv，可以使用：\nuv tool install git-filter-repo 提示： git-filter-repo 为了安全起见，要求在一个全新的、干净的克隆仓库上进行操作。它会自动断开与远程仓库的连接，防止你意外推送错误的修改。\n使用 git-filter-repo 删除指定文件一定不能忘记 --invert-paths 参数！ 否则，仓库里除了这个文件，其它所有文件都将被删除。（点名批评 gemini-2.5-flash）\n删除单个文件或文件夹：\ngit filter-repo --path path/to/your/example.jpg --invert-paths 删除指定类型或模式的文件：\ngit filter-repo --path-glob \u0026#39;*.jpg\u0026#39; --invert-paths 删除所有名字相同的文件：\ngit filter-repo --path \u0026#39;.DS_Store\u0026#39; --invert-paths 执行完毕后，git-filter-repo 会自动清理相关的 commit。\n重新推送至远程仓库 现在需要将其强制推送到远程仓库。\n为了防止未来再次误提交这类文件，最好先将它们添加到 .gitignore 文件中。\n重新关联远程仓库并强制推送 git-filter-repo 会删除 origin 配置，需要重新添加并使用强制镜像推送给远程，--mirror 是一个很强的操作，请确保你事先备份了。\ngit remote add origin \u0026lt;your-repo-url\u0026gt; git push --force --mirror 同步所有协作者的本地仓库 这一步至关重要，也是整个操作代价最大的地方。\n所有协作者（包括你自己其它设备上的）都不能再使用 git pull 来更新他们的本地仓库。因为本地历史和被重写的远程历史已经完全不同，必须从远程重新 git clone 一个全新的仓库。\n因此，在执行历史清理前，务必三思并与项目的参与者充分协调。\n","permalink":"https://jackchou.top/posts/git-rm-files/","summary":"其实是因为我自己经常做这种事，导致必须要写个东西来警告一下自己（以及方便以后自己使用）","title":"如何从 Git 历史记录中彻底删除文件"},{"content":"记得很久之前在库迪喝过一次马黛茶，味道非常的一言难尽，这家宁波路上的小店专卖马黛茶，味道还不错。\n店里有一只黑猫，还有更多黑猫的元素，贴纸、周边、玩偶一类的。\n","permalink":"https://jackchou.top/photos/cat-250628/","summary":"(9 Images) 一些猫猫能量","title":"📷 马黛茶店里的猫猫"},{"content":"将会记录一些和图片博客相关的内容，包括如何在有限的带宽和对象存储下尽可能提高图片质量和体验，色彩管理等。\n如果你对这些内容也感兴趣，欢迎继续阅读或与我交流，否则，这部分内容对于大部分读者应当是“透明”的。\n格式 AVIF 压缩参数和图片分辨率，文件大小还在调试中。\n经过肉眼观测，4096px 的图片，500KB 的 avif 能够有不错的观感、加载速度和费用平衡。\nOSS 考虑了一下阿里云 OSS，bucket 放在杭州，然后开着公共读的话，外网流量比较多，海外访问速度也一般。使用 CDN 的话需要域名备案，其实和放在 R2 再套 CDN 的麻烦程度没有区别。\n阿里云同城冗余存储的费用是 0.15RMB 每月每 GB，R2 是 0.015USD 每月每 GB，还有 10GB 的免费额度。\n最重要的是 R2 没有外网流量费用，虽然国内访问慢一点，但是不会钱包爆炸，所以暂时苦一苦国内，先用 R2，以后如果真的有很多国内读者，考虑套一个 CDN。\n文章的具体形式 困难的是文章的文件名，因为它会成为 URL 的一部分，暂时就用主题加日期这样不优雅但相对高效的办法。\n另外比较关键的是，也许不会有太多机会产出大量的单一题材图片（翻译成人话是没有太大段的旅游），太零碎的话也不好。所以暂定是在 summary 标出图片的数量（类似以前多图杀猫时代的 nP 标法）。附加一点简单的文字描述，组成一个图片为主的游记或者日记形式。\nHDR 小红书都支持 HDR 图片了，我还在等什么？\n好在既然用了浏览器，HDR 图片的支持可谓易如反掌，再加上一个开源项目即将完工，各种 HDR 图片格式之间的转换也不再是难题，初步的想法是用 PQ 传递函数的 AVIF（美其名曰 ISO-22028-5），苦一苦安卓用户。\n色彩管理 某次面试的时候，面试官提到如何确保图片在每个人的终端上有一致的显示效果？\n仔细思考，我的回答会是：也许做不到。因为终端设备的情况实在太过于复杂，每个设备的显示技术、颜色管理、用户设定都不同，很难保证一个“一致”的显示效果。举一个极端的例子，我见过相当一部分设备开着数个“电脑管家”提供的护眼模式，叠加之后的显示效果可想而知。\n不过我能做到的是在内容提供端提供一个尽可能统一且兼容的方案，目前来看，可能会是 nclx 标识，他足够简单，足够轻量，测试来看浏览器的兼容性也很好。剩下的就是相信浏览器与系统的颜色管理。\n","permalink":"https://jackchou.top/photos/test-photos/","summary":"点击五次版本号进入开发者模式","title":"说明及测试页面"},{"content":"所见即所得\nWYSIWYG (ˈwɪziwɪɡ)\nWhat You See Is What You Get\n这本书最后几章内容有点放飞自我的感觉，也不怎么给参考文献，不是很能看懂，为了内容完整（以及这本书已经续借三次了）还是硬着头皮写完吧。\n“属性” 先定义了一堆颜色再现的“属性”：\n范围 Scope：分为“与颜色再现自身相关”和“颜色再现和源色相关”。没听懂，大部分都是后一种，和喜好颜色有关的是前一种。 大概是指颜色再现的目标是为了在各种程度上还原源色（不论是光谱、三刺激值或是色貌）还是有别的目标。比如拍摄一个低显色灯光下的色卡，是还原出失准的颜色，还是色卡在标准照明体下的颜色。\n应用 Application：分为与应用相关或独立于应用。这个也没听懂，大部分都是后一种，只有一个创造性颜色再现是前一种。 这个应该比前一种情况更“激进”一些。喜好色或记忆色虽然也是进行了偏离“准确”状态的调整，但仍是符合心理物理现象的（记忆色也算一种色貌现象）。而应用相关可能指为了某种应用场景而进行更创造性和夸张的处理，比如黑白化、艺术性的着色等。\n基本性质 Nature：分为可以确定性描述（已知颜色再现具有这样的性质）和“理想状态的再现”。这个也不怎么听得懂，大概意思是能够确定的是前一种（使用“相等”，“相对”这种关系描述的），比较含糊的是后一种（记忆色，喜好色之类的）。\n表现 Expression：分为可以用物理方法定量测量和可以用心理视觉定性测量的。这个就很好理解，书里提到“可以定量测量”与上面的“与源色相关”总是成对出现，但好像既不充分也不必要，比如色貌相等的颜色再现就是源色相关但不能定量测量。\n这些属性还有各自的代号（一个大写字母），也没看出有什么关系，这个代号和后面的例子还对不上，我也查不到哪个文献里提到了这些东西。\nHunt 的分类 Hunt 把颜色再现的目标分为几类，出自 The Reproduction of Colour 一书的第 11 章。\n光谱颜色再现：源和再现的光谱一致，比如 Lippmann 彩色摄影（1908 年的诺贝尔奖），是通过干涉实现的，洛桑联邦在 2021 年进行了复现和详细的分析 1。\n正确颜色再现：源和再现的三刺激值（绝对值）一致，意味着在相同观看条件下，绝对色貌（视明度和视彩度）属性一致。\n色度颜色再现：源和再现的色坐标（按照对应白色的归一化三刺激值）一致，意味着在相同观看条件下，相对色貌（明度和彩度）属性一致。\n以上三种是能够物理测量的，但要注意需要在相同观看条件下，才能获得较好的颜色再现效果，因为他们没有考虑观看条件对色彩感知的影响。一个很好的例子是在自发光屏幕上再现出白炽灯下的白纸，如果三刺激值或色坐标一致，屏幕上的颜色看起来会更黄一些，可能是因为自发光屏幕不会引起折扣光源现象，色适应程度比白炽灯观看环境更低。\n等价颜色再现：各自观看条件下，色貌属性绝对量相同，三刺激值则不相同。考虑了观看条件对颜色感知的影响，包括色适应等。\n对应色颜色再现：各自观看条件下，色貌属性的相对量相同，色坐标不相同。相机的理想颜色再现应该属于这种情况。\n这两种是考虑了色貌的上两种的对应再现。在不考虑同色异谱问题的情况下，理论上能达到“所见即所得”（What you see is what you get）的效果。原文里提到等价颜色再现中，虽然绝对亮度不同，但应该比较接近，但实际上由于高亮度下，视明度的高度非线性，绝对亮度可能相差较多。\n喜好颜色再现：为了满足喜好，对颜色进行调整。比如让蓝天更蓝、肤色更红润或更高的明度来满足人们对图片的喜好，可以理解为修图，相机的颜色再现也有大部分属于这种情况。\nICC 的四种显色意图 颜色再现的目标在 ICC 色彩管理系统中被称为显色意图（Rendering Intent），分为四种：\n感知（Perceptual）：保持图像的总体色貌，当色域大小不匹配时，会进行压缩或扩展，以适应目标色域。会改变图像所有颜色的色调和饱和度，但能保持图像颜色之间的总体视觉关系。 饱和色（Saturation）：使得目标图像的饱和度尽可能高，进行色域压缩或扩展时不注重整体色貌匹配。一般来说，比感知意图的目标色域更大。 绝对色度（Absolute Colorimetric）：尽可能精确的匹配色度，源色域和目标色域重叠的部分保持不变，目标色域以外的颜色保持色调不变，映射到色度尽可能接近的位置。 相对色度（Relative Colorimetric）：与绝对色度显色意图的区别在于，首先将原图的白场和黑场变换到目标色域的白场和黑场，对变换后超出色域的颜色进行保持色调不变的最近位置映射。 此处的白场和黑场仅指代亮度，绝对色度和相对色度都是有色适应的，绝对色度显色意图的绝对亮度也会维持基本不变，即使目标色域有更亮的白场。\n色域 色域指的是一个设备或系统能够再现的颜色范围。色域在不同空间有不同的形状，对于显示器这样的加色系统，RGB 色域是一个立方体，在 RGB 上应用非线性（Gamma）后仍然是一个立方体，因为 RGB 是线性无关的，使用从 RGB 到 XYZ 的转换矩阵，将立方体映射到 XYZ 空间后，色域是一个平行六面体。\n当我们提及“最近”，“最小差异”，“色调”时，都是在均匀颜色空间中，而从 XYZ 向均匀颜色空间的转换中，包含了非线性步骤，即便是 IPT 或 sUCS 这样简单的均匀颜色空间，也由两步线性变换和夹在其中的一步非线性变换组成。\n这个非线性变换会把平行六面体变成一个很复杂的形状，包含曲面和曲线，而且大部分情况下是非凸的。要描述这么复杂的边界，可以使用凸壳或者 $\\alpha$-shape 来近似。\n确定了色域在均匀颜色空间上的形状后，使用不同的“路径”（等明度、等色调或者是别的斜线），将色域外的颜色沿着“路径”移动到色域内，移动的距离可以由距离作为参数来确定，最简单粗暴的方式是裁切，即只要在色域外就直接移动到色域边界。\n完结撒花 这本书的笔记到这里就结束了，有关后两章颜色管理和显示、采集设备的更多内容将在别的工作内介绍（这本书里写的太潦草了）。\n从寒假拖延到暑假，也算是重新学习了一遍色彩科学，希望你我都有新的发现和收获。\nG. Baechler, A. Latty, M. Pacholska, M. Vetterli, and A. Scholefield, “Shedding light on 19th century spectra by analyzing Lippmann photography,” Proceedings of the National Academy of Sciences, vol. 118, no. 17, p. e2008819118, Apr. 2021, doi: 10.1073/pnas.2008819118.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://jackchou.top/posts/pcrdi07/","summary":"Notes for Principles of Color Reproduction in Digital Images, Ep. 7","title":"数字影像颜色再现原理笔记：颜色再现和色域"},{"content":"发现好久没有写博客了，其实有很多草稿，但都处于烂尾的状态。\n搬运一个 Github 上的 Issue，有助于正确使用和理解各种 HDR 传递函数。\nhttps://github.com/colour-science/colour/issues/1348\nIssue 的大致意思是，按照 BT.2408 的表1，把漫射白放在 203.0 nits 的显示亮度，计算出18% 灰卡的显示亮度不是 26 nits。\nBT.2408 和问题 BT.2408 是一份关于 HDR 操作实践的标准，表1 推荐了一些物体的显示亮度和不同传递函数下的码值。\nReflectance Object or Reference (Luminance Factor, %) Nominal Luminance, cd/m² (PQ \u0026amp; 1000 cd/m² HLG) Nominal Signal Level Nominal Signal Level Grey Card (18%) 26 38 38 Greyscale Chart Max (83%) 162 56 71 Greyscale Chart Max (90%) 179 57 73 Reference Level: HDR Reference White (100%) also diffuse white and Graphics White 203 58 75 问题是如何使用 HDR 传递函数，完成这些数字间的转换，比如使用 Python 的 colour 库。\nimport colour 理论 表格分三部分，第一列是反射率，对应场景参考的线性光（Scene Referred Linear Light），第二列是显示亮度，也就是显示参考的线性光（Display Referred Linear Light），后两列是两个系统下的编码值（Code Value）。\n他们的数值范围是：\n场景光：0.0 - 1.0，是相对的，比如在一个摄影系统里由相机的曝光控制。一个灰卡和漫射白的场景光可能是 0.18 和 1.0，也可能是 0.018 和 0.1。 显示光：0.0 - 10000 nits，在 HDR 系统中是绝对的，对 HLG 系统来说，要规定一个峰值亮度，比如 1000 nits。 码值：0 - 255 或者 0 - 1023，取决于系统的位深，也可以用 0.0 - 1.0 的浮点数表示，个人觉得浮点数会好用一点。 一个传递函数系统定义了如何完成这些亮度和码值的转换。\n场景线性光到显示线性光的转换称为 OOTF（Opto-Optical Transfer Function） 从场景线性光到码值的转换称为 OETF（Optical-Electrical Transfer Function） 从码值到显示线性光的转换称为 EOTF（Electrical-Optical Transfer Function） 特别注意的是，OETF 不是 EOTF 的逆函数。从显示线性光到码值的转换应当使用 EOTF 的逆函数，而不是 OETF，从码值到场景线性光的转换同理，应该使用 OETF 的逆函数，而不是 EOTF。\n场景光、显示光和码值之间的转换关系实际上只需要两个传递函数，PQ 用到的是 EOTF 和 OOTF，HLG 用到的是 OETF 和 OOTF。在 BT.2100 中，PQ 的 OETF 等价于 OOTF 接 EOTF 的逆函数，HLG 的 EOTF 等价于 OETF 的逆函数接 OOTF。\ncolour 里有提供这些传递函数的实现，包括 PQ 的 OETF 和 HLG 的 EOTF。\nPQ PQ 是显示参考的，完整的转换关系是：使用 OOTF 将场景线性光转换为显示线性光，然后用 EOTF 的逆函数将显示线性光转换为码值。显示的时候使用 EOTF 将码值转换为显示线性光。\n我们先把漫射白放在 203 nits 的显示亮度，此时的场景线性光由 OOTF 的逆函数得到，场景线性光中，灰卡和漫射白的比例是 0.18，计算得到灰卡的场景光，应用 OOTF 得到灰卡的显示线性光（26 nits）。对漫射白和灰卡的显示线性光应用 EOTF 的逆函数，得到他们的对应码值。\ndisp_lin_white = 203 scene_lin_white = colour.models.ootf_inverse_BT2100_PQ(disp_lin_white) print(\u0026#34;Scene Linear:\u0026#34;, scene_lin_white) # 0.0307311888745 scene_lin_grey = scene_lin_white * 0.18 print(\u0026#34;Scene Linear Grey:\u0026#34;, scene_lin_grey) # 0.00553161399741 disp_lin_grey = colour.models.ootf_BT2100_PQ(scene_lin_grey) print(\u0026#34;Display Linear Grey:\u0026#34;, disp_lin_grey) # 25.6890888306 signal_white = colour.models.eotf_inverse_BT2100_PQ(disp_lin_white) print(\u0026#34;Signal White:\u0026#34;, signal_white) # 0.580688881042 signal_grey = colour.models.eotf_inverse_BT2100_PQ(disp_lin_grey) print(\u0026#34;Signal Grey:\u0026#34;, signal_grey) # 0.378961634455 HLG HLG 是场景参考的，完整的转换关系是：使用 OETF 将场景线性光转换为码值，解码时使用 OETF 的逆函数将码值转换为场景线性光，然后使用 OOTF 将场景线性光转换为显示线性光。\n同样，把漫射白放在 203 nits 的显示亮度，此时的场景线性光由 OOTF 的逆函数得到，场景线性光中，灰卡和漫射白的比例是 0.18，计算得到灰卡的场景光，对场景光应用 OETF 得到码值，对场景光应用 OOTF 得到显示线性光。\ndisp_lin_white = 203 scene_lin_white = colour.models.ootf_inverse_BT2100_HLG(disp_lin_white) print(\u0026#34;Scene Linear:\u0026#34;, scene_lin_white) # 0.264797185624 scene_lin_grey = scene_lin_white * 0.18 print(\u0026#34;Scene Linear Grey:\u0026#34;, scene_lin_grey) # 0.0476634934123 disp_lin_grey = colour.models.ootf_BT2100_HLG(scene_lin_grey) print(\u0026#34;Display Linear Grey:\u0026#34;, disp_lin_grey) # 25.9312256307 signal_white = colour.models.oetf_BT2100_HLG(scene_lin_white) print(\u0026#34;Signal White:\u0026#34;, signal_white) # 0.749877364632 signal_grey = colour.models.oetf_BT2100_HLG(scene_lin_grey) print(\u0026#34;Signal Grey:\u0026#34;, signal_grey) # 0.378140820644 需要注意的是，HLG 的 OOTF 会随着显示峰值亮度变化而变化，不传任何参数的情况下，colour 默认使用 1000 nits 的峰值亮度，对应的 OOTF 是一个 1.2 的 gamma。另外，HLG 的 OOTF 应当作用在 RGB 分量上，只传一个亮度会提出 Warning，但思路和结果是正确的。\n一点后记 关于为什么不能把 OETF 和 EOTF 当作逆函数使用，正是因为 OOTF 在其中作怪，最理想的情况下，显示器完全再现场景光，OOTF 应该是一个线性的函数，此时 OETF 和 EOTF 是逆函数（用一个亮度做系数）。\nPQ 用到的 OOTF 是 BT.709 OETF 和 BT.1886 EOTF 的组合，弯曲程度介于线性和 gamma 1.2 之间，HLG 用到的是一个与亮度相关的伽马函数，1000 nits 时为 gamma 1.2。\n个人觉得，理解这些传递函数是必要的，尤其是 HDR 系统中，很多时候需要在不同的传递函数间转换。BT.2408 的表格提供了一个很好的参考，但实际应用中，很少会真的参考这些传递函数，尤其是 OOTF，制作 PQ 内容的时候，通常是面向显示光调整后，用 EOTF 的逆函数转换为码值，并不用到 OOTF。HLG 要用到 OOTF 的设计更可能是为了兼容 SDR 系统和广播制作。\n这个小实验也很好的证明了：只要运算正确，用什么传递函数得到的结果都是一样的（除了量化的区别），不存在用了 HLG 效果会和 PQ 不一样。\n英语小课堂 Issue 里有一句：Now, the penny finally dropped.\n这个表达来源于老式自动售货机，需要一枚硬币投入后才会工作，有时硬币卡住了，过一会儿才掉下去，机器才开始工作。所以这个短语比喻“突然明白过来”或“领悟到之前没搞懂的事情”。\n","permalink":"https://jackchou.top/posts/bt2408/","summary":"一些无聊的定义，爱来自 BT.2408","title":"一个帮助理解 HDR 传递函数的小实验"},{"content":"目标 🚩 图像处理的目标之一是颜色再现（Colour Reproduction），当置身于实际场景中，接收到的光可能来自不同物体的反射、透射、散射及它们的混合，或者直接来自光源。它们的光谱千变万化，亮度也可能跨越很大范围。显示器则不同，它只能提供有限的亮度范围，光谱上仅能提供三种基色的混合。\n幸运的是，同色异谱和视觉对颜色感知的复杂性使得颜色再现成为可能，经过色彩科学的研究和发展，我们追求的已经不仅是亮度或色坐标的再现，而是颜色外貌（Colour Appearance）的再现，这需要色貌模型（Colour Appearance Model）的参与。\n色貌模型可以用来预测特定观察条件下，一个三刺激值的颜色外貌（明度、彩度等）。对于图像和颜色再现来说，需要考虑实际场景和显示器上截然不同的观察条件，传统的电影院能提供的亮度不过 48 nits，却能够再现出栩栩如生的各种场景，这部分是因为电影院提供了一个几乎无光的昏暗观察条件。\n通过正向色貌模型，从三刺激值计算出每一个像素的色貌，并根据显示器的观察条件应用逆向的色貌模型，预测显示器需要产生一个怎样的三刺激值来获得这样的色貌。这便是一个比较完整的利用色貌模型进行颜色再现的图像处理过程。\niCAM06 是 Jiangtao Kuang 等人提出的一种用于渲染 HDR 图像的色貌模型，其中用到了很多色貌模型的理论和算法，实现了比较科学的从大亮度范围的场景到显示器的图像处理。\n起点：输入 一个典型的色貌模型接受三刺激值和观察条件作为输入。\n三刺激值区别于更常见的 RGB 空间，是一种设备无关的空间，它独立于设备，观察条件一样的情况下，只要两个颜色的三刺激值相等，他们就能实现匹配（看起来一样）。而 RGB 是一个设备相关的空间，比如两个不同的显示器都显示一个纯红色，RGB 相等但颜色很可能不同，因为不同的显示器有不同的红色光基元。\n在传统的图像处理流程中，从 raw 图像出发，经过白平衡和色彩校正矩阵（Colour Correction Matrix），可以将颜色空间转换到 XYZ 三刺激值。一个常见的实现是在 raw 图像处理库 rawpy 中，使用 output_color = rawpy.ColorSpace(5) 指定输出色空间。\n需要注意的是，这样获得的 XYZ 并非实际场景中的三刺激值，而是已经经过白平衡（色适应）后的三刺激值。而我们需要的是能代表实际场景的颜色，因此，需要一个稍作修改的初始 ISP。\n从更底层的角度看，raw 图像是如何从光谱产生的？\n$$ R=\\int P(\\lambda)\\,\\bar{r}(\\lambda)\\,\\mathrm{d}\\lambda $$ 上式中是一个理想图像传感器的表达式，$P$ 表示光谱功率，$\\bar{r}$ 表示传感器的光谱敏感度，由光电二极管的光谱特性、滤色片的透过率等共同决定，$R$ 是输出的像素值，可以从 raw 文件中读取。\n而三刺激值的表达式可以写作：\n$$ X=\\int P(\\lambda)\\,\\bar{x}(\\lambda)\\, \\mathrm{d}\\lambda $$ 其中，$\\bar{x}$ 表示人眼的光谱敏感度。因此，如果可以从 $\\bar{r}(\\lambda),\\bar{g}(\\lambda),\\bar{b}(\\lambda)$ 线性组合出 $\\bar{x}(\\lambda)$ 等，我们就可以用相机的 raw 像素值估计三刺激值。这个线性组合的过程可以用一个 3x3 的矩阵表示。\n上图是一个利用线性组合从相机的光谱敏感函数预测三刺激值的示意图，经过线性组合的相机光谱敏感函数具有与三刺激值的光谱敏感函数相近的形状。\n另外，还需要一个系数进行缩放，转化为能代表绝对亮度的三刺激值，这个系数可以通过相机的光圈、快门速度、感光度计算得到，这些用于控制进光量的参数不会影响光的线性程度和相对关系。\n图像分解 按照视觉对颜色和细节的感知不同，将图像分解为基础层（Base-layer）和细节层（Details-layer）。对颜色的操作，比如色适应和色调压缩都只对基础层生效，细节层则经过增强或调整后合并到调整过的基础层上。\n基础层通过使用一种保边的双边滤波器获得，该方法由 Durand 和 Dorsey 先前提出。双边滤波是一种非线性滤波器，其中每个像素的权重由空间域中的高斯滤波和强度域中的另一高斯滤波共同决定，后者会降低与中心像素强度差异较大像素的权重。\n因此，双边滤波能在有效平滑图像的同时保持锐利边缘不受影响，从而避免了局部色调映射算子常见的\u0026quot;光晕\u0026quot;伪影现象。其中强度域是在对数空间计算的，对数空间中的强度更能代表感知对比度和对整幅图像更均匀的处理。\n细节层由原本的图像减去基础层获得，两层图像都需要转换回线性空间。\niCAM06 中使用的双边滤波通过分段线性近似和最近相邻降采样加速。\n色适应 一个物体在不同的光照条件和观察环境下，其颜色会发生变化，但是人类视觉系统可以在一定程度上保持对物体颜色的稳定感知。这种现象被称为颜色恒常性（Colour Constancy）。这种保持相对稳定的过程称为色适应（Chromatic Adaptation）。\n色适应变换（Chromatic Adaptation Transform，CAT）是用于预测对应色的模型。输入为两个观察条件（通常用场景白点的三刺激值表示）和一个观察条件下的颜色，预测在另一个观察条件下能够与之组成对应色的颜色。\n根据 von Kries 的假设，色适应在视觉器官的层面是独立的。色适应变换的基本结构为：\n将输入的 XYZ 转换到某个代表视觉器官的空间（锥体响应）。\n在这个空间内对每个量进行独立的处理（比如乘各自的增益系数）\n转回到 XYZ 空间，得到另一个观察条件下的颜色三刺激值。\n按照这个结构设计的色适应变换有很多，其中 CAT02 和 CAT16 是 CIE 先后推荐的两个色适应变换模型。在第二步中有一个适应度 D，代表了色适应的程度，iCAM06 中，把这个适应度乘以了一个 0.3 的系数，相当于降低了适应程度，更接近场景中的颜色而非适应后的对应色，来增加图像的颜色饱和度。\n这是非常奇怪的做法，我更倾向于是代码错误导致不乘这个系数会出现数值错误。因为原始代码中色适应一步用到的两个锥体响应，一个是归一化的，一个是绝对值。\niCAM06 中，这一步色适应的目标适应场是 D65，因为之后的几个均匀颜色空间都是设计在 D65 白点的，而适应场的白点选用的是基础层的高斯模糊，这有一点类似于灰度世界的假设。\n$$ \\begin{align*} D \u0026= 0.3 F \\left[ 1 - \\left( \\frac{1}{3.6} \\right) e^{-\\frac{(L_A - 42)}{92}} \\right] \\\\ R_c \u0026= \\left[ \\left( R_{D65} \\frac{D}{R_W} \\right) + (1-D) \\right] R \\end{align*} $$原文式中适应度 D 的计算里，$e$ 上的指数中 42 的正负号是错的。\n色调压缩 人眼感知亮度并不是线性的，而是高度非线性。按照这个非线性的特性进行色调压缩，可以在有限的亮度范围内再现出更大亮度范围的颜色外貌。\n这个非线性关系也是由视觉实验得到的，iCAM06 使用的是 CIECAM02 中的后适应部分，形如一个 Sigmoid 函数。使用时，从三刺激值转换到另一个代表视觉细胞的空间，再应用被称作“后适应”的响应曲线。在 iCAM06 中，还加入了暗视觉下杆状细胞的响应，叠加在锥体细胞的响应上，来预测暗视觉-混合视觉区间的亮度，杆细胞的响应非常小。\n锥细胞的后适应非线性关系如下：\n$$ R'_a = \\frac{400 (F_L R' / Y_W)^p}{27.13 + (F_L R' / Y_W)^p} + 0.1 $$这一步中用到的参考白 $Y_{W}$ 也是基础层的高斯模糊，但模糊程度比色适应时的更小。\n这一步完成了亮度的压缩，原本很大的亮度范围，经过这样的 Sigmoid 函数之后，范围是 0.1 到 400，实际上很少有超过 200 的情况出现。在这一步之前，都是和场景光保持线性，这一步之后则是和显示光保持线性，因此，这一步也可以理解成是一种光光传递函数（OOTF）。\n合并图像与输出 完成色适应和色调压缩之后，基础层已经是一个可以在屏幕上相对正常显示的图像，可以把细节层增强后合并回去。\n此时得到的图像仍然是在线性的 XYZ 三刺激值空间中，将 XYZ 转换到可以用于显示的 RGB 空间分为两步：\n转换到线性 RGB 空间 应用传递函数编码 对于最常见的 sRGB 空间来说，第一步用到的矩阵可以很方便的在网上找到，第二步则是一个 gamma 校正，系数为显示器 gamma 的倒数，通常取 0.45-0.5 之间。\n附加操作：IPT 空间 将一个高动态范围，高亮度的原始图像压缩到低亮度的显示器上，有时候其颜色会变得不那么鲜艳，明暗之间的对比也需要增强。\niCAM06 的解决方法是转换到一个均匀颜色空间中做增强，选用的是 IPT 空间，I 代表明度，P 和 T 是两个颜色方向，分别代表红-绿和黄-蓝。\n增强对比的方法是在明度上应用一个 1.0-1.5 之间的 gamma 指数，取值由观看环境决定。其原理是根据观看环境的相对亮度，感知对比度会发生变化，电影院这样的昏暗环境需要更高的对比度，因此通常采用一个较高的系统 gamma 指数。潜在的问题在于以往的系统 gamma 是施加在线性光的，而不是明度这样非线性的尺度。\n增强彩度的方法是对两个颜色方向拉伸，拉伸的程度与亮度有关，这依据了 Hunt 效应：亮度的增加会导致感知视彩度的增加。\n$$ P = P \\cdot \\left[ (F_L + 1)^{0.2} \\left( \\frac{1.29C^2 - 0.27C + 0.42}{C^2 - 0.31C + 0.42} \\right) \\right] $$\n结果与分析 该算法解决了两个问题：\n如何在显示器上再现真实世界的场景。 如何在传统的低动态范围显示器上再现高动态范围图像。 与计算机视觉不同，色彩科学更关注人类视觉感知，旨在从视觉角度处理图像。iCAM06 通过色彩适应、色调压缩和均匀色彩空间等方法，为从高动态范围到低动态范围的图像处理提供了一个可解释的解决方案。\n然而，iCAM06 也存在一些不足：\n色彩适应算法存在问题，校正后的效果不理想，可能是由于色彩适应模型的局限性和灰度世界假设的影响。 用于色调压缩的 Sigmoid 函数过度降低了图像对比度，无法平衡低动态范围和高动态范围输入的效果。 边缘保持变换和细节增强可能会引入伪影和过度锐化。 在均匀色彩空间中进行处理缺乏可靠的理论基础，特别是对明度应用伽马指数的做法。 总体而言，iCAM06 利用色彩科学的研究成果，提出了一种有效的高动态范围图像处理方法，是将色彩科学融入图像处理的成功探索。\nReferences [1] M. D. Fairchild and G. M. Johnson, \u0026ldquo;Meet iCAM: A next-generation color appearance model,\u0026rdquo; Proc. 10th Color Imaging Conf., vol. 10, no. 1, pp. 33–38, Jan. 2002.\n[2] J. Kuang, G. M. Johnson, and M. D. Fairchild, \u0026ldquo;iCAM06: A refined image appearance model for HDR image rendering,\u0026rdquo; J. Visual Communication and Image Representation, vol. 18, no. 5, pp. 406–414, Oct. 2007.\n[3] F. Durand and J. Dorsey, \u0026ldquo;Fast bilateral filtering for the display of high-dynamic-range images,\u0026rdquo; in Proc. 29th Annual Conf. Computer Graphics and Interactive Techniques (SIGGRAPH), San Antonio, TX, USA, Jul. 2002, pp. 257–266.\n[4] P. Hung and R. S. Berns, \u0026ldquo;Determination of constant hue loci for a CRT gamut and their predictions using color appearance spaces,\u0026rdquo; Color Research \u0026amp; Application, vol. 20, no. 5, pp. 285–295, Oct. 1995.\n[5] M. R. Luo and C. Li, \u0026ldquo;CIECAM02 and its recent developments,\u0026rdquo; in Advanced Color Image Processing and Analysis, C. Fernandez-Maloigne, Ed., New York, NY, USA: Springer, 2013, pp. 19–58.\n[6] M. D. Fairchild, \u0026ldquo;A revision of CIECAM97s for practical applications,\u0026rdquo; Color Research \u0026amp; Application, vol. 26, no. 6, pp. 418–427, 2001.\n","permalink":"https://jackchou.top/posts/icam06-survey/","summary":"颜色外貌在图像处理和再现中的简单尝试","title":"iCAM06：图像处理中的色貌模型"},{"content":"HLG OETF 的设计思路 $$ E'=\\left\\{ \\begin{array}{ll} r\\sqrt{E}, \u0026E \\leq 1 \\\\ a\\ln(E-b)+c \u0026E\u003e1 \\\\ \\end{array} \\right. $$ r 等于 0.5，三个常数 abc 的确定方法是，这个分段函数连续，导数相同，E 等于 12 的时候 E\u0026rsquo; 等于 1。\n也就是说，这样设计的 OETF 能承受 12 倍的参考白亮度。\nOOTF OOTF 中的两个光分别代表场景和屏幕，很多时候，OETF 和 EOTF 并不是互逆的关系，而是共同组成一个非线性关系来匹配不同的观察环境，比如一个负片的 gamma 可能是 0.6，打印时使用的 gamma 高达 3.0，共同组成一个高达 1.8 的“系统 Gamma”。SDR 电视可能有 1.2 左右的系统 Gamma，但对于 HDR 这样亮度分布广泛的显示，系统 gamma 需要分别调整。\n$$ \\gamma=1+\\frac{1}{5}\\log_{10}\\left( \\frac{Y_{\\text{peak}}}{Y_{\\text{surround}}} \\right) $$EOTF 严格来说，HLG 没有 EOTF 这种东西，而是使用 OETF 的逆函数与 OOTF 的组合，先把码值变换回场景线性光，然后直接应用一个 OOTF 得到显示线性光，因此，HLG 是完全场景参考的。\n$$ Y_{d}=\\alpha Y_{s}^\\gamma + \\beta $$ 其中，$Y_{s}$ 是场景线性光，由 RGB 和对应基元的转换矩阵计算得到（归一化的时候需使用 12，将场景线性光范围控制在 0-1），$\\alpha$ 和 $\\beta$ 作用与 Rec.1886 一样，控制了相对亮度和对比度，由屏幕的白点和黑位计算得到。\n$$ \\begin{align} \u0026\\alpha=L_{P}-L_{B} \\\\ \u0026\\beta=L_{B} \\end{align} $$与 SDR 的兼容性 由于前半段传递函数使用的是类似 gamma（约等于0.5）的形状，直接使用 Rec.1886 解码也可以获得一个相对线性的 OOTF。\n因此，把 HDR 部分丢弃，然后剩余部分看作 SDR 内容，即实现了与 SDR 的兼容。\n","permalink":"https://jackchou.top/draft/hlg-understanding/","summary":"一种似乎很高级的显示独立传递函数","title":"HLG 白皮书解读"},{"content":"什么是“图像” 图像本质上是一个“矩阵”或者“数组”，比如说最常见的图像可能是形状（Height，Width，Channel）的数组，每个位置上的数是八位量化的，用整型或浮点表示的 256 个不同的等级。这里面存的东西一般叫做码值或像素值（Code Value）\n编码 这个数组如果直接保存可能会很大，于是需要一些压缩的手段，即“编码”。编码的方式在不断更新，比如使用色度降采样、离散余弦变换（DCT）、霍夫曼编码等进行压缩的 JPG（JPEG）编码；又比如扩展性很强的 TIFF（*.tif）文件，它本身是一个容器格式，可以在内部调用 ZIP、LZW、PackBits 甚至 JPEG 等多种无损/有损编码；再比如比较先进的 HEIC（HEIF/HEVC）和 AV1 编码，它们具有灵活的分区结构、多模式帧内预测以及更高级的熵编码，能够实现非常高的编码效率。\n编码这个过程可能会带来一定的损失，即有损压缩。平时最常用的 JPG 标准就包含无损和有损两种工作模式，只不过无损模式几乎没有人在用。后来出现的许多编码方式同样支持无损压缩——AV1 甚至提供真正的无损档位——只要不是刻意追求极限压缩率，有损压缩带来的质量损失其实很难被察觉。\n不同编码方式的另一个区别是它们允许的量化位深。JPG 标准支持 8 位和 12 位量化，但 12 位模式同样很少见；更新的格式往往支持更高位深，例如 HEIC 和 AVIF 可以做到 10 位乃至 12 位，TIFF 容器内则可以存放每通道 16 位甚至 32 位（浮点）数据。这一点与 HDR 的需求密切相关：要在更宽的亮度范围内避免出现可见的色阶断层，就需要更高的量化精度。\n附加信息 只有一堆数字是没有意义的，还需要知道他们定义在什么空间上，至少要标注出三基色、白点和传递函数（也就是 RGB 空间的定义）。\n附加信息就需要告诉解码器和系统里的色彩管理，这些数字的具体含义，如果没有的话，一般会当成 sRGB 处理，颜色空间与实际不匹配的话就会出大问题。\n解码软件解出像素值和附加信息之后，颜色管理系统会把这些已知色彩空间的像素值转换成显示器的驱动值然后正确显示，所以理论上，码值甚至可以是三刺激值和线性的，只要有对应的附加信息来标注它。下面的图是两个标识了 XYZ 空间和线性传递函数的 PMCC 色卡，图片中的像素值直接是三刺激值。\n这是一个 D65 光源下的色卡三刺激值图像，其中超出 1 的部分进行裁切，实际上这是一种错误的处理，nclx 中的 CIEXYZ 需要以等能白为白点，可以选用 ICC 中的 Bradford CAT 来转换。\n这是适应到等能白的图片（用的是直接替换白点），由于适应到等能白，所以不会出现超过 1 的值，显示的时候，由系统的颜色管理将其色适应到显示白点上，因此看起来的效果应当与浅色模式下的背景接近，浅色模式的页面背景码值是 245。\n如果你在使用 iOS 或 iPadOS，可能看不到这两个图像，别的系统经测试基本都可以。\n附加信息的具体形式有很多种，比如嵌入 ICC 配置文件，或者是保存在图像文件里的 xml 语句或是 nclx，还可以存在 EXIF 里。\n这一步是实现 HDR 效果最关键的部分，标注了正确的传递函数之后，解码器就能把码值转换成能够超过 SDR 名义亮度的所谓“HDR”内容。\n有一种比较特殊的 HDR 实现方法：Gain Map，一个文件中保存了两幅图像（一个 SDR 图和一个增益图）和一些对应的附加信息（具体的增益系数等），解码器能够将两幅图像运算出一个新的 HDR 图像。所以增益图也许也可以算一种附加信息。\n显示参考的线性光 进行图像格式转换的时候，所有线性光空间指代的都应该是显示参考 Display referred 的。即计算出图像被显示之后在显示器上的光亮度（亮度或绝对三刺激值）。\n解码的时候使用 EOTF，编码的时候使用逆向的 EOTF 而不是 OETF（PQ 一类的传递函数会有区别）。\nPQ 或 HLG 传递函数 与 HDR 视频类似，将传递函数从 Gamma 或 709 换成 PQ 或 HLG，就能实现 SDR 向 HDR 的转变，对静态图像来说，已有国际标准 ISO-22028-5。\n佳能最早在微单引入了 10bit 的 HEIC 编码，使用 PQ 作为传递函数，索尼有 HLG 静态图像，在新版本的 ACR 中，启用 HDR 输出但不启用最大兼容得到的 AVIF 和 16 位 TIF 就是 PQ 编码的。\n对这种 HDR 图片，只需要应用正确的传递函数转换到线性光或从线性光编码即可。\nGainmap Gainmap 是专用于静态图像的一种实现 HDR 的方法，优点是非常好的兼容性，它可以同时保存 SDR 和 HDR 的内容（而不是依赖动态元数据及 TMO），并且对显示驱动非常友好。\nJPG，JXL，AVIF 都可以保存这种格式，尤其是 JPG，带有 Gainmap 的 JPG 实际上就是两个 JPG 文件首尾拼接起来，不支持这种格式的图片查看器直接读取第一张就是普通的 SDR 图片，在社交媒体选择发送原图后，还能保留后一张 Gainmap，即使 app 本身不支持，保存到别的 app 也有可能看到 HDR 效果。\nGainmap 最早大规模应用应该是 OPPO 的 Find X6 Pro，后来 Google 推广了 UltraHDR 格式，ISO 正在制定 ISO-21496-1 标准，UltraHDR 1.1 版本已经兼容了这一标准。\nGainmap 可以只写入亮度，也可以是三通道的，最近发布的 OPPO Find X8 Ultra 中的原彩 ProXDR 就是指代三通道 Gainmap。\nGainmap 可以理解为一种补充增强信息（SEI）或颜色重映射信息（CRI），记录了 SDR 和 HDR 源的区别，另外通过类似静态元数据的东西保存了 Gainmap 的绝对亮度关系。\n元数据包括：内容最大亮度增益（HDR 相比 SDR 亮多少），显示最大亮度增益（母版 HDR 相比 SDR 亮多少），编码 gainmap 时用到的 Gamma 和可选的偏移量。\n关于最大亮度增益和显示最大亮度增益，一个例子是 ACR 中的 HDR 限制器，可以将后期制作时的 HDR headroom 限制到 n 档，比如设置了一个三档的限制，那么后期制作时显示器的最大增益是三档，但内容可能有超过三档的亮度增益，只是被裁切了。设置这个显示最大亮度增益的元数据的目的可能是用于还原制作时的创作意图。\n关于 SDR 的名义亮度 虽然实际使用的时候很少遵守，但 SDR 其实是有规定的白点亮度的，比如 sRGB 是 80 nits，ITU-R BT.2035 里规定的是 100 nits。\n可以按照这个亮度将 SDR 内容转换成绝对亮度，再应用逆向的 EOTF 编码，更多时候使用的名义亮度是 203 nits，这个亮度源自 ITU-R BT.2408 对各种亮度的推荐值，其中漫射白为 203 nits，但也说明了不能把这个漫射白亮度理解为 SDR 的名义亮度。\n","permalink":"https://jackchou.top/posts/hdr-format-conversion/","summary":"Conversion of HDR still image formats","title":"HDR 图像格式转换"},{"content":" 提示：我没有自己使用过 Imatest（好贵），以下内容基于观看别人的分析结果后的主观和直觉。\nPipeline sRGB -\u0026gt; XYZ -\u0026gt; CIELAB (Display) \u0026lt;-\u0026gt; CIELAB (Reference)\n如上的测试是面向最终结果（输出的 JPG 图像）而非中间过程的，图像处理器里的流程会对色卡上的颜色产生不同的影响，也就是说，类似自动曝光（AE）也会影响结果。\n从最终输出的 JPG 图像出发（假设它是 sRGB 空间），先将其转换到 XYZ 三刺激值（使用对应色彩空间的转换矩阵和电光传递函数），此时得到的 XYZ 三刺激值是显示器参考（Display Referred）且归一化的，即和完美色彩管理或标准显示器上测量的三刺激值除以亮度相同。\n计算色差需要在均匀颜色空间内进行，将 XYZ 转换到 CIELAB 还需要一个参考白点（$\\text{XYZ}_{n}$），对于显示器参考的颜色来说，显示屏白点是一个常见的选择。\n色卡上的 CIELAB 值，通常直接可以查到，或者色卡公开了其反射率，使用标准照明体（通常是 D65）的光谱功率分布和标准观察者的颜色匹配函数可以计算出其 XYZ，再以 D65 做参考白点就能计算出其 CIELAB 值。\n然后在 CIELAB 上选一个色差公式计算色差，比如最常用的 DeltaE2000，当然也可以把 CIELAB 换成别的均匀颜色空间或者色貌模型来进行更多维度的对比。\n结果和分析 简单的计算所有颜色的平均色差是不合理的，能得出的结论非常有限（除非你的目标只有颜色的完全再现）。\n白平衡和色适应 如上计算出的色卡的 CIELAB 值中，灰阶的 Chroma 应该接近 0，而实际图像中的灰阶 Chroma 是否也是接近 0 则取决于拍摄光源和相机的白平衡处理。如果相机的白平衡完全矫正了光源（相当于完全适应到 D65），那么图像中色卡的灰阶部分也应该表现出中性色。\n但白平衡算法不一定会将所有的拍摄环境都进行完全色适应，这也与我们的主观感觉不符，最典型的例子是白炽灯，这种昏黄的光源下不会表现出完全的颜色恒常性，此时比较理想的颜色再现是保留一部分“黄色”，即不完全适应，那么图像中色卡中的灰阶部分就不是中性色，而是具有一定的彩度。\n在需要完全适应到 D65 的情况下（灰阶应该呈现出中性色），可以用灰阶区域的彩度偏差 $\\Delta C$ 描述白平衡是否准确。\n如果图像的白点不是 D65，白平衡的目标光源应该是这个白点，此时需要考虑 CIELAB 中错误的色适应变换是否会有影响（CIELAB 应该仅在 D65 下工作）。\n风格化 因为测试图像已经进行了整个图像处理流程，自然也会包含一些风格化，比如记忆色增强或是一些比较复杂和强烈的处理。此时再评价颜色是否“准确”就显得有些不合理了，不过仍可以通过比较色卡的标准色和图像中色卡的颜色来观察典型颜色向哪一个方向移动和调整。\n需要注意的是，这时候就不应再评价颜色是否“准确”，而且由于相机不符合所谓 Luther 条件，在将相机的 RGB 转换到 XYZ 的时候就已经存在不小的误差。用色卡自己训练，自己检验，在 RAW 转出来的 XYZ 上计算色差一般都不会小于 3，之后各种风格化、空间转换、色域和色调压缩只会引入更多的误差，因此，在判断是否准确、风格化倾向时，需要考量是由误差引起的，还是由风格化引入的。色差累积的过程也不是一直向一个方向的，有可能最终的色差反而会变得很小，甚至出现个别颜色的色差小于 1 的情况，也不能代表这个相机在其他情况下还原该颜色时是否还能这么准确。\n分析风格化的时候，可以用图像的平均彩度与色卡的平均彩度之比来观察图像整体的彩度是否增大了，以及观察每一个典型颜色的偏移，或转换到 CIELCh 和别的空间进行更深入的分析。\n自动曝光和亮度 相机的自动曝光策略也会影响色差，而且最终图像变换回的 XYZ 是 Display Referred 的，相对色卡上的反射率，原始场景的亮度不一定线性，在这个显示器参考的 XYZ 上乘系数假装增益不能代表拍摄时候的曝光控制，更像是在调节显示器的背光亮度（但不同步调整计算 CIELAB 时选用的参考白点），这是一个很奇怪的操作，但可以有效的降低因为曝光错误导致的色差异常，下面这个实例中，通过在 XYZ 上乘一个 0.76 的系数，能降低三个色差单位（可能只在计算上有意义）。\n因此，Imatest 中也提供了不含亮度的彩度差，只计算彩度上的差距，不考虑明度的影响，这似乎更加奇怪（因为改变背光亮度或曝光控制这样的操作也会影响彩度）。\n不均匀的光照和同色异谱 拍摄色卡时，能够有一个均匀的光照是再好不过，但使用灯箱的时候，不可避免的会出现上面更靠近光源而更亮的情况。使用上面提到的模拟亮度调整后，可以观察明度差别，如果发现前几排都为正值，底下几排都是负值，就需要考虑是否是由于不均匀的光照导致的。\nRAW 上的修正方法是用一个均匀的表面（灰卡或是哑光相纸）来矫正，但现在图像已经是走完整个 ISP，得到的线性光是显示器参考的，不能够代表场景参考那边的线性光。\n关于同色异谱问题：色卡提供的 CIELAB 是由反射率和 D65 标准照明体计算出来的，但是实际上并不存在一个光源的光谱功率分布和标准照明体相同，相机的光谱敏感函数经由颜色矩阵校正后和标准观察者的颜色匹配函数也有差异，因此同色异谱是不可避免的，这也会导致色差的错误增加，因为色卡不仅评价了相机的颜色还原，一定程度上也评价了光源的显色指数和相机的同色异谱现象。\n色卡和颜色分析 色卡在图像处理和评价中到底起到了什么样的作用，那些各种空间里的数字又有什么含义。\n对我来说，色卡最大的价值在于提供了 30 个很典型的反射率样本，包括了记忆色，饱和色和中性色，标准照明体、标准观察者的光谱数据都可以很方便的获得，从而进行很灵活的三刺激值计算，这远比一个只能在 D65 下使用的 CIELAB 更有意义。\n这也是为什么更推荐使用 PMCC，因为其反射率是公布和发表的，理论上你甚至可以不拥有实际的色卡，只当作 30 个反射率样本来用就可以。\n另外，我觉得直接对色卡图片进行主观的颜色评价是很不合适的，脱离了实体，记忆色的效果应该微乎其微，观察一个蓝色的色块真的能够联想到蓝天，并进行记忆色增强吗？对于观察者来说，通过看三十个颜色方块，就评价颜色是否自然，甚至评价颜色是否准确是很不合理的。\n另外，用各种颜色空间和色貌模型进行分析的时候，应该注意专业术语的用词，而不是随意的使用“饱和”，“鲜艳”。既然用了色貌模型，就应该使用准确的颜色属性来描述。\n色卡的有关数据和文章可以在这里找到：\nM. R. Luo, “The new preferred memory color ( PMC ) chart,” Color Research \u0026amp; Application, p. col.22940, May 2024, doi: 10.1002/col.22940.\n简单实践 这是一张由相机自动白平衡、自动测光拍摄的色卡，照明条件是普通的白光 LED，不是标准照明体模拟器或全光谱 LED。\n直接按照上述方法计算色差，得到的平均 $\\Delta E_{2000}$ 色差是 6.5，几乎所有的明度都偏高，也就是按照使用屏幕白点做参考白，图像偏亮，在 XYZ 上乘以 0.76 后，得到的色差最小，为 3.8，这个操作是在不改变屏幕亮度的情况下调暗图像，等效于降低背光亮度但不调整计算 CIELAB 时的屏幕白点。\n意思是降低屏幕亮度观察上面那个图，和不降低屏幕亮度看这个图是一模一样的，但算出来的色差会不一样。\n对灰阶和明度的分析 具体到每一个颜色的色差，原图中的白色块色差只有 0.83，而降低亮度后则有 6.01。灰阶上，第二和倒数第二色块与参考间的明度差几乎为 0，白色和黑色的明度低于参考，中间两个色块的明度则高于参考，意味着 ISP 中可能包含了一个增加对比的形如 Sigmoid 的色调曲线。\n","permalink":"https://jackchou.top/posts/colour-checker-for-jpg/","summary":"观摩学习用 Imatest 和色卡分析图像颜色的读后感","title":"并非色差：用色卡评价最终输出图像"},{"content":"读取 raw 数据的工具 Dcraw 最著名的读取 raw 数据的工具莫过于 dcraw。Dcraw 能够将各种编码方式的 raw 文件转换成 TIFF 或 PPM 格式。\n使用命令行 dcraw -4 -T -D file_name 就能够获得一个 16 bit 的 TIFF 文件，记录了 raw 的直接数值，没有经过包括解拜尔、白平衡、扣除黑电平在内的操作。\n遗憾的是，dcraw 的最后一次更新是 2018 年 6 月 1 日。因此之后相机的附加参数（白平衡，颜色矩阵等）不再包含，仅用于提取 raw 数据的功能也不一定能够正常使用。\n比如说：对于索尼在四代机（ILCE-7M4）中加入的无损压缩 RAW 格式，虽然后缀名都是 arw，但 dcraw 会报 cannot decode file 的错误，而和之前一样的无压缩 RAW 是可以解的。\ndcraw.c 是 dcraw 的核心文件，由一万多行纯 c 语言完成。\nRawpy/Libraw Rawpy 是 libraw 的 python warpper。Libraw 提供了访问 raw 数据的统一接口，用于提取像素值，它基于 dcraw，将 dcraw.c 重构为更现代和模块化的库，并在 dcraw 停止维护后继续支持。\n各方法和品牌的差别 Sony 无压缩 RAW 测试机型是 ILCE-7 CM2：\n以下方式读取的无压缩 RAW 结果是一样的：\nDcraw 转 tiff 后用 openimageio 读取 直接用 rawpy 读取 用 adobe DNG converter 转换后用 rawpy 读取 用 adobe camera raw 转换后用 rawpy 读取（同上，虽然在 acr 中查看尺寸时不同） 用 adobe DNG converter 转换后，用 dcraw 转 tiff 再用 oiio 读取 以上方法读出的尺寸是 (4688, 7040)，33003520 像素，范围是 0-16383.\n实际上，用 adobe dng converter 和 adobe camera raw 转换的 dng 是一样的，以下不再赘述。Rawpy 和 dcraw 读取 dng 也是等效的。\n以下是会发生变化的：\nCaptrue One 转换 dng 后，用 rawpy 读取（或用 dcraw 转 tiff 再读取）。图像会变成 (4672, 7008) 范围是 0-65535。高少的 16 个像素是上下各 8 个，长少的 32 个像素是左 12 右 20。裁切后和上面几种方法也有区别，按照商（都归一化，按照 65535 或 16383）来看，最大 1.04，最小 0.95，平均 1.00。这个对齐是在 ps 里用肉眼完成的。 无损压缩 RAW 索尼的无损压缩 RAW 原理是先补 0 到 512 的倍数，然后分块，再按照 bayer 分四个子图进行差分编码和霍夫曼编码。\n对于无损压缩 RAW 来说，情况比较复杂，因为目前没有办法在无压缩的 ARW 和无损压缩的 ARW 间转换（如果分两次拍，即使使用联机拍摄，带来的位移等误差也大于一个像素）。以下是经过测试的情况：\nDcraw 不支持无损压缩 RAW（因为索尼引入无损压缩 RAW 时 dcraw 已不再更新）。 Rawpy 读取 ARW，得到的是 (5120, 7168) 尺寸，这是由于分块压缩导致的（512 的倍数），只有左上角 (4688, 7040) 区域有内容，剩下的是 0（而不是黑电平），数值是 0-16383。 用 adobe DNG converter 转换成 dng 后用 rawpy 读取，得到的尺寸是 (4686, 7038)，比无压缩 RAW 等少两个像素。上一种情况中再去掉底部和右边各 2 像素，可以完全匹配，也是 0-16383。 用 Capture One 转换出的 dng 用 rawpy 读取，得到的尺寸也是 (4672, 7008)，范围 0-65535。同样是上下 8 像素，左 12 右 20，裁切 rawpy 读取的 ARW 的有内容部分后基本匹配（甚至差值的平均值都是一样的 -5e-6 左右，需要进一步测试）。 关于 Capture One 的 DNG 理论上，一个解码 RAW 并编码到 DNG 的编解码器不会带来太复杂的误差。但 Capture One 导出的 DNG 不仅尺寸有区别，还会将原本 14 bit 的数据拉伸到 16 bit，且不能与其它方法读的 raw 完全匹配。\n在 Gemini 和 DeepSeek 的帮助下，进行了一些更细致的分析。关于如何从 14 bit 到 16 bit，Capture One 进行的应该是左移两位，即直接 *4。将 rawpy 读取的 arw 左移后与 C1 导出的 dng 相除与相减，得到的商为 1.000004，差也是 e-7 的数量级。其中，R 和 B 通道是完全匹配的，误差全部来自两个 G 通道，而且和图像内容有关，个别图像中，G 的最大误差甚至能达到 10%，多数情况下，最大误差不超过 5%。\nSony RAW 的最佳实践 综上，最推荐的 Sony RAW 使用方法是拍摄无压缩的 RAW 之后直接用 Rawpy 读取，用 dng converter 可以方便的把无压缩 RAW 转换成无损压缩的 DNG 来减少体积，同时不会有任何损失，或是无损压缩 RAW 用 Rawpy 读取并做裁切，但注意无损压缩 RAW 转换成 DNG 时会损失两行两列像素。而其它方法获得的 DNG 存在未知因素，不应使用。\nCanon 测试机型是 600D，输出的是 CR2。\n用 rawpy 和转成 dng 之后读取是一致的，图像尺寸是 (3516, 5344)，左边 142 像素和上方 51 像素应该是光学黑场（被物理遮盖用于黑电平校正的部分），能读出近似黑电平的数值，剩余部分是图像。\nDcraw 是可以处理 600D 的，读出的是没有光学黑场的部分，这一部分和裁切后的 rawpy 或 dng 匹配。\nR6 Mark 2 输出的 CR3 （用 rawpy 或转成 dng 读取）也类似，左侧 154 个像素、顶部 96 个像素是光学黑场，另外右侧还有 8 个像素的白色区域。\nHasselblad 测试机型为哈苏 X2D-100C，相机直接输出 3FR 格式的 RAW 文件。其传感器型号可从 3FR 文件中直接确认，为索尼 IMX461-BQR。\n哈苏的 RAW 工作流历史上涉及 3FR 和 FFF 两种文件格式。\n随着新版 Phocus 的发布，FFF 文件已被移出 RAW 工作流，现在无需先转换到 FFF 再处理 RAW 图像。\n在旧版流程中，用户可以通过 Phocus 软件将 3FR 转换为 FFF。转换时有一些可选的调整选项，但这不影响 FFF 文件本身的原始数据（例如，使用 rawpy 读取的结果都相同）。从文件头可以发现，3FR (49 49 2A 00) 遵循小端序 TIFF 规范，而 FFF (4D 4D 00 2A) 则是大端序 TIFF。\nIMX461-BQR 的公开规格显示，其总像素为 11760×8896，有效像素为 11664×8750。然而，使用 dcraw 或 rawpy 等工具直接解析 3FR 文件，会得到一个 11904×8842 的超大图像。这个图像包含了以下几个区域：\n图像内容区： 尺寸为 11664×8750，与 461 的有效像素一致。 光学黑场 (Optical Black)： 包围在图像内容区外，左右各 48px，上方 90px。 额外内容： 在最外围，包含左侧 76px、右侧 68px 和上方 2px 的非图像数据。 分析可知，包含光学黑场在内的图像宽度为 11760px（与传感器总像素宽度吻合），但高度为 8840px，略有出入。\n无论是 3FR 还是 FFF，都可以转换为 DNG 格式，转换后的 DNG 文件尺寸会裁切到与有效像素区一致，内容上，虽然画面内容能够对齐，但数值上有一些小区别。\n所以目前来看，处理哈苏 3FR 文件的最佳实践是直接使用 libraw 读取，提取出有效的图像区域，并利用图像中的光学黑场数据进行精确的黑电平校正。\nFujifilm 测试机型是 X-T5。\n富士的 raw 比较特殊，因为其表面的滤色片不是普通的拜尔排列，而是 X-Trans，最小重复单元是 6 行 6 列。好在不影响我们分析 raw 图像本身。\n把 RAF 直接输入 rawpy，得到的图像长 7872，高 5196，转换成 DNG 后，长 7728，高 5152。多出来的长 44 个像素，高 144 个像素具体分布是：\n左侧 12 个有画面的像素，右侧 12 个有画面的像素和 120 个黑。 顶部 16 个有画面的像素和 5 个黑，底部 16 画面 7 黑。 重叠部分的像素值是完全一样的。\n另外，rawpy 读取 raf 的 raw pattern 有错误，dng 中的 raw pattern 是正确的。\nNikon 待续\n发现研究这个收益实在是太低了，还要学习很多东西，等粗浅的搞完 Nikon 就暂停。在实际使用中，推荐直接用 dng convertor 转换成 dng，用 rawpy 读取，可以直接获得图像内容。\n","permalink":"https://jackchou.top/posts/how-to-read-raw/","summary":"跑得快不一定赢，不跌跟头才是成功","title":"如何正确读取 RAW 文件"},{"content":"亮一点，再亮一点 印象中，从 Realme GT 5 Pro 开始，手机屏幕的峰值亮度开始变得越来越“浮夸”。\n屏幕亮度遥遥领先，突破行业新纪录。全新发光材料搭配狂暴调教算法，不惧耀眼日光，真实还原明暗。——真我 GT 5 Pro\n其峰值亮度已经达到 4500 nits 这样惊人的数值，但这是“局部峰值激发亮度”，只有在很苛刻的条件下（HDR 内容，强光激发，小窗口）才能做到，也几乎没有任何实用价值。很坏的是，这种没有价值的高亮度成为了宣传上的重点和各家竞争的关键，甚至可以在产品参数页里只写这一个亮度（峰值亮度 6000 nits 的真我 Neo 7 表示甚至可以不写亮度）。\n之后，亮度战争蔓延到全屏激发、全屏手动亮度，比如一加和小米都提供了额外的阳光模式，允许用户把手动亮度调的更高。各家的宣传口径把高亮度不约而同的叫做“阳光屏”，认为高亮度在手机上最实用的场景是提升高亮环境下的可读性。\n亮度对抗照度 屏幕在高亮度下的可读性是很复杂的，和显示的内容、电光传递函数都有关系，而且是一个主观的心理物理量。一个最简单的量化方法是对比度，即屏幕不显示内容时的亮度和显示一个白色时的亮度，此处的亮度是考虑了屏幕反射环境光的综合亮度。\n$$ \\text{luminance}=\\frac{\\text{illuminance}*\\text{reflectance}}{\\pi}+\\text{display luminance} $$上式中的反射率是 SCI 反射率（包含镜面反射成分），假设屏幕处于一个无限大且均匀的穹顶光照下（比如户外），所以可以用除以 $\\pi$ 的方式估算反射光的亮度。\n随着照度的提高，对比度会很快的下降（注意下图的 y 轴是对数坐标的），使得室外的屏幕可读性不好，表现为看不清，或者觉得屏幕不够“通透”。\n常见的晴天户外照度约为 50000 lx，无镀膜的玻璃包含镜面反射的反射率约为 5%，这种情况下，对比度仅有 2 左右，且增加屏幕亮度的效果有限。\n另辟蹊径：降低屏幕反射率 从上面的计算方法可以看出，提高对比度不仅有提高亮度一种方法，还可以降低屏幕的反射率，可以通过镀膜实现。实际上，iPad 很早就有抗反射涂层技术，也经常出现在各种对比测试里，它的反射图案呈现一种较暗淡的紫红色，但 iPhone 上是没有的（也许是出于耐用性或是微晶玻璃不容易做镀膜的原因）。三星在手机上已经应用，vivo 在 X100 Ultra 上进行了一次尝试，向用户提供一种带有抗反射涂层的手机膜。\n通过这种技术，屏幕的反射率可以降低到低于 2%（按照 DxO 的测试）。降低屏幕反射率对提高对比度是相对高效的，其效果相当于把屏幕亮度提高到 4000 nits 以上。\n值得注意的是，现在手机几乎所有传感器都在屏幕或保护膜以下，vivo 提到了由于更低的反射率，贴了抗反射膜的手机需要刷特别的固件来重新标定传感器。\n一点发现和猜测 用积分球测量的包含镜面反射的反射率，结果和 DxO 是接近的。刚好有一台崭新出厂的 iPhone 16 Pro，其反射率显著的高于久经沙场的裸奔 Find X6 Pro，猜测是微晶玻璃（也就是超瓷晶面板）的特性所致。\n还有一些手机出厂就搭配了磨砂表面，比如一些类纸的手机，他们的不包含镜面反射的反射率自然会显著的更高，而包含镜面反射的反射率和正常手机差不多。\n另外，以上测量都是把屏幕擦的干干净净之后测量的，如果屏幕沾染上指纹、油污，反射率都会显著增高，尤其是带来一些不理想的纹理和各向异的杂散光。一些实体店里的手机被很多人把玩过，或者是没有清理屏幕的习惯，屏幕的显示质感都会变得糟糕。\n一台久经沙场和被邦邦摩擦过的 iPad Pro 2021 配备有抗反射涂层，反射率约在 2%，但在 400 nm 以下反射率会飙升到 20% 左右。相较 Find X6 Pro，反光更暗，更蓝。\niPhone 17 和未来 之前我测试到，崭新出厂的 iPhone 16 Pro 是没有抗反射涂层的，其反射率很接近普通的玻璃表面。而在 iPhone 17 系列，苹果特意提到：\n这是 iPhone 迄今最出色的 6.3 英寸超视网膜 XDR 屏。峰值亮度达 3000 尼特，ProMotion 自适应刷新率最高达 120Hz，反光也减少了 33%。\n根据上手的图片和视频来看，iPhone 17 系列也是用上了新型的抗反射涂层。而 IQOO 提到，将在 IQOO 15 出厂时，自带一张 AR 抗反射的贴膜。\n同时，越来越多的显示器和电视，也都用上了这种技术，比如海信的“黑曜屏”一方面就是指关机时看起来“黑”，也是由抗反射技术实现的。随着供应链技术成熟，抗反射技术应该会很快造福更多产品和用户。\n","permalink":"https://jackchou.top/posts/display-reflectance/","summary":"可能是比遥遥领先的屏幕亮度和狂暴调教算法更有效的提升","title":"反射率：高亮环境可读性的第二条路"},{"content":" 观前提示：抽象和中二的部分都是 DeepSeek R1 写的，它还有更多更离谱的。\n《ISP 锻造入门：从零开始铸造你的「原神之眼」RAW 处理器》 《博士，你甚至不肯叫我一声 ISP：三原色与勇者傻瓜套装》 《像素工程师修炼 Day1：如何让 RAW 的野生 RGB 臣服于人类の色彩暴政》 §0. 序章：勇者的觉醒——在像素荒原上捡到一本《ISP 入门指南》 ISP（Image Signal Processor）负责将传感器输出的 RAW 图像转换为在屏幕上显示的图像。通常涉及各种颜色空间的转换，处理和映射。\n这个系列将从最基础的 ISP 开始，逐渐加入模块来解决遇到的问题，提高图像质量。\n接下来将实现一个最基本的两步 ISP，获得初始武器。\n§1. 理想的 RAW 图像 理想的起点是范围在 0-1 之间，0 代表没有输入，1 代表传感器的饱和值的三通道图像。但相机吐出的 RAW 图像是有黑电平补偿、没有解拜尔阵列、经过相机厂商编码的私有格式。\n好在已经有很多开源工具能够帮我们完成这些预处理，比如 dcraw、libraw 等。Rawpy 是一个 Python 包装的 LibRaw，使用下面的代码可以将 RAW 图像读取为一个比较理想的 numpy 数组：\ndef read_raw_image(path): with rawpy.imread(path) as raw: rgb = raw.postprocess( gamma=(1, 1), output_bps=16, use_auto_wb=False, use_camera_wb=False, user_wb=[1, 1, 1, 1], output_color=rawpy.ColorSpace.raw, no_auto_bright=True, half_size=True, ) rgb = rgb / 65535.0 return rgb 这里的 rgb 是一个三维的 numpy 数组，形状是 (H, W, 3)，H 和 W 分别是图像的高和宽。是经过预处理的理想 RAW 图像。\n如果直接编码成图像，得到的就是“原图”。\n§2. 从 RAW RGB 到 XYZ 请看前传：颜色空间转换：RAW 与 XYZ。\nCCM（Color Correction Matrix）是一个 3x3 的矩阵，用于将 RAW RGB 转换为 XYZ。\nccm = np.array( [[1.297, 0.558, 0.0596], [0.0793, 0.569, -0.1675], [0.1033, -0.1577, 1.2465]] ) cameraRGB_2D = cameraRGB.reshape(-1, 3) XYZ_2D = np.dot(cameraRGB_2D, ccm) XYZ = XYZ_2D.reshape(cameraRGB.shape) 此处两步 reshape 是为了进行矩阵乘法，如果之后还需要进行其他操作，可以暂时保留向量形态。\n此时得到的 XYZ 是对拍摄环境中三刺激值的估计，于是，从相机各自不同的光谱响应转换到了一个统一的颜色空间。这里的操作并不考虑三刺激值的绝对值，如果要对整体亮度调整，在 XYZ 上进行操作是比较合理的，比如乘上一个系数来模拟曝光补偿。\n§3. 从 XYZ 到 sRGB 请看前传：颜色空间转换：XYZ 与 sRGB。\nM_XYZ2sRGB = np.array( [[3.2406, -1.5372, -0.4986], [-0.9689, 1.8758, 0.0415], [0.0557, -0.2040, 1.0570]] ) sRGB_linear_2D = np.dot(XYZ_2D, M_XYZ2sRGB.T) sRGB_linear = sRGB_linear_2D.reshape(cameraRGB.shape) sRGB_linear_clipped = np.clip(sRGB_linear, 0, 1) sRGB = np.where( sRGB_linear_clipped \u0026lt;= 0.0031308, 12.92 * sRGB_linear_clipped, 1.055 * np.power(sRGB_linear_clipped, 1 / 2.4) - 0.055, ) 这里的操作包括色彩空间转换和 OETF（光电传递函数），将 XYZ 转换为 sRGB 空间。sRGB 是一个 0-1 之间的三通道图像，可以直接显示在屏幕上。注意在应用 OETF 之前，需要将线性空间的 sRGB_linear 限制在 0-1 之间，这一步实际上是将超出色域的颜色直接裁切，保证色域内的颜色绝对再现，是一种最简单的色域映射方法。\n§4. 初始武器锻造报告 至此，我们已经完成了一个最基础的 ISP，虽然简单，重要的是它每一步都有色彩科学的理论支撑。\n为了展示这个 ISP 有多脆弱，我们点亮这盏灯，就能遇到的第一个问题。\n高光溢出：当超出传感器的饱和值，传感器将其记录为（1, 1, 1），这样的像素在经过初始版本的 ISP 处理后，变成（1, 0.8, 1），呈现粉色。一种简单粗暴的解决办法是在 cameraRGB 上检测是否有饱和像素，如果有，就直接显示白色。\n之后，我们将补齐初始版本省略的模块，解决会遇到的各种问题，并逐渐提高图像质量。\n","permalink":"https://jackchou.top/posts/isp-01/","summary":"解密 RAW 色彩密码本：CCM 参数炼成与 sRGB 传送门构建方法论","title":"转生 ISP 异世界 Day0：误入 RAW 森林的我用 3x3 魔法阵召唤 RGB"},{"content":"复习：XYZ 三刺激值 XYZ 是色彩科学最重要的颜色空间，色貌模型、均匀颜色空间、各种 RGB 空间都是从 XYZ 出发的。XYZ 由光谱辐射亮度和颜色匹配函数相乘得到，即：\n$$ X = k \\int_{\\lambda} P(\\lambda) \\bar{x}(\\lambda) d\\lambda $$其中，$P(\\lambda)$ 是光谱辐射亮度，$\\bar{x}(\\lambda)$ 是标准观察者的颜色匹配函数，$k$ 是归一化系数。\n光谱敏感函数 绝大多数相机用滤色片将光分为三个通道，滤色片的透光率和光电二极管的波长响应共同决定了三个通道对不同波长的光的敏感程度。这个与波长相关的函数称为光谱敏感函数（Spectral Sensitivity Function）。\n仿照 XYZ 的计算过程，一个理想传感器输出的像素值可以由下式计算：\n$$ R = k \\int_{\\lambda} P(\\lambda) \\bar{r}(\\lambda) d\\lambda $$其中，$\\bar{r}(\\lambda)$ 是红通道的光谱敏感函数，k 是一个系数，$P(\\lambda)$ 可以是传感器上的光谱辐射照度。\n传感器接收到光的多少不仅由光强决定，还和相机的快门速度、镜头的光圈大小有关，为方便起见，都由 k 统一表示。\n线性变换？ XYZ 和 RAW RGB 都是线性空间，并不意味着他们可以直接通过一个矩阵线性变换，但可以近似的进行变换，即 ISP 中的 CCM（Color Correction Matrix）。\n由上面的公式不难注意到，能够用一个 3x3 的矩阵完成 RAW RGB 到 XYZ 变换的条件是：\n$$ \\begin{aligned} \\bar{x}(\\lambda) = a_{11} \\bar{r}(\\lambda) + a_{12} \\bar{g}(\\lambda) + a_{13} \\bar{b}(\\lambda) \\\\ \\bar{y}(\\lambda) = a_{21} \\bar{r}(\\lambda) + a_{22} \\bar{g}(\\lambda) + a_{23} \\bar{b}(\\lambda) \\\\ \\bar{z}(\\lambda) = a_{31} \\bar{r}(\\lambda) + a_{32} \\bar{g}(\\lambda) + a_{33} \\bar{b}(\\lambda) \\end{aligned} $$如果不能满足上面的条件，可以用最小二乘法求解一个最优的 CCM 矩阵。\n参考实现 以下是一个相机的 SSF（来自一个早期实验，不能作为实际用途），因为我也不知道测的到底准不准。\n通过最小二乘法求解用这个 SSF 线性组合出 CIE 1931 XYZ CMF 的 3x3 矩阵：\n$$ \\begin{bmatrix} 1.297 \u0026 0.0793 \u0026 0.1033 \\\\ 0.558 \u0026 0.569 \u0026 -0.1577 \\\\ 0.0596 \u0026 -0.1675 \u0026 1.2465 \\end{bmatrix} $$用该矩阵将 SSF 转换为一个近似的 XYZ（用 Estimated XYZ 表示）：\n一些问题和待续 以上内容基于的假设：RAW 是线性的，相机的光谱响应范围是 380-780nm 等。 改进 CCM 的方法。 不使用 SSF 建立 CCM 的方法。 衡量 CCM 质量的方法 CCM 的目的是将 RAW RGB 转换为 XYZ，我更喜欢的描述是用 RAW 数据“预测”XYZ，衡量 CCM 质量的本质是看预测的是否准确。对 XYZ 来说，可以找一个色差公式计算预测值和真实值的差异。使用的颜色样本通常包括中性色、饱和色和常见物体的颜色，比如肤色、天空、植物等。这些“重要”的颜色也就是色卡上的颜色，最著名的色卡是 Xrite 的 ColorChecker Classic，包含了 24 个色块，但爱色丽没有公布过他们的反射率数据，不利于做理论计算，一个更好的选择是 PMCC (Preferred Memory Color Chart)，它包含了饱和色、中性色和 18 种经典的记忆色，且提供了光谱反射率。\nM. R. Luo, “The new preferred memory color ( PMC ) chart,” Color Research \u0026amp; Application, p. col.22940, May 2024, doi: 10.1002/col.22940.\n计算这 30 个颜色样本的预测 XYZ 和真实 XYZ 的色差，就能衡量 CCM 的质量。通过更换不同的光源（常见的选择是 D65，A 和 CWF 或 TL84），可以衡量 CCM 在不同光源下的表现。\n","permalink":"https://jackchou.top/posts/ccm-02-raw-xyz/","summary":"RAW 到 XYZ 的转换","title":"颜色空间转换：RAW 与 XYZ"},{"content":"RGB 颜色空间 RGB 颜色空间几乎是最常见的颜色空间，它是一个加色系统，通过三个基色的混合来描述其中的颜色。最常见的 RGB 颜色空间是 sRGB（standard Red Green Blue），由惠普和微软在 1996 年共同推出，并逐渐获得各行业和软件的广泛支持。\n以 sRGB 为代表的 RGB 颜色空间主要包含三部分定义：色度学上的 RGB 及白点定义、非线性传递函数和观看环境。例如，sRGB 定义红、绿、蓝三基色的 xy 色度坐标为（0.64, 0.33）、（0.30, 0.60）、（0.15, 0.06），白点坐标为（0.3127, 0.3290）；采用一个近似 Gamma 2.2 的传递函数；以及观看环境的照度、环境反射率甚至炫光。\n具体请看 sRGB 的定义。\n按照定义的前两部分：三基色和白点，传递函数，可以得出转换的顺序是 RGB -\u0026gt; 线性 RGB -\u0026gt; XYZ。其中，线性 RGB 到 XYZ 的转换通过一个矩阵实现，这个矩阵实际上描绘了三基色在 CIEXYZ 中的位置以及他们以何种比例混合出白点。\n构建转换矩阵 关键：确定三基色的“比例” 定义中只给出了三基色的“色度坐标”，色坐标是没有亮度信息的，假设我们现在有 RGB 三色的 LED 光源，调节他们的亮度，能混合出不同的颜色，现在，我们希望找到一个比例，使其混合后产生定义中的白点色坐标。\n一种简便的方法如下（由 Claude 3.7 Sonnet 提供）：\n首先将三原色及白点的亮度预设为 1 (Y=1)，并计算出它们对应的 CIEXYZ 值（从 xyY 计算 XYZ）。\n由于 CIEXYZ 是线性的，求解此时亮度为 1 的三基色按何种比例能加出白点，得到三基色的实际 XYZ。\n按照矩阵乘法的定义，将三基色的线性组合用矩阵描述，构建出转换矩阵。\n色度坐标的混合 以下是我思考这个问题时候写的繁琐过程，上面那个方法足够简洁和直观，您可以直接跳过下面的内容，继续阅读传递函数部分，放在这里纯粹是因为我不舍得删。\n如何确定三个色度坐标混合后的新色度坐标？\n首先，将 xy 色坐标变换到 CIEXYZ 三刺激值，Z 在后续的混合中不重要，此处省略其变换，而 Y 就是我们要找的比例。\n$$ \\begin{align*} \u0026X+Y+Z=\\frac{Y}{y} \\\\ \u0026X=x(X+Y+Z)=\\frac{xY}{y} \\\\ \\end{align*} $$给三个分量添加下标来表示，无下标的则表示混合后的颜色，CIEXYZ 是线性的，可以加和，此处计算了混合后颜色的 X，Y 和 XYZ 之和（用于后续计算色坐标）。\n$$ \\begin{align*} \u0026 Y=Y_{1}+Y_{2}+Y_{3} \\\\ \u0026 X=\\frac{x_{1}Y_{1}}{y_{1}}+\\frac{x_{2}Y_{2}}{y_{2}}+\\frac{x_{3}Y_{3}}{y_{3}} \\\\ \u0026 X+Y+Z=\\frac{Y_{1}}{y_{1}}+\\frac{Y_{2}}{y_{2}}+\\frac{Y_{3}}{y_{3}} \\\\ \\end{align*} $$令 $X+Y+Z=S$，三刺激值求和后再回到 xyY 色坐标，混合后的色度坐标为：\n$$ \\begin{align*} \\\\ \u0026 y=\\frac{Y}{S} \\\\ \u0026 x=\\frac{X}{S} \\end{align*} $$即：\n$$ \\begin{align*} \u0026S=\\frac{Y}{y} \\\\ \u0026X=xS=\\frac{xY}{y} \\end{align*} $$当三基色的色度坐标和白点色度坐标已知时，可构建如下的方程组。\n$$ \\left\\{ \\begin{align*} \u0026 Y_{1}+Y_{2}+Y_{3}=Y \\\\ \u0026 \\frac{1}{y_{1}}Y_{1}+\\frac{1}{y_{2}}Y_{2}+\\frac{1}{y_{3}}Y_{3}=\\frac{Y}{y} \\\\ \u0026 \\frac{x_{1}}{y_{1}}Y_{1}+\\frac{x_{2}}{y_{2}}Y_{2}+\\frac{x_{3}}{y_{3}}Y_{3}=\\frac{xY}{y} \\end{align*} \\right. $$用矩阵表示为：\n$$ \\begin{bmatrix} 1 \u0026 1 \u0026 1 \\\\ \\frac{1}{y_1} \u0026 \\frac{1}{y_2} \u0026 \\frac{1}{y_3} \\\\ \\frac{x_1}{y_1} \u0026 \\frac{x_2}{y_2} \u0026 \\frac{x_3}{y_3} \\end{bmatrix} \\begin{bmatrix} Y_1 \\\\ Y_2 \\\\ Y_3 \\end{bmatrix} = \\begin{bmatrix} Y \\\\ \\frac{Y}{y} \\\\ \\frac{xY}{y} \\end{bmatrix} $$通常将 Y 设为 1（即白点亮度归一化），可求解得到三原色按什么比例（每个基色的亮度 Y）混合能获得指定的白点。\n转换矩阵 求得三个基色的 xyY 后，将其转换为 XYZ，不难注意到此时已经计算出 RGB 空间中基向量对应的 XYZ 三刺激值。\n因此，RGB 到 XYZ 的转换矩阵如下，如需从 XYZ 到 RGB，只需求逆矩阵。\n$$ \\begin{bmatrix} X_{r} \u0026 X_{g} \u0026 X_{b} \\\\ Y_{r} \u0026 Y_{g} \u0026 Y_{b} \\\\ Z_{r} \u0026 Z_{g} \u0026 Z_{b} \\\\ \\end{bmatrix} \\begin{bmatrix} R \\\\ G \\\\ B \\end{bmatrix} = \\begin{bmatrix} X \\\\ Y \\\\ Z \\end{bmatrix} $$非线性传递函数 为了更好的适应人眼的感知特性，RGB 空间中的值通常会经过非线性传递函数，将线性 RGB 转换为非线性 RGB。例如，sRGB 选用了一个接近伽马 2.2 的非线性传递函数，并修正了逆变换时在零附近可能存在的问题。\n从线性 sRGB 到非线性 sRGB 的转换函数为，虽然指数上是 2.4，但实际上它更接近于 $x^{2.2}$。\n$$ \\begin{align*} \u0026 R' = \\begin{cases} 12.92R \u0026 R \\leq 0.0031308 \\\\ 1.055R^{1/2.4}-0.055 \u0026 R \u003e 0.0031308 \\end{cases} \\end{align*} $$思考 如何判断一个给定的三刺激值是否在某个 RGB 空间内？\nHow to determine if given XYZ tristimulus values fall within a color gamut.\nThe gamut is defined by four CIE xy coordinates representing red, green, blue, and white (assume white point luminance has been normalized to 1.0).\nPlease provide the Python code.\n第一个能不联网正确回答这个提问的是 Deepseek R1（此处指的是老 R1），大概要输出一万 tokens，多数平台部署的 R1 没有这么长的输出。\n之后能做对的模型：Gemini 2.5 Pro，OpenAI o3 Pro，Deepseek V3-0324，Claude 3.7 Sonnet，Grok 4，Kimi K2。\n做不对的：GPT 4.1，Qwen，Claude Sonnet 4（3.7 思考能做对，4 思考也做不对）。\n关键在于是否考差了亮度。正确的做法是构建转换矩阵，将 XYZ 转到 RGB，然后观察是否有小于 0 或大于 1 的数。典型错误是，将 XYZ 转到 xy 色坐标，观察是否落在三基色围成的三角形里。\n","permalink":"https://jackchou.top/posts/ccm-01-rgb-xyz/","summary":"构建矩阵实现 XYZ 和定义在 XYZ 上的 RGB 空间转换","title":"颜色空间转换：RGB 与 XYZ"},{"content":"分光 不论是三刺激值 XYZ 还是其它的颜色属性，都是从光谱派生而来的，直接测量光谱功率分布（Spectral Power Distribution）是最基础的颜色测量方法，通过光谱可以计算出任何需要的颜色属性，且具有最大的灵活性。\n光谱的测量核心在于分光，牛顿使用棱镜，将波长不同的光在空间上分开，形成彩虹，就是一种分光的方法。使用棱镜、光栅等原理都能实现分光，区别在于光谱分辨率、光谱带宽、光谱范围等。\n分光之后，使用光电二极管、CCD、CMOS 等光电探测器，将空间上分开的光谱采集和处理。\n另外，根据是否自带光源，测量的具体是何种光谱功率分布（何种辐射度量），光谱测量仪器可分为分光光度计（Spectrophotometer）、光谱辐射度计（Spectroradiometer）等。\n最著名的光谱辐射度计可能是 Konica Minolta 的 CS-2000，它可以测量 380-780nm 的 1nm 间隔的辐射亮度。\n积分 有时候，我们只需要颜色属性而非光谱，比如最常见的 CIE XYZ 三刺激值，按照 XYZ 的定义：\n$$ X = K\\int_{380nm}^{780nm} P(\\lambda) \\cdot \\bar{x}(\\lambda) d\\lambda $$ 其中，$P(\\lambda)$ 是光谱功率分布，$\\bar{x}(\\lambda)$ 是颜色匹配函数，$K$ 是归一化系数。\n如果有一种滤色片，它的透射光谱乘上探测器的光谱敏感函数，得到的整体的光谱敏感度与 $\\bar{x}(\\lambda)$ 相似，那么直接读取输出值就可以得到$X$。这种类似于直接在物理意义上对光谱进行积分的方法，称为积分测量，可以直接得到颜色属性。\n通过积分能测量的属性有：三刺激值（使用颜色匹配函数积分），亮度（使用光谱视效函数积分）。总之，只要是通过一个光谱敏感函数积分得到的属性，都可以使用积分测量。准确度取决于仪器的光谱特性的匹配程度。\n色度计（Colorimeter），廉价的色差仪就是使用了积分测量。比如 Datacolor 的 SpyderX。\n积分测量的问题在于，颜色匹配函数并非一直不变。比如最早使用的 CIE1931 颜色匹配函数，到后来的 CIE1964，再到 CIE2006，而积分测量方法不能够向后兼容，也没有计算其他光谱相关指标的能力，例如积分设备测出来三刺激值完全一致的两个光源，可能具有不同的蓝光能量分布，对节律的影响就不同。另外，匹配不好的仪器会导致同色异谱现象，即输出误差会随着光谱的变化而变化。相机在一定程度上也能够看作是一种对颜色的积分测量，其光谱敏感函数称为 SSF（Spectral Sensitivity Function）。\n其它测量方面 除了最基础的光谱测量，还需要考虑实际物体在不同角度的反射率，光泽，纹理等。工业上还会有一次性测量二维平面乃至三维空间中的颜色的需求。都有专门的仪器和方法进行测量，当然，价格一般也是不菲。\n比如 Eldim 公司的 EZContrast 系列能够一次测量多个角度的反射率或辐射亮度，TopCon 公司生产的成像光度计能够一次测量二维平面上多个点的光谱和颜色。\n而相机作为一种具有三种光谱积分的成像设备，是很好的低成本二维成像颜色测量工具，但需要格外注意同色异谱现象和特征化。\n","permalink":"https://jackchou.top/posts/pcrdi06/","summary":"Notes for Principles of Color Reproduction in Digital Images, Ep. 6","title":"数字影像颜色再现原理笔记：颜色测量"},{"content":"高级色度学 之前的内容里，我们已经学习了色度学，色度学可以量化和计算颜色感知，按照色度学，在一定条件下，CIE XYZ 三刺激值相同的两个颜色刺激能够匹配，条件包括了背景、光源、材质等。在实际生活中，这些条件不一定满足，导致两个在色度学上相同的颜色刺激不能匹配。为此，提出了色适应变换等修正的方法。\n尤其是跨媒体颜色再现（Cross Media Colour Reproduction）越来越广泛的应用，需要能够将各种观察条件作为参数输入，对颜色刺激进行更精细的描述的模型。视觉感知到的不同观察条件下的颜色刺激称为颜色外貌（Colour Appearance），对色貌进行研究和建模称为高级色度学，得到的模型称为色貌模型（Colour Appearance Model，CAM）。\n色貌 高级色度学使用色貌属性来更精细的描述感知到的颜色刺激。色貌属性已经是色彩科学术语的一部分，所有有关色彩科学的标准词汇都可以在 https://cie.co.at/e-ilv 找到，接下来需要仔细的使用色貌属性的中英文，索引来自 CIE S 017:2020 ILV，关于色貌属性的准确解释，建议去看国际标准的描述。\n常见的色貌属性有：视明度（Brightness），明度（Lightness），视彩度（Colourfulness），彩度（Chroma），饱和度（Saturation），色相（Hue）。\n另外，还有很多新的色貌属性正在被研究和提出。\n相关色：related colour，17-22-047，colour perceived to belong to an area seen in relation to other colours。描述一个颜色和周围的其他颜色存在关系，最好的例子是“灰色”，灰色一定是一个相关色，因为它只能在与更亮颜色的比较中产生。\n视明度：brightness，17-22-059，attribute of a visual perception according to which an area appears to emit, transmit or reflect, more or less light。描述亮的程度的绝对属性。\n明度：lightness (of a related colour)，17-22-063，brightness of an area judged relative to the brightness of a similarly illuminated area that appears to be white or highly transmitting。相对色才有的属性，描述区域视明度相对于周围最亮的或白色的视明度的关系。\n一些书里写：明度是相对于周围白点或最亮区域的相对亮度的感知，应为相对视明度。也不代表：明度=视明度/白场视明度，因为他们都是非线性量。\n视彩度：colourfulness，17-22-072，attribute of a visual perception according to which the perceived colour of an area appears to be more or less chromatic。描述颜色的绝对属性。更亮的颜色刺激可能会具有更高的视彩度。\n彩度：chroma，17-22-074，colourfulness of an area judged as a proportion of the brightness of a similarly illuminated area that appears grey, white or highly transmitting。彩度是一个颜色刺激的视彩度和相似照明环境下的中性色的视明度之间的关系。\n关于以上四个量，由于颜色恒常性和认知机制，视觉系统自动把图中的红色感知成同一个物体的颜色。在与各自区域的背景或照明环境的比较中，他们具有了相同的明度和彩度（也可以说，明度和彩度是视觉系统排除光源的影响后，对一个样本“反射率”的感知）。而上下颜色的视明度和视彩度这两个绝对属性是不同的。\n饱和度：saturation，17-22-073，colourfulness of an area judged in proportion to its brightness。是一个颜色的视彩度和视明度之间的关系。下面的图片直观的显示了视彩度，视明度和饱和度的区别。\n在 CIECAM 16 中，饱和度由视彩度和视明度的比例计算得来。\n$$ s=100*\\left( \\frac{M}{Q}\\right)^{0.5} $$\n表达有关“彩色”的日常词汇也有很多，比如鲜艳、饱和、彩 度，或者 Vividness、Brilliance 等。他们在色彩科学中都有不同的含义。\n色貌模型 色貌模型可以预测不同观察条件下的颜色刺激的色貌属性，模型通常包括色适应和一些色貌现象的预测。因此，色貌模型的输入是一个颜色刺激和观察条件，输出则是各种色貌属性。\n输入与输出 几乎所有的色貌模型都使用了 XYZ 三刺激值作为输入，保证了和现有色彩科学良好的兼容性，而观察条件则需要仔细的定义，通常会包括背景（background）、周围环境（surround）、适应场（adaptation field）等，此外，还需要输入白点（white point）用于计算色适应和相对色貌属性，白点又分为参考白点（reference white point）和适应白点（adapted white point），参考白点也称选用白点（adopted white point），是人为设置的计算白点，比如与显示器相关的计算中，会选用显示器显示出的白色作为参考白点。适应白点则是视觉系统内的白点，即视觉系统认为的白色。\n适应场白点（adaptation field white point）指适应场中的白点，比如环境中白场的颜色刺激。当完全适应于一个场景时，适应场白点和适应白点相同。\n最基本的输出的色貌属性是：明度，彩度，色相。\n基本结构 色貌模型的基本结构是：\n将颜色刺激（三刺激值）转换为锥体响应（cone responses）。 在锥体响应上进行色适应变换，得到适应后的锥体响应。 根据视觉理论基础（对立色理论、非线性压缩）得到中间信号（高级信号）。 结合观察条件，计算得到色貌属性。 即：色适应变换（但不使用回到三刺激值的逆矩阵）+ 中间处理 + 色貌属性计算。\n按照这个基本结构，CIELAB 也可以算是一个简单的色貌模型。\n$$ \\begin{align*} L^* \u0026= 116 f\\left(\\frac{Y}{Y_n}\\right) - 16 \\\\ a^* \u0026= 500 \\left[f\\left(\\frac{X}{X_n}\\right) - f\\left(\\frac{Y}{Y_n}\\right)\\right] \\\\ b^* \u0026= 200 \\left[f\\left(\\frac{Y}{Y_n}\\right) - f\\left(\\frac{Z}{Z_n}\\right)\\right] \\end{align*} $$其中，$f(t)$ 是一个非线性函数，用于模拟视觉系统的非线性压缩。由 a* 和 b* 可以计算出色相和彩度。另外，$Y/Y_n$ 可以看作是一种色适应变换，虽然从色适应的角度看，它错误的将对角矩阵（von Kries 假设）应用在了三刺激值而非锥体响应上，导致其色适应效果比较差。\n因为色适应的关系，基于 CIELAB 的色差公式可能不能够很好的处理各种不同光源下的颜色差异，比如引入更先进的色适应变换或直接用完整的色貌模型，有关内容可以在 这里 体验。\n常用色貌模型 CIECAM 16：现行的 CIE 推荐色貌模型。 CIECAM 02：CIECAM 97s 的简化和改进。 CIECAM 97s（the simple form of the CIE Colour Appearance Model 1997） Hunt: 最完整和复杂的色貌模型，从 1952 年开始发展，对 CIECAM 系列有很大影响，甚至考虑到了视杆细胞的影响。 待续 一些相关网站：\nhttp://www.huevaluechroma.com/index.php\n","permalink":"https://jackchou.top/posts/pcrdi05/","summary":"Notes for Principles of Color Reproduction in Digital Images, Ep. 5","title":"数字影像颜色再现原理笔记：颜色外貌"},{"content":" 关于色适应和色适应模型，可以参考这篇文章的章节 1.2.1\n翟其彦，‘照明色适应与颜色质量’, 博士，浙江大学，2018.\n颜色恒常性 一个物体在不同的光照条件和观察环境下，其颜色会发生变化，但是人类视觉系统可以在一定程度上保持对物体颜色的稳定感知。这种现象被称为颜色恒常性（Colour Constancy）。这种保持相对稳定的过程称为色适应（Chromatic Adaptation）。\n照明环境改变时，色适应需要一段时间来完成，图为 Fairchild 和 Reniff（1995）的实验结果，为三位观察者的稳态适应的比例与时间的关系，从 A 切换到 D65。\nM. D. Fairchild and L. Reniff, ‘Time course of chromatic adaptation for color-appearance judgments’, J. Opt. Soc. Am. A, vol. 12, no. 5, p. 824, May 1995, doi: 10.1364/JOSAA.12.000824.\n色适应的形成机制可以大致分为两部分：感觉和认知。\n感觉机制认为视网膜上的三种视锥细胞会根据光的强弱自动独立的调节增益。某种视锥细胞的响应增大时，会降低其增益，三种视锥细胞的增益调节是独立的。von Kries 在 1902 年提出的基本假设认为视觉器官中各组成部分的疲劳或适应是彼此独立的（当时还没有视锥细胞的概念）。von Kries 的基本假设是所有色适应模型的基础。\n\u0026ldquo;This can be conceived in the sense that the individual components present in the organ of vision are completely independent of one another and each is fatigued or adapted exclusively according to its own function.\u0026rdquo;\n认知机制更为复杂，认为人对物体颜色的感觉还受到物体本身的影响。比如草是绿色，苹果是红色，天空是蓝色，视觉能在各种光照条件下保持对这些物体颜色的稳定感知。这种认知机制的形成可能是由于人类在长期的生活中对物体颜色的经验积累。认知机制导致的色适应通常不完全。\n认知机制的一个典型例子是折扣光源（Discounting-the-Illuminant），也称忽略光源。指观察者能够不根据光源，而是根据物体本身的颜色（反射率）来判断物体的颜色。如白天的煤炭是黑色的，夜晚的雪是白色的，但实际上白天煤炭的亮度更高，视觉感知的是主要煤炭和雪的反射率。折扣光源在跨媒介的颜色再现中非常重要，跨媒介颜色再现指用不同的媒介来展示颜色，比如自发光的显示器和印刷出来的纸张上的颜色，自发光的显示器本身就是光源，没有折扣光源现象，而印刷出来的颜色，观察者能够一定程度上忽略照明光源的影响。\nApple 在 iPhone 8 和 iPhone X 上推出的 True Tone 技术（原彩显示），这种技术能够根据环境光照的变化调整显示器的颜色，模拟出折扣光源现象，让显示器像是在该光源下的纸张印刷物一样，一定程度上提高了显示舒适性。\n色适应变换 色适应变换建立了对应色（Corresponding Colours）的联系。对应色指在不同观察条件下能够匹配的两个颜色，设想一个观察者有超强的颜色恒常性，同一个场景，更换不同的光源，他感知到的颜色始终是一样的（始终匹配），此时，该场景下，同一物体在不同光源的颜色就是一对对应色，通常用 XYZ 三刺激值表示颜色，第一个观察条件下的三刺激值为 $X_1, Y_1, Z_1$，第二个观察条件下的三刺激值为 $X_2, Y_2, Z_2$，则这两组三刺激值是这两个观察条件下的对应色。\n色适应变换（Chromatic Adaptation Transform，CAT）是用于预测对应色的模型。输入为两个观察条件（通常用场景白点的三刺激值表示）和一个观察条件下的颜色（用三刺激值表示），预测在另一个观察条件下能够与之组成对应色的颜色（也用三刺激值表示）。\n建立 CAT 模型需要对应色数据集来训练和验证，以下是常见的几种建立对应色数据集的实验方法：\n单目匹配：设计实验装置，分隔左右眼视野，让两边处于不同的观察条件下，观察者比较和匹配两边的颜色刺激。这种方法无法研究认知机制导致的色适应。 记忆匹配：被试者在一个观察条件下记住某种颜色刺激，到另一个观察条件下匹配颜色刺激。 数值估计：被试者在不同的观察环境中对颜色刺激进行“评分”，比如估计颜色的亮度、饱和度、色调等数值。 我没有设计、举行或参加过有关色适应的实验，仅从个人主观臆测的角度，收集对应色实验数据是很困难的。上面的三种方法都有各自的缺陷，比如记忆匹配中，人对颜色的短期记忆很有限，数值估计中，让被试对一个主观的值进行打分估计，需要考虑如何设计实验统一被试间的评分标准。\nCAT 的基本结构 根据 von Kries 的假设，色适应在视觉器官的层面是独立的。色适应变换的基本结构为：\n将输入的 XYZ 转换到某个代表视觉器官的空间。 在这个空间内对每个量进行独立的处理（比如乘各自的增益系数） 转回到 XYZ 空间，得到另一个观察条件下的颜色三刺激值。 von Kries 本人没有给出过一个具体的 CAT 办法，但可以根据其假设建立简单的色适应模型，比如 Ives 和 Helson 模型。\nM. H. Brill, ‘The relation between the color of the illuminant and the color of the illuminated object’, Color Research \u0026amp; Application, vol. 20, no. 1, pp. 70–76, Feb. 1995, doi: 10.1002/col.5080200112.\nH. Helson, ‘Some Factors and Implications of Color Constancy*’, J. Opt. Soc. Am., vol. 33, no. 10, p. 555, Oct. 1943, doi: 10.1364/JOSA.33.000555.\n首先将两个观察条件的光源或白场、一个颜色刺激（\\(\\text{XYZ}_{w1}, \\text{XYZ}_{w2}, \\text{XYZ}_{1}\\)）转换到 LMS 相对锥体响应空间，可以用一个 3x3 矩阵完成。然后对每个量乘上一个增益系数，可以表示为乘上一个对角矩阵。最后转回到 XYZ 空间，即乘第一步的逆矩阵，得到 $\\text{XYZ}_{2}$，有时候也写作 $\\text{XYZ}_c$，表示对应色。\n增益系数是两个观察条件的光源或白场的锥体响应之比，即“刺激大的视觉器官会自动调整减小增益”的假设。如：\n$$ L_2 = \\frac{L_{w2}}{L_{w1}} L_1 $$这样简单的线性模型已经能够很好的预测对应色数据集中的数据。\nCAT 的改进 一些研究提出了在第二步使用非线性的调整或是三通道间相互影响的非独立调整来试图改进色适应变换。比如 Nayatani 和 Guth 用幂函数代替线性增益。但并不能获得较好的效果。\n改变从 XYZ 三刺激值到 LMS 相对锥体空间的变换矩阵可能可以得到更好的结果。此时不能再用 LMS 表示，而是改用 RGB。比如 Fairchild 使用的 HPE 变换矩阵，Bradford 的 BFD 变换矩阵，CAT02 和 CAT16 使用的矩阵。\n另外，虽然非线性调整不能取得较好的效果，但线性增益时使用的系数里可以有一些改进，比如 CMC-CAT 和 CAT02 中引入了适应度 D 的概念，用于控制适应的完全程度。D 介于 0 和 1 之间，1 表示完全适应，0 表示完全不适应。在 CAT02 中，D 是一个有关输入侧适应场亮度的数，并加入一个用于代表环境亮暗的因子 F。\n$$ D = F \\cdot \\left[1 - \\frac{1}{3.6} e^{\\frac{-L_A - 42}{92}}\\right] $$其中，$L_A$ 是输入侧适应场的亮度，单位是 cd/m²，$F$ 是环境因子，平均环境中取 1.0，微暗环境取 0.9，暗环境取 0.8，由相对亮度决定，比如明亮的办公室，室内看电视和昏暗的电影院。\nCAT16 现行的 CIE 推荐色适应变换方法是 CAT16，是一个线性变换，一步法 CAT16 的过程如下。\n输入：输入侧适应场白点 \\(\\text{XYZ}_{w}\\)，输出侧（参考侧）适应场白点 $\\text{XYZ}_{wr}$，输入颜色 $\\text{XYZ}$，适应场光源亮度 $L_A$，环境因子 $F$。\n将 \\(\\text{XYZ}_{w}\\)，\\(\\text{XYZ}_{wr}\\)，$\\text{XYZ}$ 转换到 RGB 空间。使用的变换矩阵为 \\(\\mathbf{M}_{16}\\)。 \\[ \\begin{bmatrix} R \\\\ G \\\\ B \\end{bmatrix} = \\begin{bmatrix} 0.401288 \u0026 0.650173 \u0026 -0.051461 \\\\ -0.250268 \u0026 1.204414 \u0026 0.045854 \\\\ -0.002079 \u0026 0.048952 \u0026 0.953127 \\end{bmatrix} \\begin{bmatrix} X \\\\ Y \\\\ Z \\end{bmatrix} \\] 对 RGB 三通道分别进行适应变换，增益系数是有关适应度 D 的，适应度 D 的计算方法和 CAT02 中一样，G 和 B 的增益系数中将 $R_{wr}$ 和 $R_w$ 更换。 \\[ k_R = D \\cdot \\frac{Y_w}{Y_{wr}} \\cdot \\frac{R_{wr}}{R_w} + 1 - D \\\\ R_c = k_R \\cdot R \\] 将适应变换后的 RGB 转回 XYZ 空间，使用 \\(\\mathbf{M}_{16}^{-1}\\)。下标用 c 或 r 表示对应色或参考场的含义。 \\[ \\begin{bmatrix} X_c \\\\ Y_c \\\\ Z_c \\end{bmatrix} = \\mathbf{M}_{16}^{-1} \\begin{bmatrix} R_c \\\\ G_c \\\\ B_c \\end{bmatrix} \\]由于适应度 D 的存在，CAT16 在多数情况下是不能逆向的，CAT16 还有一个两步法的版本，用于解决一步法逆向后无法得到原始输入的问题。两步法约定了一个中间光源，比如等能白，通过将输入场适应到等能白场，再从等能白场反向预测输出场的对应色。\n如果用 \\(\\Lambda_{r,t}\\) 指代从输入场 t 到输出场 r 的线性增益对角矩阵。则一步法的总变换矩阵为：\n\\[ \\Phi_{r,t} = \\mathbf{M}_{16}^{-1} \\Lambda_{r,t} \\mathbf{M}_{16} \\]两步法的总变换矩阵为：\n\\[ \\begin{align*} \\Pi_{r,t} \u0026= \\Psi_{r,se} \\Phi_{se,t} \\\\ \u0026= \\mathbf{M}_{16}^{-1} \\Lambda_{se,r}^{-1} \\mathbf{M}_{16} \\mathbf{M}_{16}^{-1} \\Lambda_{se,t} \\mathbf{M}_{16} \\\\ \u0026= \\mathbf{M}_{16}^{-1} \\Lambda_{se,r}^{-1} \\Lambda_{se,t} \\mathbf{M}_{16} \\end{align*} \\]其中 se 表示等能白，两步法和一步法在实际效果上几乎没有差别，目前使用更多的是一步法。\n","permalink":"https://jackchou.top/posts/pcrdi04/","summary":"Notes for Principles of Color Reproduction in Digital Images, Ep.4","title":"数字影像颜色再现原理笔记：色适应变换"},{"content":"黑体 黑体（Black Body）指能够吸收所有电磁辐射而无散射或反射的理想化物体，因此，黑体辐射出的电磁波完全由黑体的温度决定，称为黑体辐射。\n$$ M_{\\lambda}(T) = \\frac{2hc^2}{\\lambda^5} \\frac{1}{e^{\\frac{hc}{\\lambda k_B T}} - 1} $$其中，$h$为普朗克常数，$c$为光速，$k_B$为玻尔兹曼常数，使用时需注意单位转换（尤其是 m 和 nm）。\n图中展示了几个温度下的黑体光谱辐射出射度。黑体辐射具有以下特征：\n每个温度下的光谱辐射出射度曲线仅有一个峰值。 随着温度的升高，光谱辐射出射度的峰值位置向短波长方向移动。 在任意波长下，高温黑体的辐射出射度始终高于低温黑体的辐射出射度。 用可见光范围内的辐射出射度可以计算出黑体的颜色，将各种温度下的黑体颜色绘制在色度图上，形成的线称为普朗克轨迹。\n通过普朗克轨迹可以看出，随着温度升高，黑体从红色开始，逐渐变为黄色，经过白色区域后变为蓝色（请自行脑补）。日常生活中有时会提及冷暖色光，按照黑体辐射的相关计算，能发出冷色光（偏蓝的光）的黑体具有较高的温度，发暖色光的黑体温度则较低。\n虽然黑体作为理想物体并不存在，但金属在被加热时的特征接近黑体（光谱发射率比较平坦），可以想象一块铁被不断加热的过程以理解黑体辐射。室温中的铁不发光，因为室温时，铁的辐射能量很小。随着铁逐渐被加热，根据特征 3，辐射出射度不断提高，铁开始“发光”，先呈现暗红色，再是橙红色。之后，根据特征 2，光谱辐射中短波部分逐渐增加，发出的光越来越蓝，呈现冷白色甚至蓝色。\n金属的发射率 一直以来，我个人都认为金属比较接近黑体，其实两者之间有很大的区别。\n根据基尔霍夫热辐射定律，物体在热平衡时，对辐射的吸收比（$\\alpha$）恒等于发射率（$\\epsilon$）。对一个物体来说，对辐射的吸收，反射（$\\rho$）和透射（$\\tau$）之和为 1。金属可以认为透射率为 0，因此有$\\rho + \\alpha = 1$，即$\\epsilon = 1 - \\rho$。\n黑体的发射率为 1，所以反射率越低的金属，其特征越接近黑体，比如深色、表面粗糙的金属（钨，铁），另外，金属对各种波长的反射率比较均匀，所以金属的辐射光谱具有和黑体辐射接近的形状。\n比如 CIE 标准照明体 A，其定义为一个温度 2856K 的黑体的光谱分布，和同色温的钨丝白炽灯的光谱分布非常接近。\n色温和相关色温 不同温度的黑体辐射出的光具有不同的颜色，可以用温度描述具有相同颜色（相同 xy）的光源，即色温（Colour Temperature）。\n某一色温的的光的光谱功率分布不需要和黑体辐射一致，也不需要具有相同的温度，只需要相同的色度。对多数光源来说，其色度坐标不一定落在普朗克轨迹上，于是寻找与光源色坐标最接近的普朗克轨迹上的点，称为相关色温（Correlated Colour Temperature, CCT）。此处的“接近”指的是颜色接近，因此需要在均匀颜色空间中计算，通常使用的是 CIE 1960 uv 色品图，具有相同相关色温的色坐标连成线，称为等温线。\n如果偏离普朗克轨迹太多，相关色温没有意义，因为两条等温线甚至会交叉。偏离普朗克轨迹的程度称为 Duv（$\\Delta_{uv}$）。Tcp 和 Duv 可以更直观的描述光源的颜色特性。\n标准照明体 归根结底，颜色是人对光的感知，而光源从根本上决定了有关颜色的一切，确定一个光源在色彩科学的研究中是极为重要的。\n除了自然光源，随着科技的发展，人造光源也经历了多次变革，为了方便沟通和标准化，CIE 规定了一些标准照明体，标准照明体是一系列光谱功率分布，而非特定的光源，甚至可能不存在能提供这样光谱的光源。\nCIE 标准照明体 D 有些标准照明体来自自然光源，最重要的自然光是日光。CIE 通过收集多组日光的光谱数据，提出了一种从色温出发，计算日光光谱的方法。计算出的光谱分布称为 CIE 日光照明体，其中相关色温 6504K 的日光照明体被定义为 D65 标准照明体，另外，相关色温为 5003K、5500K 和 7504K 的 D50、D55 和 D75 为补充照明体。目前，没有能够直接产生 D65 光谱的光源。\n具体计算过程是：\n给定相关色温 $T_{cp}$，计算对应的 $x_D$，下式中的 $T_{cp}$ 适用范围是 4000K 到 7000K。 $$ x_D = -4.6070 \\times 10^9 / T_{cp}^3 + 2.9678 \\times 10^6 / T_{cp}^2 + 0.09911 / T_{cp} + 0.244063 $$ 计算 $y_D$，下式实际上是二阶多项式拟合的日光轨迹。$x_D$ 和 $y_D$ 是 $T_{cp}$ 对应的日光照明体的色度坐标。 $$ y_D = -3.000 x_D^2 + 2.870 x_D - 0.275 $$ CIE 通过统计方法对采集的日光光谱数据进行主成分分析，将日光光谱分为三部分。$M_1$ 和 $M_2$ 由 $x_D$ 和 $y_D$ 计算得到。 $$ S_D(\\lambda) = S_0(\\lambda) + M_1 S_1(\\lambda) +M_2 S_2(\\lambda) $$$$ M_2 = \\frac{0.0300 - 31.4424 x_D + 30.0717 y_D}{0.0241 + 0.2562 x_D - 0.7341 y_D} $$最终得到的 $S_D(\\lambda)$ 即为 CIE 日光照明体的光谱功率分布，是相关色温 $T_{cp}$ 的函数。\nD. B. Judd et al., ‘Spectral Distribution of Typical Daylight as a Function of Correlated Color Temperature’, J. Opt. Soc. Am., vol. 54, no. 8, p. 1031, Aug. 1964, doi: 10.1364/JOSA.54.001031.\nCIE 标准照明体 A A 照明体代表了白炽灯发出的光，光谱功率分布是温度为 2856K 的黑体辐射。CIE 规定色温为 2856K 的钨丝白炽灯为标准照明体 A。\nCIE 标准照明体 E 等能白光，是人为规定的光谱分布，广泛用于色空间的理论计算中，提供中介的作用。也不存在能够产生 E 照明体的光源。\n其他标准照明体 模拟日光的标准 B 和 C 照明体，已弃用。\n除了白炽灯以外，荧光灯也在相当长的一段时间里是主要的照明设备，尤其是在美国和欧洲。标准照明体 FL 系列是荧光灯的光谱分布，FL1 到 FL12 分别对应不同的荧光灯。\nFL2 也称 CWF （Cool White Fluorescent，冷白荧光灯），主要用于美国的商场和办公机构，相关色温为 4150K（所以色温也不是很冷）。\nFL11 也称 TL84，是飞利浦的特有产品，是欧洲最重要的商业光源。相关色温为 4000K。\n虽然现在荧光灯逐渐被 LED 取代，但是荧光灯的标准照明体仍然在对应市场的质量检测和对色灯箱中使用。荧光灯因为其发光原理，具有窄带的光谱，在同色异谱的研究中有重要地位。\n显色性 多数物体本身并不发光，而是被光照亮后发光，因此光源直接影响了物体在人眼中的颜色，光源对颜色的影响称为显色（Colour Rendering）。光源的显色性是评价光源的重要指标，总体可分为颜色保真指数和色域指数。\n颜色保真指数 一个物体的在光源下的颜色，应当与“熟悉的”参照光源一致，一般指日光或标准照明体 D 系列。因此，在该光源下的颜色与参考照明体下的颜色色差越小，该光源的颜色保真度越高。\n简单来说，测试颜色保真度的方法是：选取一个参考照明体和一系列颜色样本（已知其反射率），根据光源光谱和反射率计算颜色样本的三刺激值，选取一个均匀颜色空间和色差公式，计算一个样本在两种光源下颜色的色差。\n另外，虽然参考照明体和被测光源的相关色温相同，他们的颜色也可能不同，因此，还需要用色适应模型修正光源本身颜色差异的影响。\n显色指数（Colour Rendering Index）是 CIE 指定的一种光源显色评价方法，5000K 及以上使用相同相关色温的标准照明体 D 为参考照明体，以下则使用黑体辐射。颜色样本有 14 个。使用的色适应方法是 Von Kries 色适应变换模型，均匀颜色空间和色差公式是 CIE 1964。\nCRI 评价一些窄带光源时，与实际视觉感受相关性较差，CRI2012 是对其的改进。光源制造商可以通过针对性的调整光谱形状，提高 CRI 的数值，但其实该光源对其他颜色的显色性并不好。CRI2012 换用了用数学方法产生的 17 个中心对称的反射率，规避了“作弊”的问题。另外，将均匀色彩空间和色差换成了 CIECAM02-UCS，求取平均色差的方法从算数平均改为均方根平均（RMS）。\n因为使用的参考照明体是与被测光源具有相同相关色温的照明体，因此相关色温不会影响显色性的评价。\n色域指数 光源还可以具有让物体的颜色看起来更鲜艳、生动的效果，能够改善物体颜色的主观评价。因此，色域指数也是评价光源的重要指标。\n一些评价体系引入了对色域指数和其他更具体的指标的评价，如美国国家标准和技术研究所（NIST）的 CQS（Color Quality Scale）美国照明工程学会（IES）的 TM-30-15。引入了对色域，色相保真度，肤色保真度等指标的评价。\n应用中的显色性 如何理解显色性？观察光谱是否“完整”，如果光谱在某些波长范围内完全没有功率分布，那么如果有一个物体的反射波长恰好处于这段范围，他将无法被这个光源照亮。LED 在长波长处的能量分布一般较低，而 CRI 中的第九个颜色样本是一个比较饱和的红色，因此 LED 的 R9 一般较低。\n屏幕的白点通常是 D65，这个白点由红绿蓝三基色混合而成，屏幕三基色的光谱分布较窄，因此如果把屏幕显示出的白色作为照明光源，它的显色性也会较差。\n一些卖照明灯具的商家会宣传自己的灯光显色性高，是“全光谱”。在 CRI 中，平均显色指数 Ra 是指前八个颜色样本的显色性均值，不包括 LED 的弱点 R9，因此 LED 灯具的标称显色指数都很高，可以达到 90 甚至 95 以上。\n2024 年起，中国不再允许市场上使用“猪肉灯”，猪肉灯采用特别的光谱，能使得灯下的猪肉看起来更新鲜，可以看做是一种对“猪肉颜色样本”特化的灯，它对其他颜色的显色指数都很低。\n常见光源的显色指数（CRI Ra）和相关色温（CCT）：\n高压钠灯：24，2100K FL2 / CWF：62，4150K FL11 / TL84：85，4000K 全光谱 LED（蓝光/紫光激发）：95-99，2700-5000K 白炽灯：100，2856K 关于白炽灯，过于低的色温和极低的光效率使其不适合用于照明。网上有不少“白炽灯神教”，实际上反而是根本不了解显色性的表现。\n光源一致性 显色指数是以人为中心的评价指标，是评价人眼中，颜色样本在不同光源下的颜色表现。而对于影视制作来说，对光采样并记录的并非人眼，而是摄像机，用显色指数评价影视中的灯光并不合适（但很多售卖影视灯具的公司仍以 CRI 评价）。\n欧洲广播联盟提出的 TLCI 和 TLMF 是专用于评价电视制作中的光源的显色性能的方法。与之前类似，也需要选择参考光源等，但用于比较色差的三刺激值换成了摄像机拍摄后，经过处理显示在屏幕上的三刺激值，而非直接用颜色样本的反射率计算出的三刺激值。\n用到的颜色样本是 ColorChecker® 上的 18（不含灰阶）或 24 色。这是广泛用于影视制作的颜色样本，是行业内事实上的标准。\nTLCI 评价的是单个光源与标准照明体（参考照明体）之间的一致性，TLMF 评价的是混合光源与另一个实际光源（参考照明体）间的一致性。\n思考练习题 照明体和光源的区别是什么？\n答案\r- 照明体指特定的光谱分布，实际中不一定存在，比如标准照明体 D 系列和 E。 - 光源是发光的物体，实际存在，比如白炽灯、荧光灯、LED 灯等。 - 一些标准照明体能找到对应的光源，比如标准照明体 A 对应白炽灯。 ","permalink":"https://jackchou.top/posts/pcrdi03/","summary":"Notes for Principles of Color Reproduction in Digital Images, Ep.3","title":"数字影像颜色再现原理笔记：照明体和光源"},{"content":"我们已经完成了对光的定量描述，包括光谱 (Spectral Power Distribution) 和辐射量。本章则是对颜色的定量描述，称为色度学 (Colorimetry)。\n看到这里，我实在很想吐槽一下国内教材现状。比如说我们对比一下本书第二章和徐海松老师的《颜色信息工程》第二章。\n本书 2.1.1 颜色混合定律，介绍了 1854 年提出的 Grassmann 的颜色混合定律；颜色信息工程 2.1.3 格拉斯曼颜色混合定律，内容几乎完全一样。\n本书 2.1.2 颜色匹配实验，介绍了三基色颜色匹配实验的基本方法；颜色信息工程 2.1.1 颜色匹配实验，连装置的插图都是一模一样的。\n这样基础的概念出现的顺序竟然不同；在色度学基础里突然出现色貌这样的词汇并不加解释；一本书里是明度，一本书里却写亮度。给人一种生怕读者学会了的幽默体验。\n颜色的混合 混合：颜色的混合分为加色和减色。将各种颜色的光照射在白纸上，能够混合出一个白光，而将各种颜料涂抹在白纸上，则得到黑色。实验中比较常用的是加色混合，显示屏用到的便是加色混合。\n匹配 (Matching)：一个区域的一半用一种光照亮，另一半用另一种。如果观察者在中间不能观察到分界线，即两边“看起来”是一样的，那么这两个光（或称对应的颜色）对该观察者来说是匹配的。\n颜色与光：人感知光，产生颜色的感觉。光是物理量，颜色则是心理物理量。一种光对应一种颜色，一种颜色却不一定对应一种光。\n颜色的量：颜色是由光产生的，光的量能够用辐射量衡量，颜色的量也可以相对的用辐射量来衡量。比如辐射量变为两倍，“颜色的量”也变为两倍。\n一定条件下，人眼对颜色混合的感知是线性的，包括以下方面：\n如果两个光匹配，两个光具有相同的颜色，将两个颜色的量改变相同的倍数，他们仍然匹配。 如果颜色 A 和 B 匹配，颜色 C 与 D 匹配，那么颜色 A 和 C 的混合与颜色 B 和 D 的混合也能匹配。 如果颜色 A 和 B 的混合匹配颜色 C，颜色 X 和 Y 的混合匹配颜色 B。那么颜色 A，X，Y 的混合匹配颜色 C。 简单来说，颜色的混合和小学里学的加法一样，因为颜色的混合本质上就是光谱的叠加，而辐射量自然是可以线性相加的。另外，匹配完成后，不会随着环境的变化而改变，比如改变一下背景的亮度，冷暖等，不会破坏白纸上两边光的匹配。\n虽然颜色的混合是线性的，但并不代表对颜色的感知是线性的。以亮度为例，1 单位光叠加 1 单位光能够和 2 单位光匹配，不代表人对亮度的感知是线性增长的。\nCIE 1931 RGB 颜色匹配函数 CIE：国际照明委员会（Commission Internationale de l\u0026rsquo;Eclairage）是一个国际性的组织，致力于研究光、颜色和照明等问题。CIE 为色彩科学领域制定了一系列标准。之前介绍的光谱视效率函数 $V(\\lambda)$ 就是 CIE 制定的标准之一。在色彩科学的方方面面都能见到它的身影。\n有关 CIE 1931 RGB 及颜色匹配函数的详细内容，请看这篇很好的博客https://yuhaozhu.com/blog/cmf.html\n$$ C(\\lambda) = \\bar{r}(\\lambda) R + \\bar{g}(\\lambda) G + \\bar{b}(\\lambda) B $$ 有一些波长的单色光无法取得匹配，需要把三基色中的一种移动到单色光的这一边，此时他的系数为负。\n于是，我们能得到一组曲线，称之为颜色匹配函数 (Color Matching Functions)，也就是 $\\bar{r}(\\lambda)$，$\\bar{g}(\\lambda)$，$\\bar{b}(\\lambda)$。1920 年代，W.D. Wright 和 J. Guild 等人通过实验得到了一些数据，CIE 在 1931 年整理并推荐了一组标准的颜色匹配函数，称为 CIE 1931 RGB 颜色匹配函数。\n此处我们忽略了无数细节，比如实验中每个波长的单色光的能量是否相同；Wright 和 Guild 使用的三基色的波长并不相同，与 CIE 最终推荐的三基色波长也不相同，这些数据是如何被转换的；他们是否归一化，如何归一化，最终颜色匹配函数的单位到底是什么等等。教材们虽然废话连篇，却在这里选择一笔带过，推荐阅读 链接 中的文章。\n此处的函数值我们称之为三刺激值 (Tristimulus Values)。CIE 1931 RGB 颜色匹配函数只包含 2°视角的数据，2°视角对应了人眼的中央凹，是视锥细胞分布最密集的区域。Wright 的实验包含 10 位观察者，Guild 的实验则是 7 位，也就是说，这 17 个人的实验数据奠定了后来近百年色彩科学的基础，也留下了隐患和问题。\n$$ r = \\frac{R}{R+G+B} $$\ng 和 b 同理。如此得到的 $r + g + b = 1$，称为色品坐标。\n在 1931 RGB 系统中，三基色的光亮度（考虑了光谱视效函数的亮度）比例为 $1:4.5907:0.0601$ 时能混合出与等能白光匹配的颜色，且把匹配函数按比例相加后，能得到先前提到的光谱视效函数 $V(\\lambda)$，即可以用三刺激值计算光亮度。这应该是 CIE 1931 RGB 归一化时的参考\n等能白光：所有波长的辐射能量相等的光，在 1931 RGB 系统中，等能白光的三刺激值为 (0.33, 0.33, 0.33)。\nCIE 1931 XYZ 色度系统 CIE 1931 RGB 颜色匹配函数基于真实存在的三原色光，因此其计算结果中包含一些负值，这在当时导致了计算上的困难。为了解决这一问题，CIE 推荐了 CIE 1931 XYZ 标准色度系统，该系统使用了假想的三原色光，不仅确保了三刺激值均为正值，还实现了其他一些目标。\nXYZ 色度系统由 RGB 色度系统线性变换得到，即：\n$$ \\begin{bmatrix} X \\\\ Y \\\\ Z \\end{bmatrix} = \\begin{bmatrix} 2.7689 \u0026 1.7517 \u0026 1.1302 \\\\ 1.0000 \u0026 4.5907 \u0026 0.0601 \\\\ 0.0000 \u0026 0.0565 \u0026 5.5943 \\end{bmatrix} \\begin{bmatrix} R \\\\ G \\\\ B \\end{bmatrix} $$变换矩阵满足了以下条件：\nRGB 系统中，560-700 nm 为一条直线，因为这段范围内不再需要短波长的光参与匹配，新三原色中，希望有两个处于这条直线上。 希望用 XYZ 中的 Y 值来表示亮度，而 X 和 Z 对亮度的贡献为 0，因此 X 和 Z 应位于无亮度直线上，即 $r + 4.5907g + 0.0601b = 0$。 最后一条边是在光谱轨迹上与 503 nm 相切的一条直线。 等能白点仍然位于 (0.33, 0.33, 0.33) 变换后的 XYZ 颜色匹配函数均为正，代表了三个虚构的三原色光的亮度。其中，$Y(\\lambda)$ 与光谱视效函数 $V(\\lambda)$ 相同。Y 值等同于光亮度。\n将 XYZ 归一化，得到色度坐标和光亮度 $xyY$，可画出 CIE 1931 xy 色度图。\n色度图上的着色是为了美观，色度图上的点只有色度信息，而无亮度信息，比如图上没有灰色等。因为色度图仍然是线性的，因此在上面选两个点对应的色光，可以混合出这两个点之间的线段上的颜色。如果选三个点，可以混合出三角形内的颜色，这也是表示显示屏能够显示的颜色范围的方法。从图中还能看出，不存在三种色光能够混合出人眼能感知的全部颜色。\n均匀颜色空间 颜色空间（Colour Space）：是颜色的数学表示，用几个量（一般是三个）表示颜色。例如 CIE 1931 XYZ 就是一个用 XYZ 三刺激值表示颜色的颜色空间。颜色空间可以是线性的，即颜色之间可以相加减，也可以是非线性的，不同的颜色空间有不同的功能。色彩科学中，需要在合适的颜色空间中对颜色进行处理。\n亮度的非线性 首先，人眼对亮度的感知是非线性的，与匹配实验类似，让被试观察色品坐标相同，但亮度不同的两种颜色。他们的亮度分别是 $L$ 和 $L+\\Delta L$，当两个亮度差别很小时， 仍然能够达到视觉上的匹配，当亮度差超出某一阈值，能观察到差异，此时的亮度差称为“恰好可察觉的差”（Just Noticeable Difference, JND）。亮度不同时，JND 也不同，所以 XYZ 色空间中的亮度 Y 是不均匀的，Y 从 10 变为 20，90 变为 100，在感知亮度上的变化是不同的。为了解决这个问题，提出两个新的概念：明度（Lightness）和视明度（Brightness），视明度是对绝对亮度的感知，也就是一个光“亮”的程度，明度则是视明度的相对值，表示相对同样照明环境下完全漫反射白的物体的“亮”的程度，例如一张白纸，不论在晴朗的室外，还是室内，其明度均为 90（相对 100），但视明度会变化。明度的目标是相同的明度变化，在亮度上的感知变化也是相同的。\n根据不同的实验结果，提出了很多的明度模型。最简单的明度模型仅为一个幂函数，如 Hunter 的明度 $L_H = Y ^ {0.5}$。尽管明度的模型有些简单有些复杂，但他们的基本形状都接近，即暗的时候，人眼对亮度的感知增长较快，亮处则较缓，比如人眼感知的介于黑和白之间的灰色，大约具有 18-25% 的反射率，而非 50%。\n色度的非线性 同样的，如果在 CIE 1931 xy 色品图上取比较靠近的两个点，被试可能无法区分他们的颜色，即小于 JND。MacAdam 进行了一些实验，让被试对同一个颜色向不同方向进行加色混色（即往不同的方向偏离），记录能辨别差异时的新位置。实验发现，这些新位置可以用一个椭圆较好的拟合，因此称为 MacAdam 椭圆。\n从画在 CIE 1931 xy 色品图上的 MacAdam 椭圆可以看出，该色彩空间的色度均匀性比较差，椭圆大小不一。针对色度的均匀性，也有诸多尝试，比如注意到色品图上半部分的椭圆较细长，那就对色品图进行纵向的压缩，但简单的变换都不能得到较满意的结果。比较著名的尝试有 CIE 1960 UCS 和 1976 UCS。通过对 xy 进行简单的变换，转换为新的色坐标 uv 或 u\u0026rsquo;v\u0026rsquo;，在均匀性上有一些提升，此处的 UCS 指代 Uniform-Chromaticity-Scale，均匀色品标尺。\n均匀颜色空间 明度模型（或称均匀明度标尺）和均匀色品标尺共同组成了三维的颜色空间，称为均匀颜色空间（Uniform Colour Space）。比较著名的有 CIE 1976 \\(L^*a^*b^* \\)，或称 CIELAB。使用表示明度的 \\(L^*\\) 和表示红-绿，黄-蓝方向上色度的 \\(a^*b^*\\) 组成，需注意星号也是符号的一部分，应避免使用 Lab 这样的写法，容易与其他色空间中的符号混淆。\nCIELAB 是一个相对的颜色空间，需要先确定一个“参考白点”，该照明环境下完全漫射白的三刺激值 $X_n, Y_n, Z_n$。\n$$ L^* = 116 f(\\frac{Y}{Y_n}) - 16 $$$$ a^* = 500 [f(\\frac{X}{X_n}) - f(\\frac{Y}{Y_n})] $$$$ b^* = 200 [f(\\frac{Y}{Y_n}) - f(\\frac{Z}{Z_n})] $$其中，\n$$ f(t) = \\begin{cases} t^{1/3} \u0026 t \u003e (24/116)^{3} \\\\ (841 / 108)t + 16/116 \u0026 t \\leq (24/116)^{3} \\end{cases} $$CIELAB 至今仍是使用最广泛的均匀颜色空间。\n色差 在工业应用中，我们需要定量的衡量颜色之间的差异。例如在质量检测中，生产的一批产品的表面颜色差异小于多少视为合格。\n如果有一个均匀颜色空间，那么直接取两个颜色在该均匀颜色空间中的距离，就是最好的色差衡量办法。应用在 CIELAB 空间上，得到：\n$$ \\Delta E_{ab}=\\sqrt{(\\Delta L^*)^2+(\\Delta a^*)^2+(\\Delta b^*)^2} $$遗憾的是，CIELAB 的均匀性没有强大到可以直接应用这样的距离公式来衡量色差。后来几十年间又诞生了各种各样在 CIELAB 空间上计算色差的补丁，其中最著名的一个是 M.R.Luo 提出的 CIE 2000 色差公式或 CIEDE 2000，其符号为 $\\Delta E_{00}$，如果经常关注数码或显示器，应该经常见到 DE2000 作为衡量显示器色差的常用工具。\nCIEDE 2000 虽然计算复杂，但它目前是在所有数据集中性能最好的之一，也是 CIE 推荐的最新的色差公式。\n孟塞尔颜色系统 Munsell 是美国的一位画家，早在 1905 年（早于 CIE 1931 XYZ），他就通过总结前人经验并结合自身画家的身份，制定了一套色序系统（Colour Order System）。所谓色序系统，是指从视觉感知开始，将各种颜色样本按一定的顺序分类和排序形成的色彩系统。\n牛顿在将白光分出彩虹色光的时候，我们就已经能将颜色分为红橙黄绿蓝青紫等颜色，这实际上就是对颜色的色相（Hue）进行分类。\nMunsell 将颜色按三个维度，明度（Value），色相（Hue）和色度（Chroma），将颜色排列到一个三维空间中，称为颜色立体。其中的颜色卡片在视觉感知上，在三个维度上都被认为是等间隔的。是目前应用最广泛的颜色系统之一。\n因为 Munsell Color System 被认为是感知上均匀的，因此测量其中颜色的三刺激值，并转换到后来的均匀颜色空间中，观察这些点在均匀颜色空间中的分布是否仍然比较“均匀”，就能够一定程度上衡量均匀颜色空间的性能。\nM. Li and M. R. Luo, ‘Simple color appearance model (sCAM) based on simple uniform color space (sUCS)’, Opt. Express, vol. 32, no. 3, p. 3100, Jan. 2024, doi: 10.1364/OE.510196.\n","permalink":"https://jackchou.top/posts/pcrdi02/","summary":"Notes for Principles of Color Reproduction in Digital Images, Ep.2","title":"数字影像颜色再现原理笔记：色度学基础"},{"content":"光 电磁波中一定波长范围的称为光。可见光的短波端波长约 360-400nm，长波端约 760-830nm，一般取 380-780nm。\n不同波长的光能够引发不同的颜色感觉，牛顿利用棱镜将不同波长的光在空间上分开，彩虹不同位置对应着不同的波长，“颜色”也各不相同。\n平时能接触到的光，绝大多数光都是复色光，即并非单一波长，而是由多种波长混合出的光。此处需提及一个重要概念：同色异谱 (Metamerism)。对同一个人来说，一种光对应一种确定的颜色，但一种颜色却不能对应一种确定的光。同色异谱现象是颜色再现的基础和前提，所以我们有可能在显示器上再现自然界中的颜色，即使光谱完全不同。\n光谱 光谱是我们描述复色光的成分的办法。\n光是一种电磁辐射，用辐射量 $X$ 来衡量辐射的多少，光度学中，辐射量有辐射通量、辐射强度、辐射照度、辐射亮度等，但可以笼统的先用辐射量表示。我们希望观察复色光中不同波长的光的辐射多少，因此提出光谱密度：\n$$X_\\lambda = \\frac{\\mathrm{d}X}{\\mathrm{d}\\lambda}$$光谱密度可看作关于波长的函数，用横坐标为波长，纵坐标为光谱密度的图表，就能够形象的表示一个光的光谱。\n光谱密度分布也可叫做光谱功率分布 (Spectral Power Distribution, SPD)，狭义上是指辐射功率分布。\n$X_\\lambda$ 除以 $\\max{X_\\lambda}$，即将 SPD 归一化，最大值为 1，得到的关于波长的新函数称为相对光谱功率分布。\n人眼 作者 Hptim \u0026amp; Jmarchn. - 基于如下对象的个人作品： Schematic diagram of the human eye en.svg 由 Rhcastilhos，CC BY-SA 3.0，https://commons.wikimedia.org/w/index.php?curid=13572928\n其中，虹膜能够根据光的强弱自动调节中间瞳孔的尺寸，角膜、晶状体、房水、玻璃体组成了人眼的光学结构，视网膜上的细胞能够感知光、处理和传递信号，最后通过视神经将神经冲动传递给视觉中枢。\n随着年龄的增大，晶状体的光学密度会增加（即透光率下降），尤其是短波长的部分。即晶状体会变得越来越“黄”，虽然视觉的其他部分（如色适应等）使得人感受不到这样的变化，但会导致人与人之间的同色异谱现象变得严重。\n视网膜不仅将光信号转变为神经冲动，还进行了初步的处理，因此视网膜也可以说是有片上运算的“智能图像传感器”。但视网膜由内到外分别是感受器细胞、双极细胞和神经节细胞。神经节细胞的轴突形成视神经，通过盲点再穿过视网膜继续传递，也就是说，视网膜实际上是一种“前照式”传感器。和视觉相关的感受器细胞有视锥细胞 (cones) 和视杆细胞 (rods)，有一些感受器细胞与视觉无关，但也能感受光并参与人的其他生理活动，比如和节律有关的 ipRGC。\n视锥细胞分布在视觉中央很小的区域：黄斑的中央凹。95%以上的视锥细胞集中在这里，视杆细胞又很少分布。除了盲点以外，视杆细胞大量分布在 20°视角。正常视觉者的视锥细胞有三种，根据对光的波长的敏感性，分为对长波敏感的 L，中波敏感的 M 和短波敏感的 S 型，但实际上，由于 L 和 M 在基因层面的接近，他们的感光波长峰值比较接近（这可能也是红绿色盲是最常见的色盲的原因）。\n关于 LMS 敏感函数的更多内容，请见http://www.cvrl.org/cones.htm。\n注意图中光是自下而上进入眼球的。光穿过层层细胞后，在感受器细胞的末端上的视色素发生光触发的生物电反应，转化为生物电信号，再反向传递到水平细胞、双极细胞、无足细胞层，这里是网状结构，分内外两层，是信息传递和加工的地方，再传递到神经节细胞，由神经节细胞的轴突传递到大脑。\n人眼的光谱响应 根据环境光的亮暗，人眼的瞳孔和感光细胞能够自动调节和适应。其中根据感光细胞的工作状态，可将视觉分为视锥细胞单独工作的明视觉 (Photopic)，视杆细胞单独工作的暗视觉 (Scotopic) 和他们混合工作的中间视觉 (Mesopic)。从暗处到明处，由暗视觉转为明视觉的过程很快，大约一分钟就能够完成，但从明视觉转向暗视觉则需要大约三十分钟。\n有关明视觉，暗视觉和中间视觉的定义，参见：A. Stockman and L. T. Sharpe, ‘Spectral Sensitivity’, in The Senses: A Comprehensive Reference, Elsevier, 2008, pp. 87–100. doi: 10.1016/B978-012370880-9.00300-5.\n对一个光电二极管来说，他的响应度可以定义为输出除以输入的辐射能，使用不同波长的光输入，测量输出值，可以得到传感器的光谱响应度。对人眼来说，就是相同辐射量但不同波长的光，人对其的感知亮度不同。但人眼无法直接测得输出值，因此需要设计实验来相对的衡量不同波长的感知亮度。\n此处讲到的“实验”，是色彩科学中几乎最重要的方法，因为色彩是人的感觉，我们将其称为“心理物理量” (Psychophysical Quantity)，他并非一种绝对的客观的物理量，也和人的主观因素有关。测心理物理量的实验称为心理物理实验，一般来说，需要请被试完成一些任务，比如评价，匹配等。如果实验设计的不好，给被试的任务过于抽象或困难，则不能得到很好的结果，另外，一些需要代表全人类共同特点的实验，还需要考虑地区、人种的影响。\n之前提到，不同波长的光会给人不同的颜色感觉，所以这个实验可以理解成如何量化相同辐射量的不同颜色光的亮度，比如相同辐射功率的红光和蓝光哪个更亮。对于这样差异大的颜色，观察者实际上很难给出稳定的结论。可以采用分步法：让被试不断匹配两个接近波长的光，分布的匹配整个可见光范围，闪烁法：让两种波长的光交替闪烁，频率为 30-50Hz 时，如果两种光有较明显的感知亮度差异，被试者会观察到一个亮度闪烁的混合颜色，据此判断两种波长的光的感知亮度是否匹配。这两种方法都能获得更稳定的结果。\n我们把“感知亮度”暂时称作光通量 $\\Phi_v$，辐射通量为 $\\Phi_e$，他们的比值即为人的光谱响应度，如果具体到某一波长，则：\n$$\\Phi_v=K(\\lambda)*\\Phi_e$$其中，$K(\\lambda)$为光谱响应度或光谱光视效能 (Luminous Efficacy)，对整个可见光波长范围上的响应度做归一化，使其最大值为 1，得到的关于波长的函数$V(\\lambda)$称为光谱光视效率 (Luminous Efficiency)。\n现在使用的光谱光视效率函数时 1924 年 CIE 根据 251 位观察者的实验确定的，其最大值位于 555nm，也就是说人眼对波长为 555nm 的黄绿光最为敏感。需要注意的是，CIE 推荐使用的这个 $V(\\lambda)$ 是多位观察者的实验数据拟合而成的，世界上并不一定存在这样的人。CIE 在 1951 年进一步确定了暗视觉下的光视效率函数 $V'(\\lambda)$，暗视觉下，最大视效能位于 508nm，整体向短波方向偏移，即暗视觉下，人对长波长的光不太敏感。中间视觉则直接使用明视觉函数和暗视觉函数的线性组合。\n数据来自http://www.cvrl.org/lumindex.htm\n光度学 “亮度”其实是一个充满歧义的词汇。大多数激光都很亮，但如果用激光来提供室内的照明，他又不如几瓦的 LED 灯明亮。为了消除这种歧义，就需要更准确的物理量来定义“亮”。\n光是一种辐射，之前提到的辐射量，包括辐射能 $Q_e$，辐射通量 $\\Phi_e$，辐射强度 $I_e$，辐射亮度 $L_e$，辐射照度 $E_e$。他们虽然名字接近，但都是不同的物理量。理解这些辐射量之间的关系后，可以方便的派生到光度量，而不是像各大教材一样直接学一大堆光度量。\n辐射量是与电磁波相关的物理量，和人眼无关；而光度量和人眼有关，是心理物理量。\n辐射能和辐射通量 辐射能：Radiant energy，单位是焦耳。表示电磁辐射的能量，电磁辐射是光子组成的粒子流，光子所携带的能量的总和就是辐射能。一个光子的能量可以用普朗克公式计算：$E=h\\nu$，其中$h$是普朗克常数，$\\nu$是光子的频率。\n辐射通量：Radiant flux，单位是瓦。表示单位时间的辐射能量，辐射能对时间求导即可得到辐射通量。更直观的说法是辐射功率，但为了和光通量联系，建议使用辐通量。\n辐射强度 辐射强度：Radiant intensity，单位是瓦每球面度。\n我们先来学习一下球面度的概念，球面度 $\\Omega$ 是一个立体角单位，1 $\\mathrm{sr}$ 定义是球面上面积为$r^2$的区域所对应的立体角。一个球的表面积是$4\\pi r^2$，一个球面对应的$4\\pi sr$。\n如果一个点光源均匀的向四周发光，那么其辐射强度$I_e=\\Phi_e/4\\pi$。我们常说激光很“亮”，不仅指激光的辐射功率可能很大（比如脉冲激光），更多是指激光的辐射强度大，因为激光的方向性很强，发散角极小，在激光传播方向上的辐射强度很大。\n辐射出射度和辐照度 这些量的单位都是瓦每平方米，衡量“表面”上的不同辐射通量，可分为入射，出射。\n入射：即到达一个表面上的辐射通量，称为辐射照度 (Irriadiance)，计算方式是到达表面的辐射通量除以面积。\n出射：从一个表面离开的辐射通量，称为辐射出射度 (Radiant exitance)，计算方式是从表面发出的辐射通量除以面积。\n比如一张灰色的纸，放在灯光下，辐射照度是灯光照射到纸上的辐射通量除以纸的面积，而辐射出射度就是纸反射出的辐射通量除以纸的面积。此处入射或出射的光是什么方向都可以，只要是到达或离开表面的辐射通量。\n辐射率（辐射亮度） 辐射亮度或辐射率：Radiance，单位是瓦每球面度每平方米 ($W/(sr*m^2)$)。\n理解辐亮度，可分为几个步骤：\n一个面光源，区别于辐射强度时用到的点光源，面积是$\\mathrm{d}A$。 一个方向，与面光源的法线夹角为$\\theta$，该方向上的一个立体角是$\\mathrm{d}\\Omega$。 这个方向上，面光源的投影面积是$\\mathrm{d}A\\cos\\theta$。 这个立体角内的辐射通量是$\\Phi_e$。 $$L_e=\\frac{\\mathrm{d^2}\\Phi_e}{\\mathrm{d}\\Omega\\mathrm{d}A\\cos\\theta}$$光度学量 由于人眼对不同波长的光的感知亮度不同，因此辐射度量并不能直接反映人眼的感知亮度。辐亮度相同的不同波长的光会有不同的感知亮度。将辐射量乘上之前提到的光视效率函数，可以定义光度量。\n定义：555nm 波长，辐射功率（辐射通量）为 1/683 瓦的光对应的光通量为 1 流明。把之前的辐射量乘上光视效率函数和常数 683 lm/W，就得到了光度量。\n辐射能/辐射通量 -\u0026gt; 光能量/光通量，单位是流明秒和流明。 辐射强度 -\u0026gt; 发光强度，单位是流明每球面度，定义为一个新的单位：坎德拉 (Candela)，是国际单位制中的基本单位之一。 辐射照度 -\u0026gt; 光照度，单位是流明每平方米，定义为勒克斯 (Lux)。 辐射出射度 -\u0026gt; 光出射度，单位是流明每平方米。 辐亮度 -\u0026gt; 亮度，单位是流明每球面度每平方米，或坎德拉每平方米，定义为尼特 (Nit)。 注意到几乎每个光度学量都定义了新的单位，这其实给学习和记忆带来了困难，个人推荐在光度学中使用 Candela 和 Lux，避免使用 Nit。\n待续 ","permalink":"https://jackchou.top/posts/pcrdi01/","summary":"Notes for Principles of Color Reproduction in Digital Images, Ep.1","title":"数字影像颜色再现原理笔记：光与视觉"},{"content":"关于本书 感谢 Daniel_Li 在群里推荐本书。\n我觉得这是一本不错的色彩科学入门书籍，他比较系统的介绍了色彩科学的架构和关键内容，废话比较少使得其篇幅不长。\n虽然存在不少问题，比如和徐海松老师的《颜色信息工程》大量的“雷同”内容，讲解顺序的颠倒和混乱，还有各种小问题。但这已经是我见过国内比较好的教材和工具书了。\n书名：数字影像颜色再现原理 作者：顾晓娟 ISBN：978-7-115-61746-0\n计划 计划是按提炼和总结每一章的内容。对关键的算法进行复现，提供更详细的参考文献。挑选和完成一部分思考题。\n目前用的缩写是 PCRDI (Principles of Color Reproduction in Digital Images)。\n目录 笔记计划按照书的章节来划分，所以简要介绍一下本书的目录。\n光与视觉 有一点像绪论，介绍了光和视觉的基本概念，其中光度学的内容比较重要。\n色度学基础 介绍了颜色匹配实验，基于此介绍和推导了 CIE 标准色度系统（三刺激值，色度坐标等）。并简单介绍了均匀颜色空间和孟塞尔颜色系统，在此基础上介绍了色差公式。\n照明体和光源 介绍了色彩科学中的常见光源和评价光源的方法。例如 CIE 标准照明体，显色性和光照质量评价。\n色适应和色适应变换 在了解了光源和色度学基础的情况下，介绍了人的色适应现象和重要的色适应模型，为色貌模型提供基础。\n色貌现象和色貌模型 由于简单的色度学不能很好的描述人的主观颜色感觉。因此色貌是更重要的颜色属性。 介绍了色貌的属性，常见的色貌现象。在此基础上介绍几个重要的色貌模型。\n颜色测量和测色仪器 这一章一共只有四页\n因为色彩科学实际上不太关注颜色具体是如何被测量的（如何分光，传感器技术）。本章简单介绍了常见的测色仪器及其简单的原理。\n颜色再现 颜色再现是整个制作流程的终极目标。 颜色再现利用了先前介绍的各种模型和方法，本章介绍了颜色再现的评价指标和一些特有概念。\n数字摄影机的颜色信息处理 本章介绍了摄影机的原理，特征化摄影机的方法。\n并较详细的介绍了解马赛克与白平衡方法。\n显示设备的颜色信息处理 本章介绍了显示设备的原理，显示设备显示颜色的流程。并较详细的介绍了多基色设备的混光方法。\n数字颜色管理系统 本章介绍了颜色管理系统，例如 ICC，ACES 等。是之前所有内容的综合应用。\n","permalink":"https://jackchou.top/posts/pcrdi00/","summary":"Notes for Principles of Color Reproduction in Digital Images, Ep.0","title":"数字影像颜色再现原理笔记：绪论"},{"content":"我 我是 Jack Chou。\n我目前是色彩科学领域的研究生，关于我和我们的工作，请参阅 我的个人页面 和 实验室网站。\n爱好有很多，主要是摄影、猫和咖啡。\n这里 这个博客第一次创建在 2023 年 6 月 29 日，当时的目的是在秋招的时候能够有一个地方展示自己的内容，实际上，以那时那种一知半解的经验、阅历和心态，并不能写出像样的东西，那次秋招现在想来也不可能成功。不过也有像 Processing Raw Images in MATLAB 这样有一点内容的东西，但更多是被我用 Draft 雪藏的文章。\n后来，一个非常幸运的机会结束了那次诡异的秋招，也不再有什么动力和目标去更新这个博客，而是偶尔用在一些奇怪的用途。比如，它被用来给巴黎住 Airbnb 遇到的法国夫妻分享 明信片故事。\n这是上一次建设博客的故事，之前的部分内容还能够在 古迹 🌃 中找到。\n由于是一个部署在 Github 上的静态网站，我在 GitHub 上的其他 pages 也会拥有相同的域名，这样，访客如果不输入后面的内容，直接访问这个域名，就会看到混乱的，很久没有更新的博客。\n而为了更方便的分享那些项目的 pages 和利用 CloudFlare 的 Tunnel 功能，我购买了 jackchou00.icu 这个域名，荒废博客的问题变得更加明显。\n2025 年 1 月 20 日，为了满足我自己的分享欲和小心虚荣心，也为了让这个域名不要指向荒废的博客，重新装修过的 JacksBlog 正式 push 了。这一次，他的目的是记录一些科研和兴趣中的东西，分享一些图片和生活。\n网页是由 Hugo 生成的，使用的主题是稍作修改的 PaperMod，部署在 Github Pages 上并由 Cloudflare DNS 和代理。\n未来 不知道为什么不能在阿里云上续费 jackchou00.icu 这个域名，目前可以付一年之后迁移，之后续费需要 12 USD 每年，再让我纠结一会儿。\n目前迁移到 jackchou.top 这个域名，并由 jackchou00.icu 和 zms.im 重定向。\n我买了十年的 jackchou.top 域名，2035 年，我们会在哪里呢？\n更新日志 2025.11.22: 为所有页面增加了 Keywords 和 Description 2025.10.16: 更换代码字体为 Google Sans Code，略微增大字重。 2025.09.05: 同时使用衬线和非衬线字体的显示效果太奇怪了，换了一个名为 Sen 的字体。 2025.08.12: 尝试优化宽屏设备的显示效果，根据总宽度分两档拓展内容宽度，修改位于 themes/PaperMod/assets/css/core/zmedia.css。 2025.08.03: 在底部添加了一个粗略统计访客数量的 Badge。 2025.07.24: 主域名变更为 jackchou.top。 2025.07.20: 使用 Gemini 2.5 Pro 翻译了全部文章，英文字体更换为 Lora。 2025.06.29: 把阿里云 OSS 上的图片迁移到 Cloudflare R2 上。 2025.06.11: 使用 Saas 加速国内访问和 Cloudflare 企业支持。 2025.04.14: 增加多语言支持（Experimental Support for Multiple Languages）。 2025.02.17: 发现使用 Tags 就能很好的实现分类，移除了 Colour 这个二级分类。 2025.02.11: 部署了 Github Actions，现在，博客的源文件也有版本管理和自动部署了。 2025.02.02：增加了用于切换显示/隐藏的按钮，使用短代码实现。 2025.01.24: 停用 Misans，尝试加快加载速度，现在的中文字体是 Google Font 的思源黑体。 2025.01.22: 使用 Cloudflare R2 存储图片。 2025.01.20: 更新了字体，使用 Google Font 引入 Ubuntu Sans 和 Ubuntu Mono。中文字体是 MiSans，使用本地加载的方式。Code 的背景颜色修改为238。 2025.01.18: 引入对$\\LaTeX$公式的支持，参考 PaperMod: Math Typesetting 2025.01.15: 修改了 PaperMod 的页面背景颜色。 将themes\\PaperMod\\assets\\css\\core\\theme-vars.css中的theme，从纯白改为245。 ","permalink":"https://jackchou.top/about/","summary":"\u003ch2 id=\"我\"\u003e我\u003c/h2\u003e\n\u003cp\u003e我是 Jack Chou。\u003c/p\u003e\n\u003cp\u003e我目前是色彩科学领域的研究生，关于我和我们的工作，请参阅 \u003ca href=\"http://cel.zju.edu.cn/2024/0923/c27449a2965767/page.htm\"\u003e我的个人页面\u003c/a\u003e 和 \u003ca href=\"http://cel.zju.edu.cn\"\u003e实验室网站\u003c/a\u003e。\u003c/p\u003e\n\u003cp\u003e爱好有很多，主要是摄影、猫和咖啡。\u003c/p\u003e\n\u003ch2 id=\"这里\"\u003e这里\u003c/h2\u003e\n\u003cp\u003e这个博客第一次创建在 \u003ca href=\"/posts/old/helloworld/\"\u003e2023 年 6 月 29 日\u003c/a\u003e，当时的目的是在秋招的时候能够有一个地方展示自己的内容，实际上，以那时那种一知半解的经验、阅历和心态，并不能写出像样的东西，那次秋招现在想来也不可能成功。不过也有像 \u003ca href=\"/posts/old/processingrawinmatlab/\"\u003eProcessing Raw Images in MATLAB\u003c/a\u003e 这样有一点内容的东西，但更多是被我用 Draft 雪藏的文章。\u003c/p\u003e","title":"关于"},{"content":"\nThis is the western part of Hangzhou, one of the youngest areas of the city, with a population of over 2 million last year. This photo was taken on a hill at an altitude of about 200 metres, just on the edge of the area, excellent to discover the breathtaking speed of Hangzhou\u0026rsquo;s development.\nThis photo shows two pigeons fighting for food, but it happens to look like they were \u0026lsquo;kissing\u0026rsquo; at the moment I pressed the shutter button. It was taken at a Buddhist temple in Hangzhou called \u0026lsquo;Fa Xi\u0026rsquo;, which is famous for its effectiveness in finding marital destiny.\nJing\u0026rsquo;an Temple by night: This temple is special because it is located in the centre of Shanghai, one of the busiest areas in the world. As one of the oldest temples in China, it has a history of almost two thousand years. Fifty years ago it was completely destroyed by the Cultural Revolution and a fire. Now this \u0026lsquo;modern look\u0026rsquo; temple is the most important Buddhist site in China.\nThis photo was taken in Nanjing, which was the capital of China six times. It shows a very detailed piece of architecture from the Ming Dynasty. The green part is made of ceramic, shaped so that rain falls gently. The red part is made of wood, painted with very vivid mineral pigments, which can last a very long time and show incredible saturation under sunlight. The pattern in the shadow is from Buddhist culture, also painted with mineral pigments.\nA cat raised by the kind owners of a small shop needs to sleep more than twelve hours a day. We named the shop \u0026lsquo;The Cat\u0026rsquo;s Shop\u0026rsquo; because of this beautiful and lazy cat.\nThis is a park that bears witness to the friendship between Hangzhou, China and Fukuoka, Japan. Its lotus landscape is very famous. When summer comes, the bright sunshine makes the lotus leaves and lotus flowers show amazing and elegant colours. The vague building behind was once the courtyard of a wealthy merchant.\n(Portuguese) \u0026lsquo;Igreja de São Domingos\u0026rsquo; in Macau, has over 400 years of history, built by Spaniards and administered by Portuguese. I added this image to the collection because of its particular yellow colour and interesting contrasting lighting.\nThese two pictures were taken in Hong Kong, one of the world\u0026rsquo;s most multicultural cities. It has some of the best harbours in the world. It was occupied by the British in 1842 and only returned to China in 1997. As such, it has survived two world wars and the Chinese civil war. It is still a place where Eastern and Western cultures collide. It has created a modern, international city full of contradictions, congestion and a huge gap between rich and poor. For photographers, the streets here seem to have a kind of magic that makes it easy to take interesting pictures.\nA quiet temple in Hangzhou, close to the West Lake. Very few tourists will come here as there are so many popular viewpoints around. The quaint architecture, lush vegetation and such a quiet and peaceful atmosphere make it hard to imagine that it is located in an area with the most tourists.\nThis picture was taken by Joe(Zheyun) in Norway. One of her favourite photos after post processing.\nThis picture was taken by Joe in Iceland. I adjusted the colour and contrast according to my imagination to make it fit Iceland in my mind. Joe promised to come to Iceland with me one day. (っ °Д °;)っ\n","permalink":"https://jackchou.top/posts/old/postcards01/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://img.jackchou.top/jack-img/2025/05/c68e82d1fde8e7ff7b65b8c2c8ed19ca.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eThis is the western part of Hangzhou, one of the youngest areas of the city, with a population of over 2 million last year. This photo was taken on a hill at an altitude of about 200 metres, just on the edge of the area, excellent to discover the breathtaking speed of Hangzhou\u0026rsquo;s development.\u003c/p\u003e\n\u003cp\u003e\u003cimg loading=\"lazy\" src=\"https://img.jackchou.top/jack-img/2025/05/de35a3fa596ad2097f9a2bec3ffecd09.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eThis photo shows two pigeons fighting for food, but it happens to look like they were \u0026lsquo;kissing\u0026rsquo; at the moment I pressed the shutter button. It was taken at a Buddhist temple in Hangzhou called \u0026lsquo;Fa Xi\u0026rsquo;, which is famous for its effectiveness in finding marital destiny.\u003c/p\u003e","title":"Postcards introduction Col.01"},{"content":"一加9R刷机记录 OxygenOS 氧OS 9008救砖包可以刷入OxygenOS 11，之后升级到12和13.\n在OxygenOS12，系统设置中不再提供本地升级的入口，需要安装下面的apk。\nhttps://oxygenos.oneplus.net/OPLocalUpdate_For_Android12.apk\n使用体验：氧OS11和ColorOS不太一样，很简洁，傻快的动画。12和13和ColorOS很像了，内置的APP比较多一点，谷歌全家桶基本都装上了。因为是印度那边的系统，本地化还是不太好，约等于没有。续航还行，马马虎虎。\nColorOS13.1 从别的系统回到ColorOS也是用9008，会丢失数据，和原系统无关。\n区别是ColorOS用的MsmTools需要售后的验证码和密码，所以目前应该只能找售后刷，微信上和客服说下就行，不用去线下。\n客服那边说完以后会有邮件发过来，下载线刷包和工具，剩下的交给远程的技术就行。\n第一次刷的时候验证出错，换了个电脑解决的，原因不明，期间可能会安装点高通的驱动什么的。\n使用体验：真·出厂系统，13和13.1相对流畅，手动设置一下毒瘤APP的电池策略以后续航很好。缺点是预装比较多，系统比较臃肿，安装APP之前要漫长的安全检查，谷歌相机会报毒，不卸载不让用支付软件。新搞出来的小布建议蛮好用的，航班、高铁车次会像Apple那样常驻显示。\nNameless 无名 有很完善的Wiki和安装指导，电报群很热闹，更新很快，应该是需要从氧13某个版本解bl锁以后刷入。\n国内的第三方ROM，基于AOSP，刚开机的时候会说欢迎使用你的Pixel。\n非常简洁漂亮的系统，意外的是对Airpods支持很好，能看电量和各种信息，还有专门的图标和设置界面。\n缺点是类原生系统调度和后台控制比较放飞自我，容易发热，耗电速度惊人。刷了Magisk之后，用Scene5配合冻它会好很多，但是root了以后日用太不方便了。遂放弃。\n安卓14的正式版据说是2024年1月启动。\nColorOS14 Beta 2024.11.16 Oneplus9R开始ColorOS Log内测，应该是最后一个大版本更新。\nLE2100_14.0.0.50(CN01): 很卡，尤其是微信和网易云，有自定义刷新率，但是AVES和高德都不能100%触发120Hz。振动通知有问题。\nLE2100_14.0.0.51(CN01): 11.19更新，增量47.81MB，修复了振动通知。\n内测版又卡又不更新，反馈Bug权当放屁，润回13.1了，回滚需要全清，有官方降级工具，但很难用。\nColorOS14 LE2100_14.0.0.300(CN01)：1.5日的第一个正式版，总体上和内测差不多，卡顿问题好了不少，还是显著的不如13.1。尤其是淘宝、微信，流体云通知很不好用，小布建议里的高铁车次会先显示第二程的问题也仍有。\nLE2100_14.0.0.301(CN01)：2.5更新的，增量1.5GB，没看出来修复了啥，稍微流畅一些。多了一个新春水印，只有本机拍的照片能用，很简单的功能，机型会显示成LE2100而不是一加9R。\n","permalink":"https://jackchou.top/posts/old/%E4%B8%80%E5%8A%A09r%E5%88%B7%E6%9C%BA%E8%AE%B0%E5%BD%95/","summary":"\u003ch2 id=\"一加9r刷机记录\"\u003e一加9R刷机记录\u003c/h2\u003e\n\u003ch3 id=\"oxygenos-氧os\"\u003eOxygenOS 氧OS\u003c/h3\u003e\n\u003cp\u003e9008救砖包可以刷入OxygenOS 11，之后升级到12和13.\u003c/p\u003e\n\u003cp\u003e在OxygenOS12，系统设置中不再提供本地升级的入口，需要安装下面的apk。\u003c/p\u003e","title":"一加9R刷机记录"},{"content":"Process RAW Images in MATLAB 这是一篇由Rob Sumner写于2014年的文章，详细讲述了什么是RAW和在MATLAB中处理RAW文件。以下是对其的补充和若干翻译。\nRAW Data及其意义 对于图像处理和计算机视觉来说，研究者往往对于图像本身的含义不感兴趣，他们将图像（往往是8bit的灰度或三通道彩色）视作多变量的函数、随机数构成的矩阵或是一些连接的像素，在此基础上设计算法。\nRAW Data真正将场景中光照与图像连接起来，这对于HDR、天文摄影等与传感器行为有关的模型和方法是重要的。在这类问题下，知悉图像被捕获后的整个处理链是必要的。\nThe best image to deal with is the sensor data straight from the camera, the raw data.\n现在（2023），很多设备都具备输出RAW文件的能力，比如中端和高端的单反相机与微单相机，甚至一些手机也可以输出RAW。但他们都将遵循以下几个原则。\nRAW特指未经压缩的，包含了传感器像素值和一系列元数据（EXIF）的文件，可以有多种不同的专有的格式（尼康的NEF，佳能的CR2等），也可以是开放的格式，例如DNG（Digital Negative，数字负片）。RAW文件被故意设计成不可解读的数据格式（原文应该指厂商的专有格式），但一些逆向工程已经成功，比如CR2格式。具体请见CR2逆向工程\n注：剩余文章中，RAW指代文件，例如CR2，raw指代未经处理的传感器原始数据\nRaw Sensor Data的本质 从根本上来说，raw data不是能够被人眼所理解的，它既不包含一个确定的值来定义黑色，也没有确定的白色。raw是一个单通道的强度图像，像素值存储在10-16位数据中（根据不同型号的相机而定），对同一型号的传感器而言，不会有像素值高于某一个特定的值，表示了CCD或CMOS物理上的饱和点。实际输出的像素值可能大于我们期望的相机应有的范围（介于0到未曝光的像素值、或大于有意义的曝光像素值）。\n注：最后一句稍微有些拗口，原文为：The output may also be larger than the expected pixel dimensions of the camera, including a border of unexposed pixels to the left and above the meaningfully exposed ones. 可能意指超出传感器预期的暗电流或饱和值（由于噪声或坏点）\nColor Filter Array 颜色滤镜 光子传感器（也就是CMOS或CCD）实际上只能给出一个标量，不能给出实际颜色，通过在传感器表面安装一个与像素位置相对应的滤色片，可得知单个像素感知到的单个颜色的值，通过与邻近的其他颜色的像素比对，可以估计出这一点的颜色。这个估计的过程被称作解马赛克（Demosaicing），产生m乘n乘3的RGB值阵列，即我们需要的彩色数码图像。\n最常见的CFA是拜尔阵列，其中绿色的像素数是红、蓝的两倍，通常的解释是人眼对于绿色细微的差别更为敏感，与场景中的光强度的感知也更为接近。注意的是，根据生产商的不同，拜尔阵列具备不同的“相位”，按传感器最左上角的第一个拜尔阵列，按左上、右上、左下、右下的顺序，可分为“RGGB”，“BGGR”，“GBRG”，“GRBG”。在反拜尔的过程中，知道正确的相位是重要的。\nColor Channel Scaling 颜色通道缩放 An unfortunate reality of color imaging is that there is no truth in color.\n想象一个正在发光的光源有它自己的颜色，而靠近这个光源的物体也有特定的颜色。任何相机或人眼接收到的光都离不开这两种颜色的组合。所以任何物体实际上可以看起来是任何颜色的，取决于他被什么样的光照射。我们需要的是一个参考点，一样我们已知是某特定颜色的物体（一个我们已知色度的物体），我们可以据此调整RGB颜色使之接近，这补偿了光源的颜色，展示出物体“真正”的颜色，在能够估计整个场景都由同一光源照射的情况下，我们能把这种补偿作用到画面的每一个像素上，这个过程即为白平衡（White balancing）。本质上，我们找到一个应该是白色或灰色的像素点，其RGB三值应当是相等的。\n于是，问题简化为了找到两个标量，对三通道中的两个进行补偿，一般把绿色作为被对比的通道，拜尔阵列中的绿色滤光片比红色和蓝色有更高的透明度，因此绿色通道的标量常为1，而红色和蓝色大于1。\nCamera Color Spaces 相机色彩空间 如何将无线多维度的一个空间转换为三维向量的空间是一件复杂的事情，对于可感知的颜色，可以将其抽象的转化为一个凸锥体，即色彩空间。这方面的内容请参阅关于色度学的有关内容。\n在线性代数的语言中，我们使用三个坐标来表示一个像素的颜色，重要的是，这样的坐标需要一个特定的基，而传感器所使用的基与大多数显示屏使用的基是不相同的，我们假定显示屏输出色彩空间使用了通用的标准，sRGB。经过白平衡调整和解马赛克后，我们能够获得一个熟悉的彩色图像，但是这些颜色并非是显示器所期望的，为了矫正由相机的基和显示器的基导致的差异，需要进行一个线性变换来进行色彩空间的转换。\nEXIF Metadata EXIF元数据 RAW文件除了有来自传感器的raw data，还包含了很多与像素值或曝光值有关的元数据，这些数据以EXIF标签的形式存储，格式为TagName: Value，例如传感器数据，这些信息都存储在RAW文件中，需要特定的软件来获取。\n之前提到的白平衡矫正系数、黑电平等都会记录在EXIF中，其他有用的信息有（注意具体命名会根据品牌不同而变化）：相机型号，图像尺寸，测光模式，拍摄时间，闪光灯模式，地理信息，ISO，焦距，快门速度，光圈数，对焦距离，白平衡估计值。\nRAW Image Editing Workflow RAW图像处理流程 这将是之后使用MATLAB处理的大纲，也可以作为其他编程语言的参考。\nRaw sensor data -\u0026gt; Linearization -\u0026gt; White balance -\u0026gt; Demosaicing -\u0026gt; Color space correction -\u0026gt; Brightness control -\u0026gt; Viewable output\nRaw传感器数据 -\u0026gt; 线性化 -\u0026gt; 白平衡处理 -\u0026gt; 解马赛克 -\u0026gt; 色彩空间转换 -\u0026gt; 亮度控制 -\u0026gt; 输出图像\nRAW Utility Software 实用工具 由于专有格式RAW文件的存在，在使用MATLAB处理前，需要先使用其他软件“破解”，获得可读取的原始数据。以下介绍几个免费和实用的程序。\nDave Coffin\u0026rsquo;s dcraw 这是一个开源的跨平台软件，用于读取各种RAW文件并输出PPM或TIFF，内置了一些处理办法。 使用C语言编写，注释很少，一万行大概只有五十条注释。 dcraw可以做白平衡、解马赛克、色彩空间调整等，但为了在MATLAB中处理，只使用其转换专有格式的功能。 dcraw可以使用预编译的版本，也可以自己编译源代码。\nAdobe DNG Converter 虽然是由Adobe主导的，但是DNG是一种开放、非专有的格式，基于TIFF格式，提供了充足的空间来存放来自原本RAW文件的元数据，但元数据的命名仍会随品牌而变化。缺点是不提供Linux版本，只有Windows和MacOS可用。在本案例中，需要启用未压缩，关闭线性、解马赛克。向前兼容可随意选择。\nRAW to MATLAB Tutorial 在MATLAB中处理RAW DNG Converter能够将RAW文件中的EXIF标签命名统一，并根据Adobe对各种相机的测试向其中添加一些原本不存在的信息，例如黑电平和饱和水平。\n在MATLAB中使用imfinfo(\u0026quot;filename.dng\u0026quot;)能够返回一个包含EXIF和RAW的结构。\n在dcraw中，则可以通过dcraw -v启用详细信息，获得我们需要的黑电平，饱和值和各颜色通道的增益系数。\n在dcraw中使用dcraw -4 -D -T file_name可以生成线性16bit，未经提亮、Gamma调整、解马赛克的TIFF格式图像，使用imread就能方便的导入MATLAB。\nLinearizing 线性化 上一步获得的二维向量实际上并不是线性的图像，相机很有可能应用了一个非线性的传输方式来压缩和存储。DNG元数据中将会包含一个表，meta_info.SubIFDs{1}.LinearizationTable，通过这个LUT可以将图像线性化处理，如果元数据中不包含这个表，则表示图像已经是线性的了。如果使用了dcraw的‘-4’选项，则已经应用过这个LUT了。\n另外，需要根据黑电平和饱和值来将像素值归一化到[0,1]之间，由于噪声的存在，像素值可能高过饱和值或低于黑电平，需要进行裁切。注意有些传感器的不同拜尔滤镜通道可能具备不同的黑电平和饱和值，需要进行处理。\nWhite Balancing 白平衡 首先，需要确定拜尔滤镜排列的方式，以及RGB对应的增益系数，增益系数可以是厂商定义的各场景下的标准值，或是相机在拍摄时计算得到的值。\n原文通过一个wbmask函数根据拜尔滤镜排列方式定义出各种像素的遮罩，再以点乘矩阵的办法将增益应用到图像上。\nDemosaicing 解马赛克 解马赛克有非常多的方法，也是研究的热点之一。MATLAB中内置了一种解马赛克的方法，只要输入图像和拜尔滤镜排列方式，调用demosaic(Img, 'rggb')即可完成解马赛克。注意MATLAB内置的解马赛克函数只接受uint8或uint16输入，之前我们都以浮点存储数据，这一步需进行变换。\nColor Space Conversion 色彩空间转换 如前所述，相机的颜色基与显示器是不用的，现在MATLAB的imshow函数能够显示图像，但是其颜色实际上是不准确的，因此，我们需要将图像中颜色的基进行变换，这一步将用到一个3x3的矩阵。\n这个转换矩阵实际上是很难获得的，dcraw使用的矩阵由Adobe处获得，具体方法是先将相机的色彩空间转换到XYZ色彩空间，再从XYZ色彩空间转换到sRGB等需要的色彩空间。这两步矩阵可以合为一步。\n我们希望确保变换前后图像中白色像素的像素值均为[1,1,1]，因此需要对转换矩阵进行归一化，使其满足每一行的和为1。而sRGB和XYZ间的转换矩阵可以很方便的从各种地方获得。\nDNG中，转换矩阵存储在meta_info.ColorMatrix2中，dcraw则需要到源码中寻找。\nBrightness and Gamma Correction 亮度与伽马矫正 现在，我们的图像仍然是线性的，并不适合用来显示。因此需要做一些亮度调整，可以是乘上一个系数，也可以是一个较复杂的非线性函数。注意，这一步可能是高度主观的。\n平均亮度是最大值的四分之一 Gamma校正，应用一个2.2的gamma曲线，即Target = Current .^ (1/2.2)，Gamma曲线是一种功率函数，在最低像素值区域包含一小段线性分段。 处理结束。\n","permalink":"https://jackchou.top/posts/old/processingrawinmatlab/","summary":"\u003ch2 id=\"process-raw-images-in-matlab\"\u003eProcess RAW Images in MATLAB\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e这是一篇由Rob Sumner写于2014年的文章，详细讲述了什么是RAW和在MATLAB中处理RAW文件。以下是对其的补充和若干翻译。\u003c/p\u003e","title":"Processing Raw Images in MATLAB"},{"content":"问题描述 由Hugo生成的静态网页在本地运行时正常，将Public目录push到Github后，Github Pages无法正确显示CSS样式。\n解决 这一问题是由于Windows和MacOS或linux系统的换行符不同导致的，而Git会自动将换行符转换为CRLF，因此在Windows上生成的静态网页在Github上无法正确显示。 解决办法是将git的换行符转换功能关闭，即:\ngit config --global core.autocrlf false 再次push到Github上，即可正常显示。\n","permalink":"https://jackchou.top/posts/old/%E8%A7%A3%E5%86%B3%E6%8D%A2%E8%A1%8C%E7%AC%A6%E5%AF%BC%E8%87%B4%E7%9A%84hugo%E9%97%AE%E9%A2%98/","summary":"\u003ch2 id=\"问题描述\"\u003e问题描述\u003c/h2\u003e\n\u003cp\u003e由Hugo生成的静态网页在本地运行时正常，将Public目录push到Github后，Github Pages无法正确显示CSS样式。\u003c/p\u003e\n\u003ch2 id=\"解决\"\u003e解决\u003c/h2\u003e\n\u003cp\u003e这一问题是由于Windows和MacOS或linux系统的换行符不同导致的，而Git会自动将换行符转换为CRLF，因此在Windows上生成的静态网页在Github上无法正确显示。  \u003cbr\u003e\n解决办法是将git的换行符转换功能关闭，即:\u003c/p\u003e","title":"解决换行符导致的hugo主题渲染问题"},{"content":"Hello World!\n这里是Jackchou00的个人博客，由Hugo搭建并部署在Github上。\n我正在尝试在文章中添加图片，请期待！目前的尝试是使用Webp格式的图片，将图片放置于Hugo的Static文件夹中以备调用。之后将会转向Avif或JPEG-XL，因为他们具有更高的效率。\n","permalink":"https://jackchou.top/posts/old/helloworld/","summary":"\u003cp\u003eHello World!\u003c/p\u003e\n\u003cp\u003e这里是Jackchou00的个人博客，由Hugo搭建并部署在Github上。\u003c/p\u003e\n\u003cp\u003e我正在尝试在文章中添加图片，请期待！目前的尝试是使用Webp格式的图片，将图片放置于Hugo的Static文件夹中以备调用。之后将会转向Avif或JPEG-XL，因为他们具有更高的效率。\u003c/p\u003e","title":"HelloWorld"}]