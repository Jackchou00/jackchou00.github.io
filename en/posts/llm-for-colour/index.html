<!DOCTYPE html>
<html lang="en"
    dir=" auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Using LLMs for Colour Science: Best Practices and Test Questions | JacksBlog</title>
<meta name="keywords" content="Large Language Models, Colour Science, Python Numerical Calculations, LLM Chain-of-Thought Reasoning, RGB Gamut Cube Python, LLM Hallucination Mitigation">
<meta name="description" content="Use LLMs for technical tasks: avoid direct math, leverage Chain-of-Thought, handle long contexts.">
<meta name="author" content="Miaosen Zhou">
<link rel="canonical" href="https://jackchou.top/en/posts/llm-for-colour/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.e30af01949f15b214a659db89950589c44040efcfcdeec2087ad8629d77c216e.css" integrity="sha256-4wrwGUnxWyFKZZ24mVBYnEQEDvz83uwgh62GKdd8IW4=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://jackchou.top/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://jackchou.top/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://jackchou.top/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://jackchou.top/apple-touch-icon.png">
<link rel="mask-icon" href="https://jackchou.top/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh-cn" href="https://jackchou.top/posts/llm-for-colour/">
<link rel="alternate" hreflang="en" href="https://jackchou.top/en/posts/llm-for-colour/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css" integrity="sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js" integrity="sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js" integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>


<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Google+Sans+Code:ital,wght@0,300..800;1,300..800&family=Noto+Sans+SC:wght@100..900&family=Sen:wght@400..800&display=swap" rel="stylesheet"><script type="text/javascript">
    (function (c, l, a, r, i, t, y) {
        c[a] = c[a] || function () { (c[a].q = c[a].q || []).push(arguments) };
        t = l.createElement(r); t.async = 1; t.src = "https://www.clarity.ms/tag/" + i;
        y = l.getElementsByTagName(r)[0]; y.parentNode.insertBefore(t, y);
    })(window, document, "clarity", "script", "u9z1afks70");
</script><meta property="og:url" content="https://jackchou.top/en/posts/llm-for-colour/">
  <meta property="og:site_name" content="JacksBlog">
  <meta property="og:title" content="Using LLMs for Colour Science: Best Practices and Test Questions">
  <meta property="og:description" content="Use LLMs for technical tasks: avoid direct math, leverage Chain-of-Thought, handle long contexts.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-08-21T02:00:00+08:00">
    <meta property="article:modified_time" content="2025-11-19T01:17:33+08:00">
    <meta property="article:tag" content="LLM">
      <meta property="og:image" content="https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp">
<meta name="twitter:title" content="Using LLMs for Colour Science: Best Practices and Test Questions">
<meta name="twitter:description" content="Use LLMs for technical tasks: avoid direct math, leverage Chain-of-Thought, handle long contexts.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts üå≥",
      "item": "https://jackchou.top/en/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Using LLMs for Colour Science: Best Practices and Test Questions",
      "item": "https://jackchou.top/en/posts/llm-for-colour/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Using LLMs for Colour Science: Best Practices and Test Questions",
  "name": "Using LLMs for Colour Science: Best Practices and Test Questions",
  "description": "Use LLMs for technical tasks: avoid direct math, leverage Chain-of-Thought, handle long contexts.",
  "keywords": [
    "Large Language Models", "Colour Science", "Python Numerical Calculations", "LLM Chain-of-Thought Reasoning", "RGB Gamut Cube Python", "LLM Hallucination Mitigation"
  ],
  "articleBody": "Getting the Right Perspective on LLMs Large Language Models (LLMs) aren‚Äôt all-powerful magic, but rather powerful tools. It‚Äôs crucial to have the right perspective on LLMs, understand their limitations and characteristics, and choose the right model for the right job. We shouldn‚Äôt use them for tasks they aren‚Äôt good at, or try to force a square peg into a round hole.\nMathematical Calculations LLMs are not inherently good at precise mathematical calculations in a native conversation. Many models might fail to directly compare 9.11 and 9.9, or even, when analysing the pack14 function below, might make an absurd claim like 6 * 14 = 7 * 8 just to make its logic seem consistent.\nA brief explanation of the principle: This is a result of both the tokenisation mechanism and the fundamental nature of the model. LLMs break text down into ‚Äútokens‚Äù. A number like 9.11 might be split into three tokens: „Äå9„Äç, „Äå.„Äç, and „Äå11„Äç. When the model processes this, it sees a sequence pattern, not a single numerical value. It is fundamentally a language pattern matcher, not a symbolic calculator. Although it can ‚Äúmemorise‚Äù simple calculation results (like 2+2=4) by learning from vast amounts of text, it can easily make mistakes with slightly more complex, uncommon, or multi-step calculations.\nTherefore, rather than asking it to perform high-risk calculations directly, it‚Äôs better to leverage its coding abilities.\nFor example, the following is a poor way to ask. CIECAM16 involves many computational steps, and even Gemini 2.5 Pro cannot calculate it directly and accurately, and it takes a long time.\nXYZ = [19.01, 20.00, 21.78] XYZ_w = [95.05, 100.00, 108.88] L_A = 318.31 Y_b = 20.0 surround = \"Average\" Please calculate the CIECAM16 model's predicted appearance attributes based on the input above. It‚Äôs better to just ask it to write a Python function. A better way to ask is:\nPlease write a Python function that takes the CIECAM16 model's input parameters (XYZ, XYZ_w, L_A, Y_b, surround) and returns the calculated appearance attributes. Please use the NumPy library for numerical operations. This way, a top-tier model like Gemini 2.5 Pro can provide code that is quite complete and very close to correct, but for such niche and complex formulae, asking the LLM to answer purely from its own knowledge is asking too much.\nA small tip: Gemini parses PDFs via native multimodality. It turns each page into a number of tokens rather than directly parsing the text or content. This works well for poor layouts with lots of figures (especially academic papers). You can find more technical details in the docs. For example, if you feed the CAM16 paper to Gemini, it can accurately locate all the formulae and reproduce them correctly.\nReasoning: The Value of Thought For complex problems that require multi-step analysis, choosing a model that excels at reasoning is highly valuable. The core value lies in the Chain-of-Thought (CoT), where the model shows its step-by-step thinking process, which is sometimes more valuable than the answer itself.\nA clear and complete chain of thought allows you to:\nVerify its logic: Understand how it arrived at the conclusion, thereby judging the reliability of the conclusion. Spot errors: If the model makes a mistake in a certain step, you can clearly see where the problem lies. Learn new approaches: Observing the model‚Äôs thought process can sometimes offer you new perspectives for solving a problem. DeepSeek‚Äôs R1 is a good choice; its chain of thought is complete and detailed without being excessively long-winded. For other models, you can try adding the phrase ‚ÄúLet‚Äôs think step by step.‚Äù\nCut Your Losses Nowadays, LLMs have increasingly large context windows, with some models even offering millions of tokens of context length. But this doesn‚Äôt mean they can always maintain a high level of performance in long conversations. In fact, a long context is a double-edged sword, especially when the model starts making mistakes.\nWhen you try to repeatedly correct a model that is making errors in a conversation, its previous incorrect answers are packaged into the new context as history. This creates a contaminated context, leading the model into a vicious cycle of logical confusion.\nYou will observe that the model may start to get stuck on its own flawed reasoning. Even if you point out the problem, it struggles to break free. A very clear ‚Äúred flag‚Äù is when the model, after making repeated mistakes, starts to apologise frequently and intensely, using emotionally charged words like ‚ÄúI‚Äôm so sorry,‚Äù ‚ÄúI was completely wrong,‚Äù or ‚ÄúLet me try again.‚Äù This usually means its reasoning chain has been thoroughly corrupted.\nAt this point, the wisest course of action is to cut your losses. Don‚Äôt waste any more tokens and time ‚Äúpushing‚Äù or ‚Äúteaching‚Äù it; this will most likely only get you more incorrect information.\nThe correct approach is:\nEdit and retry: If your tool supports it, simply delete the conversation turns starting from where the error occurred. Then, modify your prompt with more explicit constraints or directly rule out the line of reasoning where it previously failed, and ask again. Start from scratch: This is the cleanest method. Open a new chat and design a better initial prompt. Incorporate what you learned from the previous failure, such as giving the model more background information, clearer instructions, or even telling it to be wary of certain potential pitfalls. Collaborating with an LLM is more like setting the initial parameters for a complex computation than teaching a student. Your goal is to initiate a correct chain of thought, not to fix one that is already in disarray.\nKnowledge and Hallucinations Without access to the internet or external tools, an LLM‚Äôs knowledge is stored entirely within its vast model parameters, which is known as parametric knowledge. This knowledge consists of patterns it has ‚Äúmemorised‚Äù from its massive training data. For a niche field like colour science, models with over 400B parameters and a rich store of world knowledge tend to have a relatively comprehensive understanding.\nThis leads to the problem of hallucination. When you ask a model for specific paper information or request it to write a professional literature review, it is very likely to invent bibliographic information.\nThe correct approach is to use tools and internet access, such as Retrieval-Augmented Generation (RAG). Many modern LLM products (like Gemini with its integrated Google Search, or some Deep Research tools) have the ability to search the web. They will first conduct a web search based on your question and then organise and answer based on reliable, real-time sources, which greatly improves the accuracy and timeliness of the answers. Gemini and Grok perform relatively well in this regard.\nAdditionally, asking the model questions like ‚ÄúWho are you?‚Äù or ‚ÄúWhat‚Äôs the date today?‚Äù doesn‚Äôt reflect its true performance, as these answers are typically hardcoded in the product‚Äôs system prompt, otherwise the model wouldn‚Äôt be able to answer.\nAssessing a Model‚Äôs True Capabilities When a new model is launched, claiming to be the new state-of-the-art (SOTA), how can you quickly test its capabilities and see if it performs well in colour science and image processing? Here are some test questions I‚Äôve accumulated to quickly try out a model.\nLogical Trap in a Bit-Packing Function import numpy as np def pack10(data : np.ndarray) -\u003e np.ndarray: # Function to pack 10-bit data into an 8-bit array out = np.zeros((data.shape[0], int(data.shape[1]*(1.25))), dtype=np.uint8) out[:, ::5] = data[:, ::4] \u003e\u003e 2 out[:, 1::5] = ((data[:, ::4] \u0026 0b0000000000000011) \u003c\u003c 6) out[:, 1::5] += data[:, 1::4] \u003e\u003e 4 out[:, 2::5] = ((data[:, 1::4] \u0026 0b0000000000001111) \u003c\u003c 4) out[:, 2::5] += data[:, 2::4] \u003e\u003e 6 out[:, 3::5] = ((data[:, 2::4] \u0026 0b0000000000111111) \u003c\u003c 2) out[:, 3::5] += data[:, 3::4] \u003e\u003e 8 out[:, 4::5] = data[:, 3::4] \u0026 0b0000000011111111 return out def pack12(data : np.ndarray) -\u003e np.ndarray: # Function to pack 12-bit data into an 8-bit array out = np.zeros((data.shape[0], int(data.shape[1]*(1.5))), dtype=np.uint8) out[:, ::3] = data[:, ::2] \u003e\u003e 4 out[:, 1::3] = ((data[:, ::2] \u0026 0b0000000000001111) \u003c\u003c 4) out[:, 1::3] += data[:, 1::2] \u003e\u003e 8 out[:, 2::3] = data[:, 1::2] \u0026 0b0000001111111111 return out def pack14(data : np.ndarray) -\u003e np.ndarray: # Function to pack 14-bit data into an 8-bit array out = np.zeros((data.shape[0], int(data.shape[1]*(1.75))), dtype=np.uint8) out[:, ::7] = data[:, ::6] \u003e\u003e 6 out[:, 1::7] = ((data[:, ::6] \u0026 0b0000000000000011) \u003c\u003c 6) out[:, 1::7] += data[:, 1::6] \u003e\u003e 8 out[:, 2::7] = ((data[:, 1::6] \u0026 0b0000000000001111) \u003c\u003c 4) out[:, 2::7] += data[:, 2::6] \u003e\u003e 6 out[:, 3::7] = ((data[:, 2::6] \u0026 0b0000000000111111) \u003c\u003c 2) out[:, 3::7] += data[:, 3::6] \u003e\u003e 8 out[:, 4::7] = ((data[:, 3::6] \u0026 0b0000000000001111) \u003c\u003c 4) out[:, 4::7] += data[:, 4::6] \u003e\u003e 6 out[:, 5::7] = ((data[:, 4::6] \u0026 0b0000000000111111) \u003c\u003c 2) out[:, 5::7] += data[:, 5::6] \u003e\u003e 8 out[:, 6::7] = data[:, 5::6] \u0026 0b0000000011111111 return out Please explain in detail what these three Python functions do. This code is from the PiDNG library and is intended to compress high-bit-depth data (10-bit, 12-bit, 14-bit) into an 8-bit uint8 array. The implementations for pack10 and pack12 are correct.\npack10: 4 x 10-bit values (40 bits) -\u003e 5 x 8-bit values (40 bits). pack12: 2 x 12-bit values (24 bits) -\u003e 3 x 8-bit values (24 bits).\nHowever, the pack14 function is incorrect. It tries to pack 6 x 14-bit values (6 * 14 = 84 bits) into 7 x 8-bit bytes (7 * 8 = 56 bits), which is mathematically impossible. The correct implementation should pack 4 x 14-bit values (4 * 14 = 56 bits) into 7 bytes.\nCommon mistake: Explaining the code of pack14 line by line without realising its logical error. Or, in an attempt to make the code seem consistent, fabricating an incorrect mathematical explanation, such as claiming that 6 * 14 equals 56.\nConcept of an RGB Gamut Cube How to determine if a given XYZ tristimulus value is within the gamut of an RGB space. The RGB space is defined by four CIE xy coordinates, representing red, green, blue, and white (where the white point's luminance is normalised to 1.0). Please provide the corresponding Python code implementation. This question tests whether the LLM understands that an RGB gamut is a three-dimensional cube (or parallelepiped), not a two-dimensional triangle.\nThe correct solution:\nConstruct the transformation matrix: Use the xy coordinates of the three primaries (red, green, blue) and the white point to calculate the 3x3 transformation matrix M from the RGB space to the CIE XYZ space. Invert the matrix: Calculate the inverse matrix M_inv, which is the transformation matrix from XYZ to RGB. Transform the coordinates: Left-multiply the given XYZ value by M_inv to get the corresponding RGB values. Check the range: Check if the calculated R, G, and B components are all within the closed interval of [0, 1]. If they all are, the XYZ value is within the RGB gamut; otherwise, it is out of gamut. A common incorrect solution:\nConverting the input XYZ value into xy coordinates as well. Then, checking on the CIE xy chromaticity diagram if this point lies within the triangle formed by the xy coordinates of the R, G, and B primaries. This method completely ignores the colour‚Äôs luminance (Y) information and is incorrect. A colour might have the correct chromaticity but be out of the target gamut because it is too bright or too dark. CIECAM16 Code Implementation Please write a Python function that takes the CIECAM16 model's input parameters (XYZ, XYZ_w, L_A, Y_b, surround) and returns the calculated appearance attributes. Please use the NumPy library for numerical operations. In the main function, calculate for: XYZ = [19.01, 20.00, 21.78] XYZ_w = [95.05, 100.00, 108.88] L_A = 318.31 Y_b = 20.0 surround = \"Average\" This tests the model‚Äôs world knowledge and programming ability. For a complex model like CIECAM16, it‚Äôs better to provide the LLM with the full PDF standard, but large-parameter models are capable of writing correct code directly. The best performers are Gemini 2.5 Pro, GPT 5 (high), and DeepSeek R1 0528, all of which made only minor mistakes in 1-2 formulas. The correct output is:\n{ \"J\": 41.73120790512664, \"C\": 0.10335573870906986, \"h\": 217.067959767393, \"Q\": 195.37170899282242, \"M\": 0.10743677233590453, \"s\": 2.3450150729795514 } November 6, 2025: The leaked gemini-3-pro-preview-11-2025 is the first large model capable of directly writing a completely error-free CIECAM16 without reference.\nNovember 18, 2025: The officially released gemini-3-pro-preview wrote the correct code cleanly and effortlessly.\nThe 3D shape of xyY In a finite RGB space where each of the three components ranges from 0 to 1, the values can be converted to XYZ through a 3√ó3 matrix. If plotted in a 3D coordinate system, RGB forms a cube, XYZ forms a parallelepiped. XYZ can then be converted to xyY. When we plot xyY in a 3D coordinate system, using xy as the base plane and Y as the z-axis, what shape do we get? The linear transformation from RGB to XYZ is straightforward: it stretches a unit cube into a parallelepiped. The conversion to xyY is a non-linear transformation, which can be seen as a projective transformation. The resulting volume is a more complex 3D shape.\nThe correct shape is a Triangular Prism with a Tent-like Top.\nBase: The black point (0,0,0) is undefined on the xy chromaticity diagram and is typically treated as the base. Sides: Formed by extending the gamut triangle (defined by the three RGB primaries) upwards, creating three planes perpendicular to the base. Top: Formed by connecting the white point (1,1,1) with the three secondary colours (Cyan, Magenta, Yellow), creating three hyperbolic curved surfaces that resemble a collapsed tent roof. Most models incorrectly identify it as a solid with six curved surfaces. It wasn‚Äôt until the release of gemini-3-pro-preview on November 18, 2025, that a model could finally answer this question completely and correctly, accurately describing its geometric features as a ‚ÄúTriangular Prism‚Äù with a ‚ÄúTent-like Top‚Äù.\n",
  "wordCount" : "2299",
  "inLanguage": "en",
  "image": "https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp","datePublished": "2025-08-21T02:00:00+08:00",
  "dateModified": "2025-11-19T01:17:33+08:00",
  "author":{
    "@type": "Person",
    "name": "Miaosen Zhou"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://jackchou.top/en/posts/llm-for-colour/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "JacksBlog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://jackchou.top/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id=" top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://jackchou.top/en/" accesskey="h" title="JacksBlog (Alt + H)">JacksBlog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                    <li>
                        <a href="https://jackchou.top/" title="‰∏≠Êñá"
                            aria-label="‰∏≠Êñá">‰∏≠Êñá</a>
                    </li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://jackchou.top/en/posts/" title="Posts üå≥">
                    <span>Posts üå≥</span>
                </a>
            </li>
            <li>
                <a href="https://jackchou.top/en/photos/" title="Photos üì∑">
                    <span>Photos üì∑</span>
                </a>
            </li>
            <li>
                <a href="https://jackchou.top/en/tags/" title="Tags üè∑Ô∏è">
                    <span>Tags üè∑Ô∏è</span>
                </a>
            </li>
            <li>
                <a href="https://jackchou.top/en/about/" title="About üòº">
                    <span>About üòº</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Using LLMs for Colour Science: Best Practices and Test Questions
    </h1>
    
    <div class="post-meta"><span title='2025-08-21 02:00:00 +0800 +0800'>2025.08.21</span>&nbsp;|&nbsp;Translations:
<ul class="i18n_list">
    <li>
        <a href="https://jackchou.top/posts/llm-for-colour/">‰∏≠Êñá</a>
    </li>
</ul>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#getting-the-right-perspective-on-llms" aria-label="Getting the Right Perspective on LLMs">Getting the Right Perspective on LLMs</a><ul>
                        
                <li>
                    <a href="#mathematical-calculations" aria-label="Mathematical Calculations">Mathematical Calculations</a></li>
                <li>
                    <a href="#reasoning-the-value-of-thought" aria-label="Reasoning: The Value of Thought">Reasoning: The Value of Thought</a></li>
                <li>
                    <a href="#cut-your-losses" aria-label="Cut Your Losses">Cut Your Losses</a></li>
                <li>
                    <a href="#knowledge-and-hallucinations" aria-label="Knowledge and Hallucinations">Knowledge and Hallucinations</a></li></ul>
                </li>
                <li>
                    <a href="#assessing-a-models-true-capabilities" aria-label="Assessing a Model&rsquo;s True Capabilities">Assessing a Model&rsquo;s True Capabilities</a><ul>
                        
                <li>
                    <a href="#logical-trap-in-a-bit-packing-function" aria-label="Logical Trap in a Bit-Packing Function">Logical Trap in a Bit-Packing Function</a></li>
                <li>
                    <a href="#concept-of-an-rgb-gamut-cube" aria-label="Concept of an RGB Gamut Cube">Concept of an RGB Gamut Cube</a></li>
                <li>
                    <a href="#ciecam16-code-implementation" aria-label="CIECAM16 Code Implementation">CIECAM16 Code Implementation</a></li>
                <li>
                    <a href="#the-3d-shape-of-xyy" aria-label="The 3D shape of xyY">The 3D shape of xyY</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="getting-the-right-perspective-on-llms">Getting the Right Perspective on LLMs<a hidden class="anchor" aria-hidden="true" href="#getting-the-right-perspective-on-llms">#</a></h2>
<p>Large Language Models (LLMs) aren&rsquo;t all-powerful magic, but rather powerful tools. It&rsquo;s crucial to have the right perspective on LLMs, understand their limitations and characteristics, and choose the right model for the right job. We shouldn&rsquo;t use them for tasks they aren&rsquo;t good at, or try to force a square peg into a round hole.</p>
<h3 id="mathematical-calculations">Mathematical Calculations<a hidden class="anchor" aria-hidden="true" href="#mathematical-calculations">#</a></h3>
<p>LLMs are not inherently good at precise mathematical calculations in a native conversation. Many models might fail to directly compare 9.11 and 9.9, or even, when analysing the <code>pack14</code> function below, might make an absurd claim like 6 * 14 = 7 * 8 just to make its logic seem consistent.</p>
<p>A brief explanation of the principle: This is a result of both the tokenisation mechanism and the fundamental nature of the model. LLMs break text down into &ldquo;tokens&rdquo;. A number like 9.11 might be split into three tokens: „Äå9„Äç, „Äå.„Äç, and „Äå11„Äç. When the model processes this, it sees a sequence pattern, not a single numerical value. It is fundamentally a language pattern matcher, not a symbolic calculator. Although it can &ldquo;memorise&rdquo; simple calculation results (like 2+2=4) by learning from vast amounts of text, it can easily make mistakes with slightly more complex, uncommon, or multi-step calculations.</p>
<p>Therefore, rather than asking it to perform high-risk calculations directly, it&rsquo;s better to leverage its coding abilities.</p>
<p>For example, the following is a poor way to ask. CIECAM16 involves many computational steps, and even Gemini 2.5 Pro cannot calculate it directly and accurately, and it takes a long time.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span>XYZ = [19.01, 20.00, 21.78]
</span></span><span style="display:flex;"><span>XYZ_w = [95.05, 100.00, 108.88]
</span></span><span style="display:flex;"><span>L_A = 318.31
</span></span><span style="display:flex;"><span>Y_b = 20.0
</span></span><span style="display:flex;"><span>surround = &#34;Average&#34;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Please calculate the CIECAM16 model&#39;s predicted appearance attributes based on the input above.
</span></span></code></pre></div><p>It&rsquo;s better to just ask it to write a Python function. A better way to ask is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span>Please write a Python function that takes the CIECAM16 model&#39;s input parameters (XYZ, XYZ_w, L_A, Y_b, surround) and returns the calculated appearance attributes. Please use the NumPy library for numerical operations.
</span></span></code></pre></div><p>This way, a top-tier model like Gemini 2.5 Pro can provide code that is quite complete and very close to correct, but for such niche and complex formulae, asking the LLM to answer purely from its own knowledge is asking too much.</p>
<blockquote>
<p>A small tip: Gemini parses PDFs via native multimodality. It turns each page into a number of tokens rather than directly parsing the text or content. This works well for poor layouts with lots of figures (especially academic papers). You can find more technical details in the <a href="https://ai.google.dev/gemini-api/docs/document-processing#technical-detail">docs</a>. For example, if you feed the CAM16 paper to Gemini, it can accurately locate all the formulae and reproduce them correctly.</p>
</blockquote>
<h3 id="reasoning-the-value-of-thought">Reasoning: The Value of Thought<a hidden class="anchor" aria-hidden="true" href="#reasoning-the-value-of-thought">#</a></h3>
<p>For complex problems that require multi-step analysis, choosing a model that excels at reasoning is highly valuable. The core value lies in the Chain-of-Thought (CoT), where the model shows its step-by-step thinking process, which is sometimes more valuable than the answer itself.</p>
<p>A clear and complete chain of thought allows you to:</p>
<ol>
<li>Verify its logic: Understand how it arrived at the conclusion, thereby judging the reliability of the conclusion.</li>
<li>Spot errors: If the model makes a mistake in a certain step, you can clearly see where the problem lies.</li>
<li>Learn new approaches: Observing the model&rsquo;s thought process can sometimes offer you new perspectives for solving a problem.</li>
</ol>
<p>DeepSeek&rsquo;s R1 is a good choice; its chain of thought is complete and detailed without being excessively long-winded. For other models, you can try adding the phrase &ldquo;Let&rsquo;s think step by step.&rdquo;</p>
<h3 id="cut-your-losses">Cut Your Losses<a hidden class="anchor" aria-hidden="true" href="#cut-your-losses">#</a></h3>
<p>Nowadays, LLMs have increasingly large context windows, with some models even offering millions of tokens of context length. But this doesn&rsquo;t mean they can always maintain a high level of performance in long conversations. In fact, a long context is a double-edged sword, especially when the model starts making mistakes.</p>
<p>When you try to repeatedly correct a model that is making errors in a conversation, its previous incorrect answers are packaged into the new context as history. This creates a contaminated context, leading the model into a vicious cycle of logical confusion.</p>
<p>You will observe that the model may start to get stuck on its own flawed reasoning. Even if you point out the problem, it struggles to break free. A very clear &ldquo;red flag&rdquo; is when the model, after making repeated mistakes, starts to apologise frequently and intensely, using emotionally charged words like &ldquo;I&rsquo;m so sorry,&rdquo; &ldquo;I was completely wrong,&rdquo; or &ldquo;Let me try again.&rdquo; This usually means its reasoning chain has been thoroughly corrupted.</p>
<p>At this point, the wisest course of action is to cut your losses. Don&rsquo;t waste any more tokens and time &ldquo;pushing&rdquo; or &ldquo;teaching&rdquo; it; this will most likely only get you more incorrect information.</p>
<p>The correct approach is:</p>
<ol>
<li>Edit and retry: If your tool supports it, simply delete the conversation turns starting from where the error occurred. Then, modify your prompt with more explicit constraints or directly rule out the line of reasoning where it previously failed, and ask again.</li>
<li>Start from scratch: This is the cleanest method. Open a new chat and design a better initial prompt. Incorporate what you learned from the previous failure, such as giving the model more background information, clearer instructions, or even telling it to be wary of certain potential pitfalls.</li>
</ol>
<p>Collaborating with an LLM is more like setting the initial parameters for a complex computation than teaching a student. Your goal is to initiate a correct chain of thought, not to fix one that is already in disarray.</p>
<h3 id="knowledge-and-hallucinations">Knowledge and Hallucinations<a hidden class="anchor" aria-hidden="true" href="#knowledge-and-hallucinations">#</a></h3>
<p>Without access to the internet or external tools, an LLM&rsquo;s knowledge is stored entirely within its vast model parameters, which is known as parametric knowledge. This knowledge consists of patterns it has &ldquo;memorised&rdquo; from its massive training data. For a niche field like colour science, models with over 400B parameters and a rich store of world knowledge tend to have a relatively comprehensive understanding.</p>
<p>This leads to the problem of hallucination. When you ask a model for specific paper information or request it to write a professional literature review, it is very likely to invent bibliographic information.</p>
<p>The correct approach is to use tools and internet access, such as Retrieval-Augmented Generation (RAG). Many modern LLM products (like Gemini with its integrated Google Search, or some Deep Research tools) have the ability to search the web. They will first conduct a web search based on your question and then organise and answer based on reliable, real-time sources, which greatly improves the accuracy and timeliness of the answers. Gemini and Grok perform relatively well in this regard.</p>
<p>Additionally, asking the model questions like &ldquo;Who are you?&rdquo; or &ldquo;What&rsquo;s the date today?&rdquo; doesn&rsquo;t reflect its true performance, as these answers are typically hardcoded in the product&rsquo;s system prompt, otherwise the model wouldn&rsquo;t be able to answer.</p>
<h2 id="assessing-a-models-true-capabilities">Assessing a Model&rsquo;s True Capabilities<a hidden class="anchor" aria-hidden="true" href="#assessing-a-models-true-capabilities">#</a></h2>
<p>When a new model is launched, claiming to be the new state-of-the-art (SOTA), how can you quickly test its capabilities and see if it performs well in colour science and image processing? Here are some test questions I&rsquo;ve accumulated to quickly try out a model.</p>
<h3 id="logical-trap-in-a-bit-packing-function">Logical Trap in a Bit-Packing Function<a hidden class="anchor" aria-hidden="true" href="#logical-trap-in-a-bit-packing-function">#</a></h3>
<pre tabindex="0"><code>import numpy as np

def pack10(data : np.ndarray) -&gt; np.ndarray:
    # Function to pack 10-bit data into an 8-bit array
    out = np.zeros((data.shape[0], int(data.shape[1]*(1.25))), dtype=np.uint8)
    out[:, ::5] = data[:, ::4] &gt;&gt; 2
    out[:, 1::5] = ((data[:, ::4] &amp; 0b0000000000000011) &lt;&lt; 6)
    out[:, 1::5] += data[:, 1::4] &gt;&gt; 4
    out[:, 2::5] = ((data[:, 1::4] &amp; 0b0000000000001111) &lt;&lt; 4)
    out[:, 2::5] += data[:, 2::4] &gt;&gt; 6
    out[:, 3::5] = ((data[:, 2::4] &amp; 0b0000000000111111) &lt;&lt; 2)
    out[:, 3::5] += data[:, 3::4] &gt;&gt; 8
    out[:, 4::5] = data[:, 3::4] &amp; 0b0000000011111111
    return out

def pack12(data : np.ndarray) -&gt; np.ndarray:
    # Function to pack 12-bit data into an 8-bit array
    out = np.zeros((data.shape[0], int(data.shape[1]*(1.5))), dtype=np.uint8)
    out[:, ::3] = data[:, ::2] &gt;&gt; 4
    out[:, 1::3] = ((data[:, ::2] &amp; 0b0000000000001111) &lt;&lt; 4)
    out[:, 1::3] += data[:, 1::2] &gt;&gt; 8
    out[:, 2::3] = data[:, 1::2] &amp; 0b0000001111111111
    return out

def pack14(data : np.ndarray) -&gt; np.ndarray:
    # Function to pack 14-bit data into an 8-bit array
    out = np.zeros((data.shape[0], int(data.shape[1]*(1.75))), dtype=np.uint8)
    out[:, ::7] = data[:, ::6] &gt;&gt; 6
    out[:, 1::7] = ((data[:, ::6] &amp; 0b0000000000000011) &lt;&lt; 6)
    out[:, 1::7] += data[:, 1::6] &gt;&gt; 8
    out[:, 2::7] = ((data[:, 1::6] &amp; 0b0000000000001111) &lt;&lt; 4)
    out[:, 2::7] += data[:, 2::6] &gt;&gt; 6
    out[:, 3::7] = ((data[:, 2::6] &amp; 0b0000000000111111) &lt;&lt; 2)
    out[:, 3::7] += data[:, 3::6] &gt;&gt; 8
    out[:, 4::7] = ((data[:, 3::6] &amp; 0b0000000000001111) &lt;&lt; 4)
    out[:, 4::7] += data[:, 4::6] &gt;&gt; 6
    out[:, 5::7] = ((data[:, 4::6] &amp; 0b0000000000111111) &lt;&lt; 2)
    out[:, 5::7] += data[:, 5::6] &gt;&gt; 8
    out[:, 6::7] = data[:, 5::6] &amp; 0b0000000011111111
    return out

Please explain in detail what these three Python functions do.
</code></pre><p>This code is from the PiDNG library and is intended to compress high-bit-depth data (10-bit, 12-bit, 14-bit) into an 8-bit uint8 array. The implementations for <code>pack10</code> and <code>pack12</code> are correct.</p>
<p><code>pack10</code>: 4 x 10-bit values (40 bits) -&gt; 5 x 8-bit values (40 bits).
<code>pack12</code>: 2 x 12-bit values (24 bits) -&gt; 3 x 8-bit values (24 bits).</p>
<p>However, the <code>pack14</code> function is incorrect. It tries to pack 6 x 14-bit values (6 * 14 = 84 bits) into 7 x 8-bit bytes (7 * 8 = 56 bits), which is mathematically impossible. The correct implementation should pack 4 x 14-bit values (4 * 14 = 56 bits) into 7 bytes.</p>
<p>Common mistake: Explaining the code of <code>pack14</code> line by line without realising its logical error. Or, in an attempt to make the code seem consistent, fabricating an incorrect mathematical explanation, such as claiming that 6 * 14 equals 56.</p>
<h3 id="concept-of-an-rgb-gamut-cube">Concept of an RGB Gamut Cube<a hidden class="anchor" aria-hidden="true" href="#concept-of-an-rgb-gamut-cube">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span>How to determine if a given XYZ tristimulus value is within the gamut of an RGB space.
</span></span><span style="display:flex;"><span>The RGB space is defined by four CIE xy coordinates, representing red, green, blue, and white (where the white point&#39;s luminance is normalised to 1.0).
</span></span><span style="display:flex;"><span>Please provide the corresponding Python code implementation.
</span></span></code></pre></div><p>This question tests whether the LLM understands that an RGB gamut is a three-dimensional cube (or parallelepiped), not a two-dimensional triangle.</p>
<p>The correct solution:</p>
<ul>
<li>Construct the transformation matrix: Use the xy coordinates of the three primaries (red, green, blue) and the white point to calculate the 3x3 transformation matrix M from the RGB space to the CIE XYZ space.</li>
<li>Invert the matrix: Calculate the inverse matrix M_inv, which is the transformation matrix from XYZ to RGB.</li>
<li>Transform the coordinates: Left-multiply the given XYZ value by M_inv to get the corresponding RGB values.</li>
<li>Check the range: Check if the calculated R, G, and B components are all within the closed interval of [0, 1]. If they all are, the XYZ value is within the RGB gamut; otherwise, it is out of gamut.</li>
</ul>
<p>A common incorrect solution:</p>
<ul>
<li>Converting the input XYZ value into xy coordinates as well.</li>
<li>Then, checking on the CIE xy chromaticity diagram if this point lies within the triangle formed by the xy coordinates of the R, G, and B primaries.</li>
<li>This method completely ignores the colour&rsquo;s luminance (Y) information and is incorrect. A colour might have the correct chromaticity but be out of the target gamut because it is too bright or too dark.</li>
</ul>
<h3 id="ciecam16-code-implementation">CIECAM16 Code Implementation<a hidden class="anchor" aria-hidden="true" href="#ciecam16-code-implementation">#</a></h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-markdown" data-lang="markdown"><span style="display:flex;"><span>Please write a Python function that takes the CIECAM16 model&#39;s input parameters (XYZ, XYZ_w, L_A, Y_b, surround) and returns the calculated appearance attributes. Please use the NumPy library for numerical operations.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>In the main function, calculate for:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>XYZ = [19.01, 20.00, 21.78]
</span></span><span style="display:flex;"><span>XYZ_w = [95.05, 100.00, 108.88]
</span></span><span style="display:flex;"><span>L_A = 318.31
</span></span><span style="display:flex;"><span>Y_b = 20.0
</span></span><span style="display:flex;"><span>surround = &#34;Average&#34;
</span></span></code></pre></div><p>This tests the model&rsquo;s world knowledge and programming ability. For a complex model like CIECAM16, it&rsquo;s better to provide the LLM with the full PDF standard, but large-parameter models are capable of writing correct code directly. The best performers are Gemini 2.5 Pro, GPT 5 (high), and DeepSeek R1 0528, all of which made only minor mistakes in 1-2 formulas. The correct output is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;J&#34;</span>: <span style="color:#ae81ff">41.73120790512664</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;C&#34;</span>: <span style="color:#ae81ff">0.10335573870906986</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;h&#34;</span>: <span style="color:#ae81ff">217.067959767393</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;Q&#34;</span>: <span style="color:#ae81ff">195.37170899282242</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;M&#34;</span>: <span style="color:#ae81ff">0.10743677233590453</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&#34;s&#34;</span>: <span style="color:#ae81ff">2.3450150729795514</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>November 6, 2025: The leaked <code>gemini-3-pro-preview-11-2025</code> is the first large model capable of directly writing a completely error-free CIECAM16 without reference.</p>
<p>November 18, 2025: The officially released <code>gemini-3-pro-preview</code> wrote the correct code cleanly and effortlessly.</p>
<h3 id="the-3d-shape-of-xyy">The 3D shape of xyY<a hidden class="anchor" aria-hidden="true" href="#the-3d-shape-of-xyy">#</a></h3>
<pre tabindex="0"><code>In a finite RGB space where each of the three components ranges from 0 to 1, the values can be converted to XYZ through a 3√ó3 matrix. If plotted in a 3D coordinate system, RGB forms a cube, XYZ forms a parallelepiped. XYZ can then be converted to xyY. When we plot xyY in a 3D coordinate system, using xy as the base plane and Y as the z-axis, what shape do we get?
</code></pre><p>The linear transformation from RGB to XYZ is straightforward: it stretches a unit cube into a parallelepiped. The conversion to xyY is a non-linear transformation, which can be seen as a projective transformation. The resulting volume is a more complex 3D shape.</p>
<p>The correct shape is a Triangular Prism with a Tent-like Top.</p>
<ul>
<li>Base: The black point (0,0,0) is undefined on the xy chromaticity diagram and is typically treated as the base.</li>
<li>Sides: Formed by extending the gamut triangle (defined by the three RGB primaries) upwards, creating three planes perpendicular to the base.</li>
<li>Top: Formed by connecting the white point (1,1,1) with the three secondary colours (Cyan, Magenta, Yellow), creating three hyperbolic curved surfaces that resemble a collapsed tent roof.</li>
</ul>
<p>Most models incorrectly identify it as a solid with six curved surfaces. It wasn&rsquo;t until the release of <code>gemini-3-pro-preview</code> on November 18, 2025, that a model could finally answer this question completely and correctly, accurately describing its geometric features as a &ldquo;Triangular Prism&rdquo; with a &ldquo;Tent-like Top&rdquo;.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://jackchou.top/en/tags/llm/">LLM</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://jackchou.top/en/posts/jpeg-structure/">
    <span class="title">¬´ Prev</span>
    <br>
    <span>HDR Image Format Analysis (II): JPEG and Its Modifications</span>
  </a>
  <a class="next" href="https://jackchou.top/en/posts/gainmap-image-intro/">
    <span class="title">Next ¬ª</span>
    <br>
    <span>Decoding HDR Image Formats (I): Basic Concepts of Gainmap</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://jackchou.top/en/">JacksBlog</a></span> ¬∑ 
        my friends&rsquo; websites: <a href="https://zhxwu.com/">zhxwu.com</a>, <a href="https://ylqian.com/">ylqian.com</a> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a><div style="text-align: center; margin-top: 10px; margin-bottom: 20px; width: 100%; display: flex; justify-content: center;">
    <img src="https://visitor-badge.laobi.icu/badge?page_id=jacksblog" alt="visitors" style="max-width: 120px; height: auto;" />
</div><script>
(() => {
    const images = document.querySelectorAll('.post-content img');
    if (!images.length) return;

    const overlay = document.createElement('div');
    overlay.className = 'image-lightbox';
    overlay.innerHTML = '<img class="image-lightbox__img" alt="" />';

    const overlayImg = overlay.querySelector('img');
    const closeOverlay = () => {
        overlay.classList.remove('is-visible');
        overlayImg.removeAttribute('src');
        document.body.style.removeProperty('overflow');
    };

    overlay.addEventListener('click', closeOverlay);
    document.addEventListener('keyup', (event) => {
        if (event.key === 'Escape' && overlay.classList.contains('is-visible')) {
            closeOverlay();
        }
    });

    document.body.appendChild(overlay);

    images.forEach((img) => {
        img.addEventListener('click', (event) => {
            event.preventDefault();
            event.stopPropagation();

            const source = img.dataset.zoomSrc || img.currentSrc || img.src;
            const cleanSrc = source.split('#')[0];

            overlayImg.src = cleanSrc;
            overlayImg.alt = img.alt || '';

            overlay.classList.add('is-visible');
            document.body.style.setProperty('overflow', 'hidden');
        });
    });
})();
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>