<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>HDR Image Format Conversion | JacksBlog</title>
<meta name=keywords content="Gainmap HDR method,HDR imaging,Image encoding"><meta name=description content="Digital images are pixel arrays compressed by JPG with DCT and Huffman coding, accurately displayed via color spaces and formats like TIFF."><meta name=author content="Miaosen Zhou"><link rel=canonical href=https://jackchou.top/en/posts/hdr-format-conversion/><link crossorigin=anonymous href=/assets/css/stylesheet.0836d676002390eb2d95514c792f0c95c72e254f79fa3685f789cce0b04d9243.css integrity="sha256-CDbWdgAjkOstlVFMeS8MlccuJU95+jaF94nM4LBNkkM=" rel="preload stylesheet" as=style><link rel=icon href=https://jackchou.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://jackchou.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://jackchou.top/favicon-32x32.png><link rel=apple-touch-icon href=https://jackchou.top/apple-touch-icon.png><link rel=mask-icon href=https://jackchou.top/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-cn href=https://jackchou.top/posts/hdr-format-conversion/><link rel=alternate hreflang=en href=https://jackchou.top/en/posts/hdr-format-conversion/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://cdn.jsdelivr.net><meta property="og:url" content="https://jackchou.top/en/posts/hdr-format-conversion/"><meta property="og:site_name" content="JacksBlog"><meta property="og:title" content="HDR Image Format Conversion"><meta property="og:description" content="Digital images are pixel arrays compressed by JPG with DCT and Huffman coding, accurately displayed via color spaces and formats like TIFF."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-25T00:00:00+08:00"><meta property="article:modified_time" content="2025-12-21T00:41:45+08:00"><meta property="article:tag" content="Colour"><meta property="og:image" content="https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp"><meta name=twitter:title content="HDR Image Format Conversion"><meta name=twitter:description content="Digital images are pixel arrays compressed by JPG with DCT and Huffman coding, accurately displayed via color spaces and formats like TIFF."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts üå≥","item":"https://jackchou.top/en/posts/"},{"@type":"ListItem","position":2,"name":"HDR Image Format Conversion","item":"https://jackchou.top/en/posts/hdr-format-conversion/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"HDR Image Format Conversion","name":"HDR Image Format Conversion","description":"Digital images are pixel arrays compressed by JPG with DCT and Huffman coding, accurately displayed via color spaces and formats like TIFF.","keywords":["Gainmap HDR method","HDR imaging","Image encoding"],"articleBody":"What is an ‚ÄúImage‚Äù? An image is essentially a ‚Äòmatrix‚Äô or an ‚Äòarray‚Äô. For example, the most common type of image might be an array with the shape (Height, Width, Channel), where the number at each position is quantised to eight bits, representing 256 different levels as an integer or floating-point number. The data stored here is generally called the code value or pixel value.\nEncoding Storing this array directly can result in a very large file, so compression methods, or ‚Äôencoding‚Äô, are needed. Encoding methods are constantly evolving. For instance, there‚Äôs JPG (JPEG) encoding, which uses techniques like chroma subsampling, Discrete Cosine Transform (DCT), and Huffman coding for compression. There‚Äôs also the highly extensible TIFF (*.tif) format, which is a container format that can internally use various lossless/lossy encoding methods like ZIP, LZW, PackBits, and even JPEG. Then there are more advanced codecs like HEIC (HEIF/HEVC) and AV1, which feature flexible partitioning structures, multi-mode intra-prediction, and more advanced entropy coding, enabling very high encoding efficiency.\nThe encoding process may introduce some loss, which is known as lossy compression. The commonly used JPG standard includes both lossless and lossy modes, although the lossless mode is rarely used. Many later encoding methods also support lossless compression‚ÄîAV1 even offers a true lossless profile. As long as one is not deliberately pursuing extreme compression ratios, the quality loss from lossy compression is actually difficult to perceive.\nAnother difference between various encoding methods is the quantisation bit depth they allow. The JPG standard supports 8-bit and 12-bit quantisation, but the 12-bit mode is also uncommon. Newer formats often support higher bit depths; for example, HEIC and AVIF can handle 10-bit or even 12-bit, while a TIFF container can hold data with 16 or even 32 bits (floating-point) per channel. This is closely related to the requirements of HDR: to avoid visible banding over a wider brightness range, higher quantisation precision is needed.\nAdditional Information A pile of numbers is meaningless on its own; we also need to know the space in which they are defined. At a minimum, the primaries, white point, and transfer function (i.e., the definition of the RGB space) must be specified.\nThis additional information tells the decoder and the system‚Äôs colour management the specific meaning of these numbers. Without it, the data is usually treated as sRGB, and if the colour space does not match the actual data, major problems will occur.\nAfter the decoding software extracts the pixel values and additional information, the colour management system converts these pixel values from a known colour space into driving values for the display, allowing them to be displayed correctly. Therefore, in theory, the code values can even be tristimulus values and linear, as long as there is corresponding additional information to define them. The images below are two PMCC colour charts tagged with the XYZ space and a linear transfer function. The pixel values in the images are directly the tristimulus values.\nThis is a tristimulus value image of a colour chart under a D65 illuminant, where values exceeding 1 have been clipped. This is actually an incorrect way of handling it; CIEXYZ in nclx requires an equal-energy white as the white point, and a Bradford CAT from an ICC profile could be used for the conversion.\nThis is the image adapted to an equal-energy white point (done by directly replacing the white point). Because it is adapted to an equal-energy white, no values will exceed 1. When displayed, the system‚Äôs colour management will perform chromatic adaptation to the display‚Äôs white point, so its appearance should be close to the background in light mode. The page background in light mode has a code value of 245.\nIf you are using iOS or iPadOS, you may not be able to see these two images. Testing on other systems has shown they are generally visible.\nAdditional information can take many forms, such as an embedded ICC profile, XML statements or nclx data stored within the image file, or it can be stored in the EXIF data.\nThis step is the most critical part of achieving an HDR effect. Once the correct transfer function is specified, the decoder can convert the code values into what is known as ‚ÄúHDR‚Äù content, which can exceed the nominal luminance of SDR.\nThere is a rather special method for implementing HDR called a Gain Map. A single file stores two images (an SDR image and a gain map) along with some corresponding additional information (specific gain coefficients, etc.). The decoder can then compute a new HDR image from the two images. Therefore, the gain map could perhaps also be considered a form of additional information.\nDisplay-Referred Linear Light When performing image format conversions, all references to linear light space should be Display-Referred. This means calculating the luminance (either brightness or absolute tristimulus values) of the image on the display after it has been shown.\nDuring decoding, the EOTF is used. During encoding, the inverse EOTF is used, not the OETF (there is a distinction for transfer functions like PQ).\nPQ or HLG Transfer Functions Similar to HDR video, changing the transfer function from Gamma or Rec. 709 to PQ or HLG can achieve the transition from SDR to HDR. For still images, the international standard ISO-22028-5 already exists.\nCanon was the first to introduce 10-bit HEIC encoding in its mirrorless cameras, using PQ as the transfer function. Sony has HLG for still images. In recent versions of ACR, the AVIF and 16-bit TIF files produced when HDR output is enabled without maximum compatibility are PQ-encoded.\nFor this type of HDR image, one simply needs to apply the correct transfer function to convert to or from linear light.\nGainmap A Gainmap is a method for implementing HDR specifically for still images. Its advantage is excellent compatibility, as it can store both SDR and HDR content simultaneously (rather than relying on dynamic metadata and a TMO) and is very friendly to display drivers.\nJPG, JXL, and AVIF can all store this format. In particular, a JPG with a Gainmap is essentially two JPG files concatenated together. Image viewers that do not support this format will simply read the first file as a standard SDR image. When sending the original image on social media, the subsequent Gainmap can be preserved. Even if the app itself does not support it, saving it to another app may still reveal the HDR effect.\nThe first large-scale application of Gainmap was likely on the OPPO Find X6 Pro. Later, Google promoted the UltraHDR format. The ISO is currently developing the ISO-21496-1 standard, and UltraHDR version 1.1 is already compatible with this standard.\nA Gainmap can be written for luminance only or for all three channels. The ‚ÄúProXDR‚Äù in the recently released OPPO Find X8 Ultra refers to a three-channel Gainmap.\nA Gainmap can be understood as a form of Supplemental Enhancement Information (SEI) or Colour Remapping Information (CRI), which records the difference between the SDR and HDR sources. Additionally, it stores the absolute luminance relationship of the Gainmap through something akin to static metadata.\nThe metadata includes: content max luminance gain (how much brighter the HDR is compared to the SDR), display max luminance gain (how much brighter the master HDR is compared to the SDR), the Gamma used for encoding the gainmap, and an optional offset.\nRegarding the content max and display max luminance gains, an example is the HDR limiter in ACR, which can limit the HDR headroom during post-production to ‚Äôn‚Äô stops. For example, if a three-stop limit is set, the maximum display gain during post-production is three stops, but the content may have a luminance gain exceeding three stops, which is simply clipped. The purpose of setting this display max luminance gain metadata is likely to restore the creative intent from the time of production.\nRegarding SDR‚Äôs Nominal Luminance Although rarely adhered to in practice, SDR actually has a specified white point luminance. For example, sRGB is 80 nits, and ITU-R BT.2035 specifies 100 nits.\nSDR content can be converted to absolute luminance based on this value, and then encoded using the inverse EOTF. More often, the nominal luminance used is 203 nits. This value originates from the recommendations for various luminance levels in ITU-R BT.2408, where diffuse white is 203 nits, but it also states that this diffuse white luminance should not be interpreted as the nominal luminance for SDR.\n","wordCount":"1400","inLanguage":"en","image":"https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp","datePublished":"2025-04-25T00:00:00+08:00","dateModified":"2025-12-21T00:41:45+08:00","author":{"@type":"Person","name":"Miaosen Zhou"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jackchou.top/en/posts/hdr-format-conversion/"},"publisher":{"@type":"Organization","name":"JacksBlog","logo":{"@type":"ImageObject","url":"https://jackchou.top/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jackchou.top/en/ accesskey=h title="JacksBlog (Alt + H)">JacksBlog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://jackchou.top/ title=‰∏≠Êñá aria-label=‰∏≠Êñá>‰∏≠Êñá</a></li></ul></div></div><ul id=menu><li><a href=https://jackchou.top/en/posts/ title="Posts üå≥"><span>Posts üå≥</span></a></li><li><a href=https://jackchou.top/en/photos/ title="Photos üì∑"><span>Photos üì∑</span></a></li><li><a href=https://jackchou.top/en/tags/ title="Tags üè∑Ô∏è"><span>Tags üè∑Ô∏è</span></a></li><li><a href=https://jackchou.top/en/about/ title="About üòº"><span>About üòº</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">HDR Image Format Conversion</h1><div class=post-meta><span title='2025-04-25 00:00:00 +0800 +0800'>2025.04.25</span>&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://jackchou.top/posts/hdr-format-conversion/>‰∏≠Êñá</a></li></ul></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#what-is-an-image aria-label="What is an &ldquo;Image&rdquo;?">What is an &ldquo;Image&rdquo;?</a><ul><li><a href=#encoding aria-label=Encoding>Encoding</a></li><li><a href=#additional-information aria-label="Additional Information">Additional Information</a></li></ul></li><li><a href=#display-referred-linear-light aria-label="Display-Referred Linear Light">Display-Referred Linear Light</a></li><li><a href=#pq-or-hlg-transfer-functions aria-label="PQ or HLG Transfer Functions">PQ or HLG Transfer Functions</a></li><li><a href=#gainmap aria-label=Gainmap>Gainmap</a></li><li><a href=#regarding-sdrs-nominal-luminance aria-label="Regarding SDR&rsquo;s Nominal Luminance">Regarding SDR&rsquo;s Nominal Luminance</a></li></ul></div></details></div><div class=post-content><h2 id=what-is-an-image>What is an &ldquo;Image&rdquo;?<a hidden class=anchor aria-hidden=true href=#what-is-an-image>#</a></h2><p>An image is essentially a &lsquo;matrix&rsquo; or an &lsquo;array&rsquo;. For example, the most common type of image might be an array with the shape (Height, Width, Channel), where the number at each position is quantised to eight bits, representing 256 different levels as an integer or floating-point number. The data stored here is generally called the code value or pixel value.</p><h3 id=encoding>Encoding<a hidden class=anchor aria-hidden=true href=#encoding>#</a></h3><p>Storing this array directly can result in a very large file, so compression methods, or &rsquo;encoding&rsquo;, are needed. Encoding methods are constantly evolving. For instance, there&rsquo;s JPG (JPEG) encoding, which uses techniques like chroma subsampling, Discrete Cosine Transform (DCT), and Huffman coding for compression. There&rsquo;s also the highly extensible TIFF (*.tif) format, which is a container format that can internally use various lossless/lossy encoding methods like ZIP, LZW, PackBits, and even JPEG. Then there are more advanced codecs like HEIC (HEIF/HEVC) and AV1, which feature flexible partitioning structures, multi-mode intra-prediction, and more advanced entropy coding, enabling very high encoding efficiency.</p><p>The encoding process may introduce some loss, which is known as lossy compression. The commonly used JPG standard includes both lossless and lossy modes, although the lossless mode is rarely used. Many later encoding methods also support lossless compression‚ÄîAV1 even offers a true lossless profile. As long as one is not deliberately pursuing extreme compression ratios, the quality loss from lossy compression is actually difficult to perceive.</p><p>Another difference between various encoding methods is the quantisation bit depth they allow. The JPG standard supports 8-bit and 12-bit quantisation, but the 12-bit mode is also uncommon. Newer formats often support higher bit depths; for example, HEIC and AVIF can handle 10-bit or even 12-bit, while a TIFF container can hold data with 16 or even 32 bits (floating-point) per channel. This is closely related to the requirements of HDR: to avoid visible banding over a wider brightness range, higher quantisation precision is needed.</p><h3 id=additional-information>Additional Information<a hidden class=anchor aria-hidden=true href=#additional-information>#</a></h3><p>A pile of numbers is meaningless on its own; we also need to know the space in which they are defined. At a minimum, the primaries, white point, and transfer function (i.e., the definition of the RGB space) must be specified.</p><p>This additional information tells the decoder and the system&rsquo;s colour management the specific meaning of these numbers. Without it, the data is usually treated as sRGB, and if the colour space does not match the actual data, major problems will occur.</p><p>After the decoding software extracts the pixel values and additional information, the colour management system converts these pixel values from a known colour space into driving values for the display, allowing them to be displayed correctly. Therefore, in theory, the code values can even be tristimulus values and linear, as long as there is corresponding additional information to define them. The images below are two PMCC colour charts tagged with the XYZ space and a linear transfer function. The pixel values in the images are directly the tristimulus values.</p><p><img alt="PMCC colour chart XYZ image under a D65 illuminant" loading=lazy src=https://img.jackchou.top/jack-img/2025/06/10c610e35151f2c92b4e3d81065f1406.avif></p><p>This is a tristimulus value image of a colour chart under a D65 illuminant, where values exceeding 1 have been clipped. This is actually an incorrect way of handling it; CIEXYZ in nclx requires an equal-energy white as the white point, and a Bradford CAT from an ICC profile could be used for the conversion.</p><p><img alt="PMCC colour chart XYZ image under a D65 illuminant, adapted to white point E" loading=lazy src=https://img.jackchou.top/jack-img/2025/06/d314f9020f60ce63115708c92aaa1711.avif></p><p>This is the image adapted to an equal-energy white point (done by directly replacing the white point). Because it is adapted to an equal-energy white, no values will exceed 1. When displayed, the system&rsquo;s colour management will perform chromatic adaptation to the display&rsquo;s white point, so its appearance should be close to the background in light mode. The page background in light mode has a code value of 245.</p><p>If you are using iOS or iPadOS, you may not be able to see these two images. Testing on other systems has shown they are generally visible.</p><p>Additional information can take many forms, such as an embedded ICC profile, XML statements or nclx data stored within the image file, or it can be stored in the EXIF data.</p><p>This step is the most critical part of achieving an HDR effect. Once the correct transfer function is specified, the decoder can convert the code values into what is known as &ldquo;HDR&rdquo; content, which can exceed the nominal luminance of SDR.</p><p>There is a rather special method for implementing HDR called a Gain Map. A single file stores two images (an SDR image and a gain map) along with some corresponding additional information (specific gain coefficients, etc.). The decoder can then compute a new HDR image from the two images. Therefore, the gain map could perhaps also be considered a form of additional information.</p><h2 id=display-referred-linear-light>Display-Referred Linear Light<a hidden class=anchor aria-hidden=true href=#display-referred-linear-light>#</a></h2><p>When performing image format conversions, all references to linear light space should be Display-Referred. This means calculating the luminance (either brightness or absolute tristimulus values) of the image on the display after it has been shown.</p><p>During decoding, the EOTF is used. During encoding, the inverse EOTF is used, not the OETF (there is a distinction for transfer functions like PQ).</p><h2 id=pq-or-hlg-transfer-functions>PQ or HLG Transfer Functions<a hidden class=anchor aria-hidden=true href=#pq-or-hlg-transfer-functions>#</a></h2><p>Similar to HDR video, changing the transfer function from Gamma or Rec. 709 to PQ or HLG can achieve the transition from SDR to HDR. For still images, the international standard ISO-22028-5 already exists.</p><p>Canon was the first to introduce 10-bit HEIC encoding in its mirrorless cameras, using PQ as the transfer function. Sony has HLG for still images. In recent versions of ACR, the AVIF and 16-bit TIF files produced when HDR output is enabled without maximum compatibility are PQ-encoded.</p><p>For this type of HDR image, one simply needs to apply the correct transfer function to convert to or from linear light.</p><h2 id=gainmap>Gainmap<a hidden class=anchor aria-hidden=true href=#gainmap>#</a></h2><p>A Gainmap is a method for implementing HDR specifically for still images. Its advantage is excellent compatibility, as it can store both SDR and HDR content simultaneously (rather than relying on dynamic metadata and a TMO) and is very friendly to display drivers.</p><p>JPG, JXL, and AVIF can all store this format. In particular, a JPG with a Gainmap is essentially two JPG files concatenated together. Image viewers that do not support this format will simply read the first file as a standard SDR image. When sending the original image on social media, the subsequent Gainmap can be preserved. Even if the app itself does not support it, saving it to another app may still reveal the HDR effect.</p><p>The first large-scale application of Gainmap was likely on the OPPO Find X6 Pro. Later, Google promoted the UltraHDR format. The ISO is currently developing the ISO-21496-1 standard, and UltraHDR version 1.1 is already compatible with this standard.</p><p>A Gainmap can be written for luminance only or for all three channels. The &ldquo;ProXDR&rdquo; in the recently released OPPO Find X8 Ultra refers to a three-channel Gainmap.</p><p>A Gainmap can be understood as a form of Supplemental Enhancement Information (SEI) or Colour Remapping Information (CRI), which records the difference between the SDR and HDR sources. Additionally, it stores the absolute luminance relationship of the Gainmap through something akin to static metadata.</p><p>The metadata includes: content max luminance gain (how much brighter the HDR is compared to the SDR), display max luminance gain (how much brighter the master HDR is compared to the SDR), the Gamma used for encoding the gainmap, and an optional offset.</p><p>Regarding the content max and display max luminance gains, an example is the HDR limiter in ACR, which can limit the HDR headroom during post-production to &rsquo;n&rsquo; stops. For example, if a three-stop limit is set, the maximum display gain during post-production is three stops, but the content may have a luminance gain exceeding three stops, which is simply clipped. The purpose of setting this display max luminance gain metadata is likely to restore the creative intent from the time of production.</p><h2 id=regarding-sdrs-nominal-luminance>Regarding SDR&rsquo;s Nominal Luminance<a hidden class=anchor aria-hidden=true href=#regarding-sdrs-nominal-luminance>#</a></h2><p>Although rarely adhered to in practice, SDR actually has a specified white point luminance. For example, sRGB is 80 nits, and ITU-R BT.2035 specifies 100 nits.</p><p>SDR content can be converted to absolute luminance based on this value, and then encoded using the inverse EOTF. More often, the nominal luminance used is 203 nits. This value originates from the recommendations for various luminance levels in ITU-R BT.2408, where diffuse white is 203 nits, but it also states that this diffuse white luminance should not be interpreted as the nominal luminance for SDR.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://jackchou.top/en/tags/colour/>Colour</a></li></ul><nav class=paginav><a class=prev href=https://jackchou.top/en/posts/icam06-survey/><span class=title>¬´ Prev</span><br><span>iCAM06: Colour Appearance Model in Image Processing</span>
</a><a class=next href=https://jackchou.top/en/posts/colour-checker-for-jpg/><span class=title>Next ¬ª</span><br><span>Not Just Colour Difference: Evaluate Image with Colour Chart</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://jackchou.top/en/>JacksBlog</a></span> ¬∑
my friends&rsquo; websites: <a href=https://zhxwu.com/>zhxwu.com</a>, <a href=https://ylqian.com/>ylqian.com</a> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script defer crossorigin=anonymous src=/js/site.min.a576538c52b362e170acc02d53f5ce6045117863354954a8f91f10c7217d94ab.js integrity="sha256-pXZTjFKzYuFwrMAtU/XOYEUReGM1SVSo+R8QxyF9lKs="></script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>