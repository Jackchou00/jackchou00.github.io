<!doctype html><html lang=zh-CN dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>(Temp) CIC 33 Paper Demonstration | JacksBlog</title>
<meta name=keywords content><meta name=description content="Visual Matching Experiment and Tone Mapping based on CAM16-UCS"><meta name=author content="Miaosen Zhou, Ming Ronnier Luo"><link rel=canonical href=https://jackchou.top/posts/cic33-paper/><link crossorigin=anonymous href=/assets/css/stylesheet.07f6d388270a92c62af4a6f9c96374ae63b804ca5e22b2e4f3d2e446ce05d1b5.css integrity="sha256-B/bTiCcKksYq9Kb5yWN0rmO4BMpeIrLk89LkRs4F0bU=" rel="preload stylesheet" as=style><link rel=icon href=https://jackchou.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://jackchou.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://jackchou.top/favicon-32x32.png><link rel=apple-touch-icon href=https://jackchou.top/apple-touch-icon.png><link rel=mask-icon href=https://jackchou.top/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-cn href=https://jackchou.top/posts/cic33-paper/><link rel=alternate hreflang=en href=https://jackchou.top/en/posts/cic33-paper/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://cdn.jsdelivr.net><meta property="og:url" content="https://jackchou.top/posts/cic33-paper/"><meta property="og:site_name" content="JacksBlog"><meta property="og:title" content="(Temp) CIC 33 Paper Demonstration"><meta property="og:description" content="Visual Matching Experiment and Tone Mapping based on CAM16-UCS"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-10-31T00:00:00+08:00"><meta property="article:modified_time" content="2025-10-31T10:25:06+08:00"><meta property="og:image" content="https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp"><meta name=twitter:title content="(Temp) CIC 33 Paper Demonstration"><meta name=twitter:description content="Visual Matching Experiment and Tone Mapping based on CAM16-UCS"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"æ–‡ç«  ğŸŒ³","item":"https://jackchou.top/posts/"},{"@type":"ListItem","position":2,"name":"(Temp) CIC 33 Paper Demonstration","item":"https://jackchou.top/posts/cic33-paper/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"(Temp) CIC 33 Paper Demonstration","name":"(Temp) CIC 33 Paper Demonstration","description":"Visual Matching Experiment and Tone Mapping based on CAM16-UCS","keywords":[],"articleBody":"Here is a temporary page for CIC presentation usage, after the conference, will be re-organized as a paper reivew.\nAll images below are encoded as ISO 22028-5 format using PQ EOTF-inverse curve, should be HDR if you are using MacBook Pro with MiniLED display and Chrome or Safari (macOS Tahoe).\nInput Image, only basic colour conversion has been applied, absolute luminance of the image has been scaled down for less clipping.\nInput Adopted White, which is a blur version of the image above, blur amount here is 3 (a relative number, larger means less blur).\nOutput Adopted White, which is a blur version of the input image, blur amount here is 2 (means more blur, already close to flat). This represents how size will affect, if the display size is larger, more local adaptation should be considered.\nOutput Image, after forward transformation and adjustment in CAM16-UCS and reverse transformation using adopted white above. This should be close to observerâ€™s result.\nHere is the ground-truth from observers and a comparison.\nMy pleasure to have you here! Please contact me using e-mail if you have any questions.\n","wordCount":"185","inLanguage":"zh-cn","image":"https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp","datePublished":"2025-10-31T00:00:00+08:00","dateModified":"2025-10-31T10:25:06+08:00","author":[{"@type":"Person","name":"Miaosen Zhou"},{"@type":"Person","name":"Ming Ronnier Luo"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://jackchou.top/posts/cic33-paper/"},"publisher":{"@type":"Organization","name":"JacksBlog","logo":{"@type":"ImageObject","url":"https://jackchou.top/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jackchou.top/ accesskey=h title="JacksBlog (Alt + H)">JacksBlog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://jackchou.top/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://jackchou.top/posts/ title="æ–‡ç«  ğŸŒ³"><span>æ–‡ç«  ğŸŒ³</span></a></li><li><a href=https://jackchou.top/photos/ title="ç…§ç‰‡ ğŸ“·"><span>ç…§ç‰‡ ğŸ“·</span></a></li><li><a href=https://jackchou.top/tags/ title="æ ‡ç­¾ ğŸ·ï¸"><span>æ ‡ç­¾ ğŸ·ï¸</span></a></li><li><a href=https://jackchou.top/about/ title="å…³äº ğŸ˜¼"><span>å…³äº ğŸ˜¼</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">(Temp) CIC 33 Paper Demonstration</h1><div class=post-meta><span title='2025-10-31 00:00:00 +0800 +0800'>2025.10.31</span>&nbsp;|&nbsp;æ›´å¤šè¯­è¨€:<ul class=i18n_list><li><a href=https://jackchou.top/en/posts/cic33-paper/>English</a></li></ul></div></header><div class=post-content><p>Here is a temporary page for CIC presentation usage, after the conference, will be re-organized as a paper reivew.</p><p>All images below are encoded as ISO 22028-5 format using PQ EOTF-inverse curve, should be HDR if you are using MacBook Pro with MiniLED display and Chrome or Safari (macOS Tahoe).</p><p>Input Image, only basic colour conversion has been applied, absolute luminance of the image has been scaled down for less clipping.</p><p><img alt=Linear loading=lazy src=https://img.jackchou.top/jack-img/cic/a851464b5cca85c7e00e5fb1876e9b8e.avif></p><p>Input Adopted White, which is a blur version of the image above, blur amount here is 3 (a relative number, larger means less blur).</p><p><img alt="Input White" loading=lazy src=https://img.jackchou.top/jack-img/cic/ad743bc551557f5ebe648f362384d07d.avif></p><p>Output Adopted White, which is a blur version of the input image, blur amount here is 2 (means more blur, already close to flat). This represents how size will affect, if the display size is larger, more local adaptation should be considered.</p><p><img alt="Output White" loading=lazy src=https://img.jackchou.top/jack-img/cic/b93cd8c2c1f5a5ee51f525427358ee70.avif></p><p>Output Image, after forward transformation and adjustment in CAM16-UCS and reverse transformation using adopted white above. This should be close to observer&rsquo;s result.</p><p><img alt=Output loading=lazy src=https://img.jackchou.top/jack-img/cic/b4e5412026410876e179179e5322abf5.avif></p><p>Here is the ground-truth from observers and a comparison.</p><p><img alt="Observer GT" loading=lazy src=https://img.jackchou.top/jack-img/cic/d850958992b501cfbaf1b14acb00d099.avif></p><p><img alt=Comparison loading=lazy src=https://img.jackchou.top/jack-img/cic/de11839bdfc843246642122139194a2a.avif></p><p>My pleasure to have you here! Please contact me using e-mail if you have any questions.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://jackchou.top/posts/imagecodecs-avif/><span class=title>Â« ä¸Šä¸€ç¯‡</span><br><span>Python AVIF ç¼–ç æ–°é€‰æ‹©ï¼šImageCodecs</span>
</a><a class=next href=https://jackchou.top/photos/hongkong-2025/><span class=title>ä¸‹ä¸€ç¯‡ Â»</span><br><span>é¦™æ¸¯</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://jackchou.top/>JacksBlog</a></span> Â·
my friends&rsquo; websites: <a href=https://zhxwu.com/>zhxwu.com</a>, <a href=https://ylqian.com/>ylqian.com</a> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script defer crossorigin=anonymous src=/js/site.min.a576538c52b362e170acc02d53f5ce6045117863354954a8f91f10c7217d94ab.js integrity="sha256-pXZTjFKzYuFwrMAtU/XOYEUReGM1SVSo+R8QxyF9lKs="></script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="æ‹·è´";function s(){t.innerHTML="å·²æ‹·è´",setTimeout(()=>{t.innerHTML="æ‹·è´"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>