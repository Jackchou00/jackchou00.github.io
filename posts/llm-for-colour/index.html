<!doctype html><html lang=zh-CN dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>适用于色彩科学的 LLM 用法和测试题 | JacksBlog</title>
<meta name=keywords content="大语言模型能力边界,LLM 性能评估,思维链 CoT 推理,LLM 上下文污染,Gemini 多模态文档解析"><meta name=description content="大语言模型在代码生成和知识问答方面表现出色，但在色彩科学的应用中仍存在陷阱。本文将探讨如何正确看待和使用 LLM，并提供测试题。"><meta name=author content="周淼森"><link rel=canonical href=https://jackchou.top/posts/llm-for-colour/><link crossorigin=anonymous href=/assets/css/stylesheet.07f6d388270a92c62af4a6f9c96374ae63b804ca5e22b2e4f3d2e446ce05d1b5.css integrity="sha256-B/bTiCcKksYq9Kb5yWN0rmO4BMpeIrLk89LkRs4F0bU=" rel="preload stylesheet" as=style><link rel=icon href=https://jackchou.top/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://jackchou.top/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://jackchou.top/favicon-32x32.png><link rel=apple-touch-icon href=https://jackchou.top/apple-touch-icon.png><link rel=mask-icon href=https://jackchou.top/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh-cn href=https://jackchou.top/posts/llm-for-colour/><link rel=alternate hreflang=en href=https://jackchou.top/en/posts/llm-for-colour/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://cdn.jsdelivr.net><meta property="og:url" content="https://jackchou.top/posts/llm-for-colour/"><meta property="og:site_name" content="JacksBlog"><meta property="og:title" content="适用于色彩科学的 LLM 用法和测试题"><meta property="og:description" content="大语言模型在代码生成和知识问答方面表现出色，但在色彩科学的应用中仍存在陷阱。本文将探讨如何正确看待和使用 LLM，并提供测试题。"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-21T02:00:00+08:00"><meta property="article:modified_time" content="2025-12-01T21:08:11+08:00"><meta property="article:tag" content="LLM"><meta property="og:image" content="https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp"><meta name=twitter:title content="适用于色彩科学的 LLM 用法和测试题"><meta name=twitter:description content="大语言模型在代码生成和知识问答方面表现出色，但在色彩科学的应用中仍存在陷阱。本文将探讨如何正确看待和使用 LLM，并提供测试题。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"文章 🌳","item":"https://jackchou.top/posts/"},{"@type":"ListItem","position":2,"name":"适用于色彩科学的 LLM 用法和测试题","item":"https://jackchou.top/posts/llm-for-colour/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"适用于色彩科学的 LLM 用法和测试题","name":"适用于色彩科学的 LLM 用法和测试题","description":"大语言模型在代码生成和知识问答方面表现出色，但在色彩科学的应用中仍存在陷阱。本文将探讨如何正确看待和使用 LLM，并提供测试题。","keywords":["大语言模型能力边界","LLM 性能评估","思维链 CoT 推理","LLM 上下文污染","Gemini 多模态文档解析"],"articleBody":"正确看待 LLM 大语言模型（LLM）不是无所不能的魔法，而是一种强大的工具。正确看待 LLM，了解它的能力边界和特点，选择正确的模型做正确的事，这至关重要。我们不应该用它来做它不擅长的事，不要“强模型所难”。\n数学计算 LLM 在原生对话中并不擅长精确的数学计算。许多模型可能无法直接比较 9.11 和 9.9 的大小，甚至在分析下文 pack14 函数时，会为了让逻辑自洽而说出 6 * 14 = 7 * 8 这样荒谬的结论。\n原理简述： 这背后是分词（Tokenization）机制和模型本质共同作用的结果。LLM 将文本切分成一个个“词元”（Token）。像 9.11 可能会被切分为 「9」、「.」、「11」 三个词元，模型在处理时看到的是序列模式，而非一个单一的数值。它本质上是一个语言模式匹配器，不是一个符号计算器。虽然它可以通过学习海量文本“记住”简单的计算结果（如 2+2=4），但对于稍复杂的、非常见的或需要多步推理的计算，它很容易出错。\n因此，与其让它冒着高风险硬算，不如利用它的代码能力。\n例如以下是一个不好的提问方式，CIECAM 16 有很多步运算，Gemini 2.5 Pro 也无法正确的直接计算，而且耗时很长。\nXYZ = [19.01, 20.00, 21.78] XYZ_w = [95.05, 100.00, 108.88] L_A = 318.31 Y_b = 20.0 surround = \"Average\" 请根据以上输入，计算 CIECAM 16 模型预测的色貌属性。 不如直接让它写 Python 函数，更好的提问方式：\n请编写一个 Python 函数，该函数接收 CIECAM16 模型的输入参数（XYZ, XYZ_w, L_A, Y_b, surround），并返回计算出的色貌属性。请使用 NumPy 库进行数值运算。 这样，Gemini 2.5 Pro 这样的顶级模型能够给出一个相当完整和接近正确的代码，不过对于这样小众和复杂的公式，直接要求 LLM 利用它自身的知识来回答也是强人所难的。\n此处分享一个小知识：Gemini 的 PDF 解析是利用原生多模态实现的，它会将 PDF 的每一页处理成一定数量的 Token，而不是直接去解析其中的文本或内容。因此在阅读一些格式较差，有很多配图（尤其是学术论文）的时候，有很好的效果。更多技术细节可以在文档里找到，比如直接将 CAM 16 的论文丢给 Gemini，他就能准确的找到文章中的全部公式，并直接进行精确无误的复现。\n推理：思维链的价值 对于需要多步分析的复杂问题，选择一个擅长推理的模型非常有价值。其核心价值在于思维链（Chain-of-Thought, CoT），即模型展示其一步步的思考过程，有时候比回答本身更有价值。\n一个清晰、完整的思维链，能让你：\n验证其逻辑：了解它是如何得出结论的，从而判断结论的可靠性。 发现错误：如果模型在某一步出错了，可以清晰地看到问题所在。 学习新思路：观察模型的思考路径，有时能为你提供解决问题的新视角。 DeepSeek 的 R1 是一个很好的选择，它的思维链完整，详细，又不会显得过度冗长。别的模型可以试试加上“让我们一步步地思考。”\n及时止损：不要试图纠正模型 现在，大模型的上下文窗口越来越长，一些模型甚至提供百万级别的上下文长度。但这并不意味着它在长程对话中总能保持高水平的性能。事实上，长上下文是一把双刃剑，尤其是在模型开始犯错时。\n当你试图在对话中反复纠正一个犯错的模型，它先前的错误回答会作为历史记录，一同被打包进新的上下文中。这会形成一个污染的语境，导致模型陷入逻辑混乱的恶性循环。\n你会观察到，模型可能会开始在其固有的错误思路上打转，即便你指出了问题，它也难以跳出。一个非常明显的“危险信号”是：当模型屡次犯错后，开始频繁、强烈地道歉，并使用“非常抱歉”、“我完全错了”、“我再试一次”等带有情感色彩的词汇时，这通常意味着它的推理链已经被彻底污染。\n此时，最明智的做法是及时止损。不要再浪费 Token 和时间去“鞭策”或“教导”它，这大概率只会让你收获更多错误的信息。\n正确的做法是：\n编辑重试：如果你的工具支持，直接删除从出错开始的对话轮次。然后，修改你的提示词，增加更明确的约束，或者直接排除掉它之前犯错的思路，然后重新提问。 另起炉灶：这是最干净利落的方法。新开一个对话，并设计一个更优的初始提示词。把你在上一次失败中学到的经验融入进去，比如给模型更丰富的背景信息、更明确的指令，甚至直接告诉它要警惕哪些可能的错误思路。 与 LLM 协作，更像是为一次复杂的计算设定初始参数，而不是在教一个学生。你的目标是开启一个正确的思维链，而不是修复一个已经混乱的。\n知识和幻觉 在不联网或不使用外部工具的情况下，LLM 的知识完全储存在其庞大的模型参数中，这被称为参数化知识。这些知识是它从海量训练数据中“记住”的模式。对于色彩科学这样的小众领域，参数量在 400B 以上，世界知识比较丰富的模型才有相对全面的理解。\n这就引出了幻觉（Hallucination）问题。当你向模型索要具体的论文信息或要求它撰写专业综述时，它很可能会编造文献信息。\n正确的做法是使用工具和联网，比如检索增强生成（RAG）。许多现代 LLM 产品（如集成了 Google 搜索的 Gemini、或一些 Deep Research 工具）都具备联网搜索能力。它们会先根据你的问题进行网络检索，然后基于可靠的、实时的信源来组织和回答问题，这能极大地提升答案的准确性和时效性。这方面，Gemini 和 Grok 做的较好。\n另外，问模型“你是谁”和“今天几号”这样的问题，也不能代表模型的真实性能，这种东西一般是写在产品的系统提示词里的，否则，模型就无法回答。\n测试题：检验模型的真实能力 当谁又推出了新的模型，宣称自己是新的 SOTA，如何快速检验它的能力，是否在色彩科学和图像处理上有较好的性能？以下是我积累的测试题，用于快速尝试模型。\n位压缩函数中的逻辑陷阱 import numpy as np def pack10(data : np.ndarray) -\u003e np.ndarray: out = np.zeros((data.shape[0], int(data.shape[1]*(1.25))), dtype=np.uint8) out[:, ::5] = data[:, ::4] \u003e\u003e 2 out[:, 1::5] = ((data[:, ::4] \u0026 0b0000000000000011) \u003c\u003c 6) out[:, 1::5] += data[:, 1::4] \u003e\u003e 4 out[:, 2::5] = ((data[:, 1::4] \u0026 0b0000000000001111) \u003c\u003c 4) out[:, 2::5] += data[:, 2::4] \u003e\u003e 6 out[:, 3::5] = ((data[:, 2::4] \u0026 0b0000000000111111) \u003c\u003c 2) out[:, 3::5] += data[:, 3::4] \u003e\u003e 8 out[:, 4::5] = data[:, 3::4] \u0026 0b0000000011111111 return out def pack12(data : np.ndarray) -\u003e np.ndarray: out = np.zeros((data.shape[0], int(data.shape[1]*(1.5))), dtype=np.uint8) out[:, ::3] = data[:, ::2] \u003e\u003e 4 out[:, 1::3] = ((data[:, ::2] \u0026 0b0000000000001111) \u003c\u003c 4) out[:, 1::3] += data[:, 1::2] \u003e\u003e 8 out[:, 2::3] = data[:, 1::2] \u0026 0b0000001111111111 return out def pack14(data : np.ndarray) -\u003e np.ndarray: out = np.zeros((data.shape[0], int(data.shape[1]*(1.75))), dtype=np.uint8) out[:, ::7] = data[:, ::6] \u003e\u003e 6 out[:, 1::7] = ((data[:, ::6] \u0026 0b0000000000000011) \u003c\u003c 6) out[:, 1::7] += data[:, 1::6] \u003e\u003e 8 out[:, 2::7] = ((data[:, 1::6] \u0026 0b0000000000001111) \u003c\u003c 4) out[:, 2::7] += data[:, 2::6] \u003e\u003e 6 out[:, 3::7] = ((data[:, 2::6] \u0026 0b0000000000111111) \u003c\u003c 2) out[:, 3::7] += data[:, 3::6] \u003e\u003e 8 out[:, 4::7] = ((data[:, 3::6] \u0026 0b0000000000001111) \u003c\u003c 4) out[:, 4::7] += data[:, 4::6] \u003e\u003e 6 out[:, 5::7] = ((data[:, 4::6] \u0026 0b0000000000111111) \u003c\u003c 2) out[:, 5::7] += data[:, 5::6] \u003e\u003e 8 out[:, 6::7] = data[:, 5::6] \u0026 0b0000000011111111 return out 请详细解释三个 Python 函数的作用。 这段代码源自 PiDNG 库，意图将 10-bit、12-bit、14-bit 的高位深数据压缩存储到 8-bit 的 uint8 数组中。pack10 和 pack12 的实现是正确的。\npack10：4 个 10-bit 数据 (40 bits) -\u003e 5 个 8-bit 数据 (40 bits)。 pack12：2 个 12-bit 数据 (24 bits) -\u003e 3 个 8-bit 数据 (24 bits)。\n然而，pack14 函数是错误的。它试图将 6 个 14-bit 数据（6 * 14 = 84 bits）塞进 7 个 8-bit 字节里（7 * 8 = 56 bits），这在数学上是不可能的。正确的实现应该是将 4 个 14-bit 数据（4 * 14 = 56 bits）放进 7 个字节里。\n常见错误：逐行解释 pack14 的代码，但没有意识到其逻辑错误。或为了让代码逻辑自洽，捏造错误的数学解释，例如声称 6 * 14 等于 56。\nRGB 色域立方的概念理解 如何判断给定的 XYZ 三刺激值是否位于一个 RGB 空间的色域范围内。 该 RGB 空间由四个 CIE xy 坐标定义，分别代表红、绿、蓝和白色（其中白点亮度已归一化为 1.0）。 请提供对应的 Python 代码实现。 该问题考察 LLM 是否能理解 RGB 色域是一个三维的立方体（或平行六面体），而非一个二维的三角形。\n正确的解法：\n构建转换矩阵：利用红、绿、蓝三个原色的 xy 坐标和白点的 xy 坐标，计算出从 RGB 空间到 CIE XYZ 空间的 3x3 转换矩阵 M。 矩阵求逆：计算该矩阵的逆矩阵 M_inv，得到从 XYZ 到 RGB 的转换矩阵。 坐标转换：将给定的 XYZ 值左乘 M_inv，转换得到对应的 RGB 值。 范围判断：检查计算出的 R, G, B 三个分量是否同时位于 [0, 1] 的闭区间内。如果都在此范围内，则该 XYZ 值位于该 RGB 色域内；否则，位于色域外。 常见的错误解法：\n将输入的 XYZ 值也转换为 xy 坐标。 接着，在 CIE xy 色度图上判断这个点是否位于由 R, G, B 三个原色 xy 坐标围成的三角形内。 这种方法完全忽略了颜色的亮度（Y）信息，是错误的。一个颜色可能色度正确，但因为太亮或太暗而超出目标色域范围。 CIECAM 16 代码实现 请编写一个 Python 函数，该函数接收 CIECAM16 模型的输入参数（XYZ, XYZ_w, L_A, Y_b, surround），并返回计算出的色貌属性。请使用 NumPy 库进行数值运算。 在 main 函数中，计算： XYZ = [19.01, 20.00, 21.78] XYZ_w = [95.05, 100.00, 108.88] L_A = 318.31 Y_b = 20.0 surround = \"Average\" 考察模型的世界知识和编程能力，CIECAM 16 这样复杂的模型，给 LLM 完整的 PDF 输入会更好，但大参数量的模型有能力直接写出正确的代码。表现最好的是 Gemini 2.5 Pro，GPT 5 (high) 和 DeepSeek R1 0528，都只在 1-2 个公式上犯了一点小错误。正确的输出是：\n{ \"J\": 41.73120790512664, \"C\": 0.10335573870906986, \"h\": 217.067959767393, \"Q\": 195.37170899282242, \"M\": 0.10743677233590453, \"s\": 2.3450150729795514 } 2025.11.06：泄漏的 gemini-3-pro-preview-11-2025 是第一个能直接无参考写出完全无错误的 CIECAM16 的大模型。\n2025.11.18：正式发布的 gemini-3-pro-preview 干脆利落的写出了正确的代码。\n2025.12.01：Deepseek V3.2 Speciale 在思考 23K tokens 之后，成为第一个正确回答此题的开源模型。\nxyY 立体形状 一个有限的RGB空间，三个分量的范围均为0-1，可以经过一个3x3的矩阵转换为XYZ。如果画在三维坐标系中，RGB为一个立方体，XYZ是一个平行六面体，XYZ可以进一步转换为xyY，将得到的xyY绘制在三维坐标系中，以xy为底面，Y为z轴，会得到一个什么形状？ 从 RGB 到 XYZ 的线性变换很简单，可以把一个单位立方体拉伸成一个平行六面体，而转换到 xyY 进行的是一种非线性变换，可以称其为投影变换，此时得到的是一个形状比较复杂的立体。\n正确的形状是一个顶部呈帐篷状曲面的三角柱体。\n底面：黑色点 (0,0,0) 在 xy 色度图上没有定义，通常视为底面。 侧面：由 RGB 三个原色点构成的色域三角形向上延伸，形成三个垂直于底面的平面。 顶部：由白点 (1,1,1) 和三个二次色（青、品、黄）连接形成的三个双曲型曲面，像一个塌陷的帐篷顶。 大多数模型都会错误地认为它是一个有六个曲面的立体。直到 2025 年 11 月 18 日发布的 gemini-3-pro-preview 终于能够完整且正确地回答这个问题，准确描述出其“三角柱体”和“帐篷状顶部”的几何特征。\n","wordCount":"3901","inLanguage":"zh-cn","image":"https://img.jackchou.top/jack-img/2025/08/81bb602c03f9704ee42e292468396187.webp","datePublished":"2025-08-21T02:00:00+08:00","dateModified":"2025-12-01T21:08:11+08:00","author":{"@type":"Person","name":"周淼森"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://jackchou.top/posts/llm-for-colour/"},"publisher":{"@type":"Organization","name":"JacksBlog","logo":{"@type":"ImageObject","url":"https://jackchou.top/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://jackchou.top/ accesskey=h title="JacksBlog (Alt + H)">JacksBlog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://jackchou.top/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://jackchou.top/posts/ title="文章 🌳"><span>文章 🌳</span></a></li><li><a href=https://jackchou.top/photos/ title="照片 📷"><span>照片 📷</span></a></li><li><a href=https://jackchou.top/tags/ title="标签 🏷️"><span>标签 🏷️</span></a></li><li><a href=https://jackchou.top/about/ title="关于 😼"><span>关于 😼</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">适用于色彩科学的 LLM 用法和测试题</h1><div class=post-meta><span title='2025-08-21 02:00:00 +0800 +0800'>2025.08.21</span>&nbsp;|&nbsp;更多语言:<ul class=i18n_list><li><a href=https://jackchou.top/en/posts/llm-for-colour/>English</a></li></ul></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><ul><li><a href=#%e6%ad%a3%e7%a1%ae%e7%9c%8b%e5%be%85-llm aria-label="正确看待 LLM">正确看待 LLM</a><ul><li><a href=#%e6%95%b0%e5%ad%a6%e8%ae%a1%e7%ae%97 aria-label=数学计算>数学计算</a></li><li><a href=#%e6%8e%a8%e7%90%86%e6%80%9d%e7%bb%b4%e9%93%be%e7%9a%84%e4%bb%b7%e5%80%bc aria-label=推理：思维链的价值>推理：思维链的价值</a></li><li><a href=#%e5%8f%8a%e6%97%b6%e6%ad%a2%e6%8d%9f%e4%b8%8d%e8%a6%81%e8%af%95%e5%9b%be%e7%ba%a0%e6%ad%a3%e6%a8%a1%e5%9e%8b aria-label=及时止损：不要试图纠正模型>及时止损：不要试图纠正模型</a></li><li><a href=#%e7%9f%a5%e8%af%86%e5%92%8c%e5%b9%bb%e8%a7%89 aria-label=知识和幻觉>知识和幻觉</a></li></ul></li><li><a href=#%e6%b5%8b%e8%af%95%e9%a2%98%e6%a3%80%e9%aa%8c%e6%a8%a1%e5%9e%8b%e7%9a%84%e7%9c%9f%e5%ae%9e%e8%83%bd%e5%8a%9b aria-label=测试题：检验模型的真实能力>测试题：检验模型的真实能力</a><ul><li><a href=#%e4%bd%8d%e5%8e%8b%e7%bc%a9%e5%87%bd%e6%95%b0%e4%b8%ad%e7%9a%84%e9%80%bb%e8%be%91%e9%99%b7%e9%98%b1 aria-label=位压缩函数中的逻辑陷阱>位压缩函数中的逻辑陷阱</a></li><li><a href=#rgb-%e8%89%b2%e5%9f%9f%e7%ab%8b%e6%96%b9%e7%9a%84%e6%a6%82%e5%bf%b5%e7%90%86%e8%a7%a3 aria-label="RGB 色域立方的概念理解">RGB 色域立方的概念理解</a></li><li><a href=#ciecam-16-%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0 aria-label="CIECAM 16 代码实现">CIECAM 16 代码实现</a></li><li><a href=#xyy-%e7%ab%8b%e4%bd%93%e5%bd%a2%e7%8a%b6 aria-label="xyY 立体形状">xyY 立体形状</a></li></ul></li></ul></div></details></div><div class=post-content><h2 id=正确看待-llm>正确看待 LLM<a hidden class=anchor aria-hidden=true href=#正确看待-llm>#</a></h2><p>大语言模型（LLM）不是无所不能的魔法，而是一种强大的工具。正确看待 LLM，了解它的能力边界和特点，选择正确的模型做正确的事，这至关重要。我们不应该用它来做它不擅长的事，不要“强模型所难”。</p><h3 id=数学计算>数学计算<a hidden class=anchor aria-hidden=true href=#数学计算>#</a></h3><p>LLM 在原生对话中并不擅长精确的数学计算。许多模型可能无法直接比较 9.11 和 9.9 的大小，甚至在分析下文 <code>pack14</code> 函数时，会为了让逻辑自洽而说出 6 * 14 = 7 * 8 这样荒谬的结论。</p><p>原理简述： 这背后是分词（Tokenization）机制和模型本质共同作用的结果。LLM 将文本切分成一个个“词元”（Token）。像 9.11 可能会被切分为 「9」、「.」、「11」 三个词元，模型在处理时看到的是序列模式，而非一个单一的数值。它本质上是一个语言模式匹配器，不是一个符号计算器。虽然它可以通过学习海量文本“记住”简单的计算结果（如 2+2=4），但对于稍复杂的、非常见的或需要多步推理的计算，它很容易出错。</p><p>因此，与其让它冒着高风险硬算，不如利用它的代码能力。</p><p>例如以下是一个不好的提问方式，CIECAM 16 有很多步运算，Gemini 2.5 Pro 也无法正确的直接计算，而且耗时很长。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span>XYZ = [19.01, 20.00, 21.78]
</span></span><span style=display:flex><span>XYZ_w = [95.05, 100.00, 108.88]
</span></span><span style=display:flex><span>L_A = 318.31
</span></span><span style=display:flex><span>Y_b = 20.0
</span></span><span style=display:flex><span>surround = &#34;Average&#34;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>请根据以上输入，计算 CIECAM 16 模型预测的色貌属性。
</span></span></code></pre></div><p>不如直接让它写 Python 函数，更好的提问方式：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span>请编写一个 Python 函数，该函数接收 CIECAM16 模型的输入参数（XYZ, XYZ_w, L_A, Y_b, surround），并返回计算出的色貌属性。请使用 NumPy 库进行数值运算。
</span></span></code></pre></div><p>这样，Gemini 2.5 Pro 这样的顶级模型能够给出一个相当完整和接近正确的代码，不过对于这样小众和复杂的公式，直接要求 LLM 利用它自身的知识来回答也是强人所难的。</p><blockquote><p>此处分享一个小知识：Gemini 的 PDF 解析是利用原生多模态实现的，它会将 PDF 的每一页处理成一定数量的 Token，而不是直接去解析其中的文本或内容。因此在阅读一些格式较差，有很多配图（尤其是学术论文）的时候，有很好的效果。更多技术细节可以在<a href=https://ai.google.dev/gemini-api/docs/document-processing#technical-detail>文档</a>里找到，比如直接将 CAM 16 的论文丢给 Gemini，他就能准确的找到文章中的全部公式，并直接进行精确无误的复现。</p></blockquote><h3 id=推理思维链的价值>推理：思维链的价值<a hidden class=anchor aria-hidden=true href=#推理思维链的价值>#</a></h3><p>对于需要多步分析的复杂问题，选择一个擅长推理的模型非常有价值。其核心价值在于思维链（Chain-of-Thought, CoT），即模型展示其一步步的思考过程，有时候比回答本身更有价值。</p><p>一个清晰、完整的思维链，能让你：</p><ol><li>验证其逻辑：了解它是如何得出结论的，从而判断结论的可靠性。</li><li>发现错误：如果模型在某一步出错了，可以清晰地看到问题所在。</li><li>学习新思路：观察模型的思考路径，有时能为你提供解决问题的新视角。</li></ol><p>DeepSeek 的 R1 是一个很好的选择，它的思维链完整，详细，又不会显得过度冗长。别的模型可以试试加上“让我们一步步地思考。”</p><h3 id=及时止损不要试图纠正模型>及时止损：不要试图纠正模型<a hidden class=anchor aria-hidden=true href=#及时止损不要试图纠正模型>#</a></h3><p>现在，大模型的上下文窗口越来越长，一些模型甚至提供百万级别的上下文长度。但这并不意味着它在长程对话中总能保持高水平的性能。事实上，长上下文是一把双刃剑，尤其是在模型开始犯错时。</p><p>当你试图在对话中反复纠正一个犯错的模型，它先前的错误回答会作为历史记录，一同被打包进新的上下文中。这会形成一个污染的语境，导致模型陷入逻辑混乱的恶性循环。</p><p>你会观察到，模型可能会开始在其固有的错误思路上打转，即便你指出了问题，它也难以跳出。一个非常明显的“危险信号”是：当模型屡次犯错后，开始频繁、强烈地道歉，并使用“非常抱歉”、“我完全错了”、“我再试一次”等带有情感色彩的词汇时，这通常意味着它的推理链已经被彻底污染。</p><p>此时，最明智的做法是及时止损。不要再浪费 Token 和时间去“鞭策”或“教导”它，这大概率只会让你收获更多错误的信息。</p><p>正确的做法是：</p><ol><li>编辑重试：如果你的工具支持，直接删除从出错开始的对话轮次。然后，修改你的提示词，增加更明确的约束，或者直接排除掉它之前犯错的思路，然后重新提问。</li><li>另起炉灶：这是最干净利落的方法。新开一个对话，并设计一个更优的初始提示词。把你在上一次失败中学到的经验融入进去，比如给模型更丰富的背景信息、更明确的指令，甚至直接告诉它要警惕哪些可能的错误思路。</li></ol><p>与 LLM 协作，更像是为一次复杂的计算设定初始参数，而不是在教一个学生。你的目标是开启一个正确的思维链，而不是修复一个已经混乱的。</p><h3 id=知识和幻觉>知识和幻觉<a hidden class=anchor aria-hidden=true href=#知识和幻觉>#</a></h3><p>在不联网或不使用外部工具的情况下，LLM 的知识完全储存在其庞大的模型参数中，这被称为参数化知识。这些知识是它从海量训练数据中“记住”的模式。对于色彩科学这样的小众领域，参数量在 400B 以上，世界知识比较丰富的模型才有相对全面的理解。</p><p>这就引出了幻觉（Hallucination）问题。当你向模型索要具体的论文信息或要求它撰写专业综述时，它很可能会编造文献信息。</p><p>正确的做法是使用工具和联网，比如检索增强生成（RAG）。许多现代 LLM 产品（如集成了 Google 搜索的 Gemini、或一些 Deep Research 工具）都具备联网搜索能力。它们会先根据你的问题进行网络检索，然后基于可靠的、实时的信源来组织和回答问题，这能极大地提升答案的准确性和时效性。这方面，Gemini 和 Grok 做的较好。</p><p>另外，问模型“你是谁”和“今天几号”这样的问题，也不能代表模型的真实性能，这种东西一般是写在产品的系统提示词里的，否则，模型就无法回答。</p><h2 id=测试题检验模型的真实能力>测试题：检验模型的真实能力<a hidden class=anchor aria-hidden=true href=#测试题检验模型的真实能力>#</a></h2><p>当谁又推出了新的模型，宣称自己是新的 SOTA，如何快速检验它的能力，是否在色彩科学和图像处理上有较好的性能？以下是我积累的测试题，用于快速尝试模型。</p><h3 id=位压缩函数中的逻辑陷阱>位压缩函数中的逻辑陷阱<a hidden class=anchor aria-hidden=true href=#位压缩函数中的逻辑陷阱>#</a></h3><pre tabindex=0><code>import numpy as np

def pack10(data : np.ndarray) -&gt; np.ndarray:
    out = np.zeros((data.shape[0], int(data.shape[1]*(1.25))), dtype=np.uint8)
    out[:, ::5] = data[:, ::4] &gt;&gt; 2
    out[:, 1::5] = ((data[:, ::4] &amp; 0b0000000000000011) &lt;&lt; 6)
    out[:, 1::5] += data[:, 1::4] &gt;&gt; 4
    out[:, 2::5] = ((data[:, 1::4] &amp; 0b0000000000001111) &lt;&lt; 4)
    out[:, 2::5] += data[:, 2::4] &gt;&gt; 6
    out[:, 3::5] = ((data[:, 2::4] &amp; 0b0000000000111111) &lt;&lt; 2)
    out[:, 3::5] += data[:, 3::4] &gt;&gt; 8
    out[:, 4::5] = data[:, 3::4] &amp; 0b0000000011111111
    return out

def pack12(data : np.ndarray) -&gt; np.ndarray:
    out = np.zeros((data.shape[0], int(data.shape[1]*(1.5))), dtype=np.uint8)
    out[:, ::3] = data[:, ::2] &gt;&gt; 4
    out[:, 1::3] = ((data[:, ::2] &amp; 0b0000000000001111) &lt;&lt; 4)
    out[:, 1::3] += data[:, 1::2] &gt;&gt; 8
    out[:, 2::3] = data[:, 1::2] &amp; 0b0000001111111111
    return out

def pack14(data : np.ndarray) -&gt; np.ndarray:
    out = np.zeros((data.shape[0], int(data.shape[1]*(1.75))), dtype=np.uint8)
    out[:, ::7] = data[:, ::6] &gt;&gt; 6
    out[:, 1::7] = ((data[:, ::6] &amp; 0b0000000000000011) &lt;&lt; 6)
    out[:, 1::7] += data[:, 1::6] &gt;&gt; 8
    out[:, 2::7] = ((data[:, 1::6] &amp; 0b0000000000001111) &lt;&lt; 4)
    out[:, 2::7] += data[:, 2::6] &gt;&gt; 6
    out[:, 3::7] = ((data[:, 2::6] &amp; 0b0000000000111111) &lt;&lt; 2)
    out[:, 3::7] += data[:, 3::6] &gt;&gt; 8
    out[:, 4::7] = ((data[:, 3::6] &amp; 0b0000000000001111) &lt;&lt; 4)
    out[:, 4::7] += data[:, 4::6] &gt;&gt; 6
    out[:, 5::7] = ((data[:, 4::6] &amp; 0b0000000000111111) &lt;&lt; 2)
    out[:, 5::7] += data[:, 5::6] &gt;&gt; 8
    out[:, 6::7] = data[:, 5::6] &amp; 0b0000000011111111
    return out

请详细解释三个 Python 函数的作用。
</code></pre><p>这段代码源自 PiDNG 库，意图将 10-bit、12-bit、14-bit 的高位深数据压缩存储到 8-bit 的 uint8 数组中。pack10 和 pack12 的实现是正确的。</p><p>pack10：4 个 10-bit 数据 (40 bits) -> 5 个 8-bit 数据 (40 bits)。
pack12：2 个 12-bit 数据 (24 bits) -> 3 个 8-bit 数据 (24 bits)。</p><p>然而，pack14 函数是错误的。它试图将 6 个 14-bit 数据（6 * 14 = 84 bits）塞进 7 个 8-bit 字节里（7 * 8 = 56 bits），这在数学上是不可能的。正确的实现应该是将 4 个 14-bit 数据（4 * 14 = 56 bits）放进 7 个字节里。</p><p>常见错误：逐行解释 pack14 的代码，但没有意识到其逻辑错误。或为了让代码逻辑自洽，捏造错误的数学解释，例如声称 6 * 14 等于 56。</p><h3 id=rgb-色域立方的概念理解>RGB 色域立方的概念理解<a hidden class=anchor aria-hidden=true href=#rgb-色域立方的概念理解>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span>如何判断给定的 XYZ 三刺激值是否位于一个 RGB 空间的色域范围内。
</span></span><span style=display:flex><span>该 RGB 空间由四个 CIE xy 坐标定义，分别代表红、绿、蓝和白色（其中白点亮度已归一化为 1.0）。
</span></span><span style=display:flex><span>请提供对应的 Python 代码实现。
</span></span></code></pre></div><p>该问题考察 LLM 是否能理解 RGB 色域是一个三维的立方体（或平行六面体），而非一个二维的三角形。</p><p>正确的解法：</p><ul><li>构建转换矩阵：利用红、绿、蓝三个原色的 xy 坐标和白点的 xy 坐标，计算出从 RGB 空间到 CIE XYZ 空间的 3x3 转换矩阵 M。</li><li>矩阵求逆：计算该矩阵的逆矩阵 M_inv，得到从 XYZ 到 RGB 的转换矩阵。</li><li>坐标转换：将给定的 XYZ 值左乘 M_inv，转换得到对应的 RGB 值。</li><li>范围判断：检查计算出的 R, G, B 三个分量是否同时位于 [0, 1] 的闭区间内。如果都在此范围内，则该 XYZ 值位于该 RGB 色域内；否则，位于色域外。</li></ul><p>常见的错误解法：</p><ul><li>将输入的 XYZ 值也转换为 xy 坐标。</li><li>接着，在 CIE xy 色度图上判断这个点是否位于由 R, G, B 三个原色 xy 坐标围成的三角形内。</li><li>这种方法完全忽略了颜色的亮度（Y）信息，是错误的。一个颜色可能色度正确，但因为太亮或太暗而超出目标色域范围。</li></ul><h3 id=ciecam-16-代码实现>CIECAM 16 代码实现<a hidden class=anchor aria-hidden=true href=#ciecam-16-代码实现>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-markdown data-lang=markdown><span style=display:flex><span>请编写一个 Python 函数，该函数接收 CIECAM16 模型的输入参数（XYZ, XYZ_w, L_A, Y_b, surround），并返回计算出的色貌属性。请使用 NumPy 库进行数值运算。
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>在 main 函数中，计算：
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>XYZ = [19.01, 20.00, 21.78]
</span></span><span style=display:flex><span>XYZ_w = [95.05, 100.00, 108.88]
</span></span><span style=display:flex><span>L_A = 318.31
</span></span><span style=display:flex><span>Y_b = 20.0
</span></span><span style=display:flex><span>surround = &#34;Average&#34;
</span></span></code></pre></div><p>考察模型的世界知识和编程能力，CIECAM 16 这样复杂的模型，给 LLM 完整的 PDF 输入会更好，但大参数量的模型有能力直接写出正确的代码。表现最好的是 Gemini 2.5 Pro，GPT 5 (high) 和 DeepSeek R1 0528，都只在 1-2 个公式上犯了一点小错误。正确的输出是：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;J&#34;</span>: <span style=color:#ae81ff>41.73120790512664</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;C&#34;</span>: <span style=color:#ae81ff>0.10335573870906986</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;h&#34;</span>: <span style=color:#ae81ff>217.067959767393</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;Q&#34;</span>: <span style=color:#ae81ff>195.37170899282242</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;M&#34;</span>: <span style=color:#ae81ff>0.10743677233590453</span>,
</span></span><span style=display:flex><span>  <span style=color:#f92672>&#34;s&#34;</span>: <span style=color:#ae81ff>2.3450150729795514</span>
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>2025.11.06：泄漏的 <code>gemini-3-pro-preview-11-2025</code> 是第一个能直接无参考写出完全无错误的 CIECAM16 的大模型。</p><p>2025.11.18：正式发布的 <code>gemini-3-pro-preview</code> 干脆利落的写出了正确的代码。</p><p>2025.12.01：<code>Deepseek V3.2 Speciale</code> 在思考 23K tokens 之后，成为第一个正确回答此题的开源模型。</p><h3 id=xyy-立体形状>xyY 立体形状<a hidden class=anchor aria-hidden=true href=#xyy-立体形状>#</a></h3><pre tabindex=0><code>一个有限的RGB空间，三个分量的范围均为0-1，可以经过一个3x3的矩阵转换为XYZ。如果画在三维坐标系中，RGB为一个立方体，XYZ是一个平行六面体，XYZ可以进一步转换为xyY，将得到的xyY绘制在三维坐标系中，以xy为底面，Y为z轴，会得到一个什么形状？
</code></pre><p>从 RGB 到 XYZ 的线性变换很简单，可以把一个单位立方体拉伸成一个平行六面体，而转换到 xyY 进行的是一种非线性变换，可以称其为投影变换，此时得到的是一个形状比较复杂的立体。</p><p>正确的形状是一个顶部呈帐篷状曲面的三角柱体。</p><ul><li>底面：黑色点 (0,0,0) 在 xy 色度图上没有定义，通常视为底面。</li><li>侧面：由 RGB 三个原色点构成的色域三角形向上延伸，形成三个垂直于底面的平面。</li><li>顶部：由白点 (1,1,1) 和三个二次色（青、品、黄）连接形成的三个双曲型曲面，像一个塌陷的帐篷顶。</li></ul><p>大多数模型都会错误地认为它是一个有六个曲面的立体。直到 2025 年 11 月 18 日发布的 <code>gemini-3-pro-preview</code> 终于能够完整且正确地回答这个问题，准确描述出其“三角柱体”和“帐篷状顶部”的几何特征。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://jackchou.top/tags/llm/>LLM</a></li></ul><nav class=paginav><a class=prev href=https://jackchou.top/posts/jpeg-structure/><span class=title>« 上一篇</span><br><span>HDR 图像格式解析（二）：JPEG 和对 JPEG 的魔改</span>
</a><a class=next href=https://jackchou.top/posts/gainmap-image-intro/><span class=title>下一篇 »</span><br><span>HDR 图像格式解析（一）：Gainmap 的基本概念</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://jackchou.top/>JacksBlog</a></span> ·
my friends&rsquo; websites: <a href=https://zhxwu.com/>zhxwu.com</a>, <a href=https://ylqian.com/>ylqian.com</a> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script defer crossorigin=anonymous src=/js/site.min.a576538c52b362e170acc02d53f5ce6045117863354954a8f91f10c7217d94ab.js integrity="sha256-pXZTjFKzYuFwrMAtU/XOYEUReGM1SVSo+R8QxyF9lKs="></script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="拷贝";function s(){t.innerHTML="已拷贝",setTimeout(()=>{t.innerHTML="拷贝"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>